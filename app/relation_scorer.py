from __future__ import annotations
from typing import Dict, List, Tuple, Optional
import os, itertools, time, random, re, hashlib, json
from collections import defaultdict, deque
from pprint import pformat
from config import get_config
from azure_clients import get_azure_chat_completion_client, build_chat_completion_params
from utils import call_ollama_generate

# ===== è¨­å®šï¼ˆconfigé›†ä¸­ç®¡ç†ï¼‰ =====
_CFG = get_config()
BACKEND = _CFG.scorer.backend.lower()
OLLAMA_MODEL = getattr(_CFG.ollama, "model_rl", None) or _CFG.ollama.model
LLM_CFG = _CFG.llm

def _pick_ollama_base():
    scorer_base_env = os.getenv("OLLAMA_SCORER_BASE")
    if scorer_base_env:
        return scorer_base_env
    # 1) ç’°å¢ƒå¤‰æ•° OLLAMA_BASE ãŒã‚ã‚Œã°æœ€å„ªå…ˆ
    base = os.getenv("OLLAMA_BASE")
    if base:
        return base
    scorer_base_cfg = getattr(_CFG.ollama, "scorer_base", None)
    if scorer_base_cfg:
        return scorer_base_cfg
    # 2) OLLAMA_BASES ãŒã‚ã‚Œã°å…ˆé ­ã‚’ä½¿ã†
    bases_env = os.getenv("OLLAMA_BASES")
    if bases_env:
        return bases_env.split(",")[0].strip()
    # 3) config ã® ollama.bases ãŒã‚ã‚Œã°å…ˆé ­
    bases_cfg = getattr(_CFG.ollama, "bases", None)
    if isinstance(bases_cfg, (list, tuple)) and bases_cfg:
        return bases_cfg[0]
    # 4) æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä½¿ã‚ãªã„ã®ãŒç†æƒ³ï¼‰
    return "http://ollama_a:11434"

OLLAMA_BASE = _pick_ollama_base()

# === è©±è€…åã®æ­£è¦åŒ–ï¼ˆä¾‹ï¼šRobot, robot, Pepper â†’ ã€Œãƒ­ãƒœãƒƒãƒˆã€ï¼‰ ===
_SPEAKER_ALIASES = {
    "robot": "ãƒ­ãƒœãƒƒãƒˆ",
    "Robot": "ãƒ­ãƒœãƒƒãƒˆ",
    "ROBOT": "ãƒ­ãƒœãƒƒãƒˆ",
    "pepper": "ãƒ­ãƒœãƒƒãƒˆ",
    "Pepper": "ãƒ­ãƒœãƒƒãƒˆ",
    "* A": "A",
    "* B": "B",
}
def _norm_speaker(name: str | None) -> str | None:
    if name is None:
        return None
    return _SPEAKER_ALIASES.get(name, name)

def _pairs(participants: List[str]) -> List[Tuple[str, str]]:
    """å‚åŠ è€…ãƒªã‚¹ãƒˆã‹ã‚‰å…¨ãƒšã‚¢ã‚’ç”Ÿæˆ"""
    # å‚åŠ è€…åã‚’æ­£è¦åŒ–ã—ã¦ã‹ã‚‰ãƒšã‚¢åŒ–
    uniq = sorted(set(_norm_speaker(p) for p in participants if p is not None))
    return [tuple(sorted(p)) for p in itertools.combinations(uniq, 2)]

def _clip(x: float, lo=-1.0, hi=1.0) -> float:
    """-1.0ã€œ+1.0 ã«ä¸¸ã‚ã‚‹"""
    return float(max(lo, min(hi, x)))

# ===== ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆç„¡æ–™ï¼‰ =====
def _scores_rule(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """å˜ç´”ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    text = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    pos_kw = ["ãã†ã ã­","ãªã‚‹ã»ã©","ã„ã„ã­","ã‚ã‚ŠãŒã¨ã†","åŒæ„","å…±æ„Ÿ","åŠ©ã‹ã‚‹"]
    neg_kw = ["é•ã†","ã„ã‚„","ç„¡ç†","å«Œ","ãŠã‹ã—ã„","é–“é•ã„","æ€’ã‚‹"]
    scores = {}
    for a,b in _pairs(participants):
        near = len(re.findall(fr"{re.escape(a)}.*?{re.escape(b)}|{re.escape(b)}.*?{re.escape(a)}", text))
        pos = sum(text.count(k) for k in pos_kw)
        neg = sum(text.count(k) for k in neg_kw)
        base = 0.1*near + 0.05*(pos-neg)
        noise = random.uniform(-0.1, 0.1)
        scores[(a,b)] = _clip(base+noise)
    return scores

# ===== Ollamaï¼ˆç„¡æ–™ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ =====
def _scores_ollama(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Ollama ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    conv = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    plines = "\n".join([f"- {a} Ã— {b}" for a,b in _pairs(participants)])
    outlines = "\n".join([f"{a}-{b}:" for a,b in _pairs(participants)])
    prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å„ãƒšã‚¢ã®è¦ªå¯†åº¦ã‚’ -1.0ã€œ+1.0ï¼ˆå°æ•°1æ¡ï¼‰ã§å‡ºåŠ›ã€‚
-1.0: å¼·ã„å¯¾ç«‹, 0.0: ä¸­ç«‹, +1.0: éå¸¸ã«è¦ªã—ã„

æ³¨æ„:
- å›ºæœ‰åã¯ä¼šè©±ãƒ­ã‚°ã®è¡¨è¨˜ã«å³å¯†ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚
- ãƒ­ãƒœãƒƒãƒˆã¯å¿…ãšã€Œãƒ­ãƒœãƒƒãƒˆã€ã¨è¡¨è¨˜ã—ã€"Robot" ç­‰ã®è‹±èªè¡¨è¨˜ã‚’ä½¿ã‚ãªã„ã“ã¨ã€‚

è©•ä¾¡å¯¾è±¡:
{plines}

ä¼šè©±:
{conv}

å‡ºåŠ›å½¢å¼ï¼ˆå€¤ã ã‘ã‚’ã‚³ãƒ­ãƒ³ã®å³ã«è¨˜ã™ï¼‰:
{outlines}
"""
    response_text = call_ollama_generate(
        prompt=prompt,
        base_url=OLLAMA_BASE,
        model=OLLAMA_MODEL,
        timeout=120,
        max_attempts=3
    )
    return _parse_score_lines(response_text, participants)

# ===== Azure (OpenAI compatible) =====
def _scores_azure(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Azure OpenAI çµŒç”±ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    conv = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    plines = "\n".join([f"- {a} Ã— {b}" for a,b in _pairs(participants)])
    outlines = "\n".join([f"{a}-{b}:" for a,b in _pairs(participants)])
    prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å‚åŠ è€…ãã‚Œãã‚Œã®ã€Œä»²ã®è‰¯ã•ï¼ˆè¦ªå¯†åº¦ï¼‰ã€ã‚’ -1.0 ã€œ +1.0 ã®é–“ã®**å®Ÿæ•°ï¼ˆå°æ•°ç¬¬1ä½ã¾ã§ï¼‰**ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
0.0 ã¯ç‰¹ã«è¦ªã—ã•ã‚‚å¯¾ç«‹ã‚‚æ„Ÿã˜ãªã„ã€Œä¸­ç«‹çš„ãªçŠ¶æ…‹ã€ã§ã™ã€‚
ãã“ã‹ã‚‰ -1.0ï¼ˆå¼·ã„å¯¾ç«‹ï¼‰ ã€œ +1.0ï¼ˆéå¸¸ã«è¦ªã—ã„ï¼‰ ã«å‘ã‘ã¦ã€ã©ã‚Œãã‚‰ã„é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

å…·ä½“ä¾‹ï¼š
-1.0 ä¾‹ï¼šçš®è‚‰ã€æ‰¹åˆ¤ã€ç„¡è¦–ã€ç›¸æ‰‹ã‚’ç„¡è¦–ã—ã¦è©±ã‚’é€²ã‚ã‚‹
+1.0 ä¾‹ï¼šå…±æ„Ÿã€è¤’ã‚ã‚‹ã€ç›¸æ‰‹ã«è©±é¡Œã‚’æŒ¯ã‚‹ã€ä¸€ç·’ã«è¡Œå‹•ã™ã‚‹

æ³¨æ„:
- å›ºæœ‰åã¯ä¼šè©±ãƒ­ã‚°ã®è¡¨è¨˜ã«å³å¯†ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚
- ãƒ­ãƒœãƒƒãƒˆã¯å¿…ãšã€Œãƒ­ãƒœãƒƒãƒˆã€ã¨è¡¨è¨˜ã—ã€"Robot" ç­‰ã®è‹±èªè¡¨è¨˜ã‚’ä½¿ã‚ãªã„ã“ã¨ã€‚

è©•ä¾¡å¯¾è±¡:
{plines}

ä¼šè©±:
{conv}

å‡ºåŠ›å½¢å¼ï¼ˆå€¤ã ã‘ã‚’ã‚³ãƒ­ãƒ³ã®å³ã«è¨˜ã™ï¼‰:
{outlines}
"""
    client, deployment = get_azure_chat_completion_client(LLM_CFG, model_type="relation")
    max_attempts = getattr(_CFG.llm, "max_attempts", 5) or 5
    base_backoff = getattr(_CFG.llm, "base_backoff", 0.5) or 0.5
    if client and deployment:
        messages = [{"role": "user", "content": prompt}]
        for attempt in range(1, max_attempts + 1):
            try:
                # GPT-5ã®å ´åˆã¯reasoningãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                params = build_chat_completion_params(deployment, messages, LLM_CFG)
                res = client.chat.completions.create(**params)
                if res and getattr(res, "choices", None):
                    choice = res.choices[0]
                    message = getattr(choice, "message", None)
                    if isinstance(message, dict):
                        txt = message.get("content", "")
                    else:
                        txt = getattr(message, "content", "")
                    txt = (txt or "").strip()
                    if txt:
                        # Azure ã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦è¾æ›¸ã‚’è¿”ã™
                        return _parse_score_lines(txt, participants)
            except Exception as exc:
                if getattr(_CFG.env, "debug", False):
                    print(f"[relation_scorer] attempt {attempt} failed:", exc)
                if attempt < max_attempts:
                    time.sleep(base_backoff * (2 ** (attempt - 1)))
                else:
                    if getattr(_CFG.env, "debug", False):
                        print("[relation_scorer] all attempts failed, falling back to local heuristic")
        # ã“ã“ã¾ã§æ¥ãŸã‚‰ Azure å‘¼ã³å‡ºã—ã¯å…¨ã¦å¤±æ•—ã—ãŸ
        # å¼·åˆ¶ã‚¨ãƒ©ãƒ¼ã«ã›ãšã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹
        if getattr(_CFG.env, "debug", False):
            print("[relation_scorer] Azure failed after retries -> falling back to rule-based scorer")
        return _scores_rule(logs, participants)
    else:
        # client/deployment ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯æ˜ç¤ºçš„ã«ã‚¨ãƒ©ãƒ¼
        raise RuntimeError("Azure relation scorer not configured (client/deployment missing)")

# ===== å…±é€š: ãƒ‘ãƒ¼ã‚¹ & å®Œæˆ =====
def _parse_score_lines(text: str, participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Ollama/OpenAI ã®å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒšã‚¢ã‚¹ã‚³ã‚¢è¾æ›¸ã«å¤‰æ›"""
    out: Dict[Tuple[str,str], float] = {}
    for line in text.strip().splitlines():
        if ":" not in line: continue
        key,val = line.split(":",1)
        if "-" not in key: continue
        a,b = [s.strip() for s in key.split("-",1)]
        # ã“ã“ã§è©±è€…åã‚’æ­£è¦åŒ–
        a = _norm_speaker(a)
        b = _norm_speaker(b)
        m = re.search(r"-?\d+(\.\d+)?", val)
        if not m: continue
        out[tuple(sorted((a,b)))] = _clip(float(m.group()))
    for a,b in _pairs(participants):
        out.setdefault((a,b), 0.0)
    return out

# ===== å…¬é–‹ã‚¯ãƒ©ã‚¹ï¼ˆEMAå†…è”µï¼‰ =====
class RelationScorer:
    """
    ä¼šè©±ãƒ­ã‚°ã‹ã‚‰ãƒšã‚¢ã‚¹ã‚³ã‚¢(-1..+1)ã‚’æ¨å®šã€‚EMAã§å¹³æ»‘åŒ–å¯èƒ½ã€‚
    """
    def __init__(self, backend: str|None=None, use_ema: bool=False, decay_factor: float = 1.5, verbose: bool=False, use_delta_session: bool=True):
        self.backend = (backend or BACKEND).lower()
        self.use_ema = use_ema
        # use_delta_session: True (æ—¢å®š) ã¯æ—¢å­˜ã®å·®åˆ†ãƒ™ãƒ¼ã‚¹ã®ã‚«ã‚¦ãƒ³ãƒˆæ–¹å¼
        # False ã«ã™ã‚‹ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ç™ºè©±æ•°ã‚’çµ¶å¯¾ã‚«ã‚¦ãƒ³ãƒˆï¼ˆmin(count[a], count[b])ï¼‰ã§æ‰±ã†
        self.use_delta_session = bool(use_delta_session)
        # æ—¢å­˜ community_analyzer.py ã¨åŒã˜å†…éƒ¨çŠ¶æ…‹
        self.scores: Dict[Tuple[str, str], float] = defaultdict(float)  # EMAå¾Œã®ä¿æŒå€¤
        self.history: Dict[Tuple[str, str], deque] = defaultdict(lambda: deque(maxlen=3))  # ãƒšã‚¢ã”ã¨ã®éå»ç™ºè©±æ•°ï¼ˆæœ€å¤§3ä»¶ï¼‰
        self.decay_factor: float = float(decay_factor)
        self.verbose = bool(verbose)
        # ç›´å‰æ›´æ–°æ™‚ç‚¹ã®ã€Œè©±è€…ã”ã¨ã®ç´¯ç©ç™ºè©±æ•°ã€ã‚’ä¿æŒï¼ˆå·®åˆ†ã§ session_utterance ã‚’å‡ºã™ãŸã‚ï¼‰
        # ä¾‹: {"A": 1, "B": 1, "ãƒ­ãƒœãƒƒãƒˆ": 1}
        self._last_totals: Dict[str, int] = defaultdict(int)
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥: æœ€å¾Œã«è¨ˆç®—ã—ãŸãƒ­ã‚°ã®ãƒãƒƒã‚·ãƒ¥ã¨çµæœã‚’ä¿å­˜
        self._last_logs_hash: Optional[str] = None
        self._last_scores_cache: Optional[Dict[Tuple[str, str], float]] = None

    def _compute_logs_hash(self, logs: List[Dict], participants: List[str]) -> str:
        """ãƒ­ã‚°ã¨å‚åŠ è€…ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¤å®šç”¨ï¼‰"""
        # ãƒ­ã‚°ã®å†…å®¹ã‚’æ–‡å­—åˆ—åŒ–ã—ã¦ãƒãƒƒã‚·ãƒ¥åŒ–
        log_str = json.dumps(logs, sort_keys=True, ensure_ascii=False)
        participants_str = json.dumps(sorted(participants), ensure_ascii=False)
        combined = f"{log_str}|{participants_str}"
        return hashlib.md5(combined.encode('utf-8')).hexdigest()

    def _instant(self, logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
        """ä¼šè©±ãƒ­ã‚°ã‹ã‚‰ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’ä¸€å›ã ã‘æ¨å®š"""
        if self.backend == "azure":
            return _scores_azure(logs, participants)
        if self.backend == "ollama":
            return _scores_ollama(logs, participants)
        return _scores_rule(logs, participants)

    def get_scores(self, logs: List[Dict], participants: List[str], return_trace: bool=False, update_state: bool=True):
        """
        æ—¢å­˜ community_analyzer.py ã¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã® EMA ã‚’é©ç”¨ã™ã‚‹:
          - ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®å„è©±è€…ã®ç™ºè©±æ•°ã‚’æ•°ãˆã‚‹
          - ãƒšã‚¢ã”ã¨ã« session_utterance = min(count[a], count[b])
          - total_past = ç›´è¿‘3ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç´¯ç©ç™ºè©±æ•°
          - ratio = session_utterance / (session_utterance + total_past)
          - alpha = clamp( decay_factor * ratio, 0.01, 1.0 )
          - updated = alpha * x_t + (1 - alpha) * prev
        """
        # --- å…¥åŠ›ãƒ­ã‚°ï¼†å‚åŠ è€…ã‚’æ­£è¦åŒ– ---
        norm_logs = []
        for L in logs:
            sp = _norm_speaker(L.get("speaker"))
            norm_logs.append({"speaker": sp, "utterance": L.get("utterance", "")})
        participants = [p for p in (_norm_speaker(p) for p in participants) if p is not None]

        # --- å†…éƒ¨çŠ¶æ…‹ã®å‚åŠ è€…åã‚’æ­£è¦åŒ– ---
        def _canon_key(k: Tuple[str,str]) -> Tuple[str,str]:
            a, b = _norm_speaker(k[0]), _norm_speaker(k[1])
            return tuple(sorted((a, b)))
        if self.scores:
            moved_scores = {}
            for k, v in self.scores.items():
                nk = _canon_key(k)
                moved_scores[nk] = v if nk not in moved_scores else moved_scores[nk]
            self.scores = defaultdict(float, moved_scores)
        if self.history:
            moved_hist: Dict[Tuple[str,str], deque] = {}
            for k, dq in self.history.items():
                nk = _canon_key(k)
                if nk not in moved_hist:
                    moved_hist[nk] = deque(dq, maxlen=3)
                else:
                    # ç‰‡æ–¹ã«æ—¢ã«å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯é•·ã„æ–¹ã‚’å„ªå…ˆï¼ˆç°¡æ˜“ï¼‰
                    if len(dq) > len(moved_hist[nk]):
                        moved_hist[nk] = deque(dq, maxlen=3)
            self.history = defaultdict(lambda: deque(maxlen=3), moved_hist)

        trace: List[str] = []
        trace.append(f"ğŸ‘¥ å‚åŠ è€…: {participants}")

        # ãƒ­ã‚°ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        current_logs_hash = self._compute_logs_hash(norm_logs, participants)

        # === èª­ã¿å–ã‚Šå°‚ç”¨ï¼ˆäº‹å‰ï¼‰ãƒ¢ãƒ¼ãƒ‰ï¼šãƒ­ã‚°ãŒåŒã˜ãªã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™ã€é•ãˆã°å†è¨ˆç®— ===
        if not update_state:
            # ãƒ­ã‚°ãŒå‰å›ã¨åŒã˜ãªã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™
            if (self._last_logs_hash == current_logs_hash and
                self._last_scores_cache is not None):
                trace.append("ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰å‰å›ã¨åŒã˜ãƒ­ã‚°: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’è¿”å´")
                return (self._last_scores_cache, trace) if return_trace else self._last_scores_cache

            # ãƒ­ã‚°ãŒé•ã†å ´åˆã¯å†è¨ˆç®—ï¼ˆãŸã ã—å†…éƒ¨çŠ¶æ…‹ã¯æ›´æ–°ã—ãªã„ï¼‰
            out: Dict[Tuple[str, str], float] = {}
            for a, b in _pairs(participants):
                key = tuple(sorted((_norm_speaker(a), _norm_speaker(b))))
                if self.use_ema:
                    # ä¿å­˜æ¸ˆã¿EMAå€¤ãŒãªã‘ã‚Œã°0.0è¿”å´
                    out[key] = self.scores.get(key, 0.0)
                else:
                    # EMAæœªä½¿ç”¨æ™‚ã¯å³æ™‚æ¨å®šã‚’è¿”ã™
                    out[key] = self._instant(norm_logs, participants).get((a, b), 0.0)
            trace.append("ï¼ˆå‚ç…§ï¼‰ãƒ­ã‚°å¤‰æ›´æ¤œå‡º: ä¿å­˜æ¸ˆã¿ã‚¹ã‚³ã‚¢ã‚’è¿”å´ï¼ˆEMAçŠ¶æ…‹ã¯æ›´æ–°ã—ãªã„ï¼‰")
            return (out, trace) if return_trace else out
        
        inst = self._instant(norm_logs, participants)
        # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯: _instant ã¯å¿…ãš dict ã‚’è¿”ã™ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
        if not isinstance(inst, dict):
            raise TypeError(f"relation_scorer._instant returned {type(inst).__name__}, expected dict")

        # === EMA ã‚’ä½¿ç”¨ã—ãªã„å ´åˆã¯ã€å³æ™‚ã‚¹ã‚³ã‚¢ã‚’ãã®ã¾ã¾è¿”ã™ ===
        if not self.use_ema:
            trace.append("âš¡ EMA disabled: returning instant (backend) scores")
            # update_state=True ã®ã¨ãã¯ä¿å­˜æ¸ˆã¿ã‚¹ã‚³ã‚¢ã‚’æœ€æ–°ã«æ›´æ–°ï¼ˆå±¥æ­´ã¯ã‚¯ãƒªã‚¢ï¼‰
            if update_state:
                self.scores = defaultdict(float, inst)
                self.history = defaultdict(lambda: deque(maxlen=3))
                self._last_totals = defaultdict(int)
            trace.append(f"ğŸ“Š å³æ™‚ã‚¹ã‚³ã‚¢ï¼ˆæœ€çµ‚ï¼‰: {pformat(inst)}")
            if self.verbose:
                print("[RelationScorer] EMA trace (disabled):")
                for line in trace:
                    print(line)
            return (inst, trace) if return_trace else inst

        # === ã“ã“ã‹ã‚‰é€šå¸¸ï¼ˆäº‹å¾Œï¼‰ãƒ¢ãƒ¼ãƒ‰ï¼šEMAã‚’æ›´æ–°ã—ã¦è¿”ã™ ===
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ç™ºè©±æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆè©±è€…åˆ¥ï¼‰
        utterance_counts: Dict[str, int] = defaultdict(int)
        for log in norm_logs:
            sp = log.get("speaker")
            if sp is not None:
                utterance_counts[sp] += 1
        trace.append(f"ğŸ—£ï¸ ç™ºè©±æ•°: {dict(utterance_counts)}")
        trace.append(f"ğŸ§  å³æ™‚ã‚¹ã‚³ã‚¢: {pformat(inst)}")
        trace.append(f"ğŸ”§ session mode: {'delta' if self.use_delta_session else 'absolute'}")

        out: Dict[Tuple[str, str], float] = {}
        for (a, b), x_t in inst.items():
            key = tuple(sorted((_norm_speaker(a), _norm_speaker(b))))
            past_utterances = self.history[key]
            total_past = sum(past_utterances)
            # ç›´å‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã¨ã®å·®åˆ†ã‹ã‚‰ã€Œä»Šå›ã®ã‚¹ãƒ†ãƒƒãƒ—å¢—åˆ†ã€ã‚’è¨ˆç®—
            if self.use_delta_session:
                da = max(0, utterance_counts.get(a, 0) - self._last_totals.get(a, 0))
                db = max(0, utterance_counts.get(b, 0) - self._last_totals.get(b, 0))
                session_utterance = min(da, db)
            else:
                # çµ¶å¯¾ã‚«ã‚¦ãƒ³ãƒˆæ–¹å¼: ä»Šå›ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç™ºè©±æ•°ãã®ã‚‚ã®ã®æœ€å°å€¤ã‚’ä½¿ã†
                da = utterance_counts.get(a, 0)
                db = utterance_counts.get(b, 0)
                session_utterance = min(da, db)

            # ãƒ‡ãƒãƒƒã‚°/ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨æƒ…å ±ã‚’è¿½åŠ 
            trace.append(f"ğŸ” ãƒšã‚¢: {key}, da={da}, db={db}, session_utterance={session_utterance}, total_past={total_past}, history={list(past_utterances)}")

            if key not in self.scores:
                # åˆå›ã¯ãã®ã¾ã¾æ¡ç”¨
                self.scores[key] = x_t
                out[key] = x_t
                trace.append(f"ğŸ†• åˆæœŸã‚¹ã‚³ã‚¢: {key} = {x_t:.2f}")
            else:
                # æ—¢å­˜å®Ÿè£…ã¨åŒä¸€ã® Î± è¨ˆç®—
                denom = (session_utterance + total_past)
                ratio = (session_utterance / denom) if denom > 0 else 0.0
                alpha_dyn = max(0.01, min(1.0, self.decay_factor * ratio))
                prev = self.scores[key]
                updated = alpha_dyn * x_t + (1.0 - alpha_dyn) * prev
                self.scores[key] = updated
                out[key] = updated
                trace.append(f"ğŸ”¢ Î±è¨ˆç®—: {key}, session={session_utterance}, past={total_past}, Î±={alpha_dyn:.2f}")
                trace.append(f"ğŸ” EMAæ›´æ–°: {key} = {alpha_dyn:.2f}Ã—{x_t:.2f} + {(1-alpha_dyn):.2f}Ã—{prev:.2f} â†’ {updated:.2f}")

            # ç›´è¿‘å±¥æ­´ã«ä»Šå›ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç™ºè©±æ•°ã‚’è¿½åŠ ï¼ˆæœ€å¤§3ä»¶ï¼‰
            past_utterances.append(session_utterance)

        # â˜… update_state=True ã®ã¨ãã ã‘ã€ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ç¾åœ¨å€¤ã«æ›´æ–°
        if update_state:
            self._last_totals = defaultdict(int, utterance_counts)
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
            self._last_logs_hash = current_logs_hash
            self._last_scores_cache = dict(out)

        trace.append(f"ğŸ“ˆ EMAå¾Œã‚¹ã‚³ã‚¢: {pformat(out)}")
        # verbose ãƒ¢ãƒ¼ãƒ‰ãªã‚‰è¨ˆç®—éç¨‹ã‚’æ¨™æº–å‡ºåŠ›ã¸å‡ºã™
        if self.verbose:
            print("[RelationScorer] EMA trace:")
            for line in trace:
                print(line)
        return (out, trace) if return_trace else out  # outã®ä¾‹: {("A","B"): 0.3, ("A","C"): -0.1, ("B","C"): 0.0}
