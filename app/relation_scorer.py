from __future__ import annotations
from typing import Dict, List, Tuple
import os, itertools, time, random, re
from collections import defaultdict, deque
from pprint import pformat
from config import get_config

# ===== è¨­å®šï¼ˆconfigé›†ä¸­ç®¡ç†ï¼‰ =====
_CFG = get_config()
BACKEND = _CFG.scorer.backend.lower()
OLLAMA_MODEL = getattr(_CFG.ollama, "model_rl", None) or _CFG.ollama.model
# OpenAI/Azure OpenAIè¨­å®šï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€llmã¨openaiã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆï¼‰
if hasattr(_CFG, 'openai'):
    OPENAI_MODEL   = _CFG.openai.model
    OPENAI_API_KEY = _CFG.openai.api_key
else:
    # llmã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—ï¼ˆAzure OpenAIç”¨ï¼‰
    OPENAI_MODEL   = getattr(_CFG.llm, 'relation_model', _CFG.llm.azure_model)
    OPENAI_API_KEY = _CFG.llm.azure_api_key

def _pick_ollama_base():
    scorer_base_env = os.getenv("OLLAMA_SCORER_BASE")
    if scorer_base_env:
        return scorer_base_env
    # 1) ç’°å¢ƒå¤‰æ•° OLLAMA_BASE ãŒã‚ã‚Œã°æœ€å„ªå…ˆ
    base = os.getenv("OLLAMA_BASE")
    if base:
        return base
    scorer_base_cfg = getattr(_CFG.ollama, "scorer_base", None)
    if scorer_base_cfg:
        return scorer_base_cfg
    # 2) OLLAMA_BASES ãŒã‚ã‚Œã°å…ˆé ­ã‚’ä½¿ã†
    bases_env = os.getenv("OLLAMA_BASES")
    if bases_env:
        return bases_env.split(",")[0].strip()
    # 3) config ã® ollama.bases ãŒã‚ã‚Œã°å…ˆé ­
    bases_cfg = getattr(_CFG.ollama, "bases", None)
    if isinstance(bases_cfg, (list, tuple)) and bases_cfg:
        return bases_cfg[0]
    # 4) æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä½¿ã‚ãªã„ã®ãŒç†æƒ³ï¼‰
    return "http://ollama_a:11434"

OLLAMA_BASE = _pick_ollama_base()

# === è©±è€…åã®æ­£è¦åŒ–ï¼ˆä¾‹ï¼šRobot, robot, Pepper â†’ ã€Œãƒ­ãƒœãƒƒãƒˆã€ï¼‰ ===
_SPEAKER_ALIASES = {
    "robot": "ãƒ­ãƒœãƒƒãƒˆ",
    "Robot": "ãƒ­ãƒœãƒƒãƒˆ",
    "ROBOT": "ãƒ­ãƒœãƒƒãƒˆ",
    "pepper": "ãƒ­ãƒœãƒƒãƒˆ",
    "Pepper": "ãƒ­ãƒœãƒƒãƒˆ",
    "* A": "A",
    "* B": "B",
}
def _norm_speaker(name: str | None) -> str | None:
    if name is None:
        return None
    return _SPEAKER_ALIASES.get(name, name)

def _pairs(participants: List[str]) -> List[Tuple[str, str]]:
    """å‚åŠ è€…ãƒªã‚¹ãƒˆã‹ã‚‰å…¨ãƒšã‚¢ã‚’ç”Ÿæˆ"""
    # å‚åŠ è€…åã‚’æ­£è¦åŒ–ã—ã¦ã‹ã‚‰ãƒšã‚¢åŒ–
    uniq = sorted(set(_norm_speaker(p) for p in participants if p is not None))
    return [tuple(sorted(p)) for p in itertools.combinations(uniq, 2)]

def _clip(x: float, lo=-1.0, hi=1.0) -> float:
    """-1.0ã€œ+1.0 ã«ä¸¸ã‚ã‚‹"""
    return float(max(lo, min(hi, x)))

def _retry(n=3, backoff=1.0):
    def deco(fn):
        def wrap(*a, **kw):
            last=None
            for i in range(n):
                try: return fn(*a, **kw)
                except Exception as e:
                    last=e; time.sleep(backoff*(i+1))
            raise last
        return wrap
    return deco

# ===== ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆç„¡æ–™ï¼‰ =====
def _scores_rule(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """å˜ç´”ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    text = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    pos_kw = ["ãã†ã ã­","ãªã‚‹ã»ã©","ã„ã„ã­","ã‚ã‚ŠãŒã¨ã†","åŒæ„","å…±æ„Ÿ","åŠ©ã‹ã‚‹"]
    neg_kw = ["é•ã†","ã„ã‚„","ç„¡ç†","å«Œ","ãŠã‹ã—ã„","é–“é•ã„","æ€’ã‚‹"]
    scores = {}
    for a,b in _pairs(participants):
        near = len(re.findall(fr"{re.escape(a)}.*?{re.escape(b)}|{re.escape(b)}.*?{re.escape(a)}", text))
        pos = sum(text.count(k) for k in pos_kw)
        neg = sum(text.count(k) for k in neg_kw)
        base = 0.1*near + 0.05*(pos-neg)
        noise = random.uniform(-0.1, 0.1)
        scores[(a,b)] = _clip(base+noise)
    return scores

# ===== Ollamaï¼ˆç„¡æ–™ãƒ»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ =====
@_retry()
def _ollama_generate(prompt: str) -> str:
    """Ollama /api/generate ã‚’å©ã„ã¦ä¸€æ‹¬å¿œç­”ã‚’è¿”ã™ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ ãªã—ï¼‰ã€‚ç°¡æ˜“ãƒªãƒˆãƒ©ã‚¤ä»˜ãã€‚"""
    import requests
    r = requests.post(f"{OLLAMA_BASE}/api/generate",
                      json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False},
                      timeout=120)
    r.raise_for_status()
    return r.json().get("response","").strip()

def _scores_ollama(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Ollama ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    conv = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    plines = "\n".join([f"- {a} Ã— {b}" for a,b in _pairs(participants)])
    outlines = "\n".join([f"{a}-{b}:" for a,b in _pairs(participants)])
    prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å„ãƒšã‚¢ã®è¦ªå¯†åº¦ã‚’ -1.0ã€œ+1.0ï¼ˆå°æ•°1æ¡ï¼‰ã§å‡ºåŠ›ã€‚
-1.0: å¼·ã„å¯¾ç«‹, 0.0: ä¸­ç«‹, +1.0: éå¸¸ã«è¦ªã—ã„

æ³¨æ„:
- å›ºæœ‰åã¯ä¼šè©±ãƒ­ã‚°ã®è¡¨è¨˜ã«å³å¯†ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚
- ãƒ­ãƒœãƒƒãƒˆã¯å¿…ãšã€Œãƒ­ãƒœãƒƒãƒˆã€ã¨è¡¨è¨˜ã—ã€"Robot" ç­‰ã®è‹±èªè¡¨è¨˜ã‚’ä½¿ã‚ãªã„ã“ã¨ã€‚

è©•ä¾¡å¯¾è±¡:
{plines}

ä¼šè©±:
{conv}

å‡ºåŠ›å½¢å¼ï¼ˆå€¤ã ã‘ã‚’ã‚³ãƒ­ãƒ³ã®å³ã«è¨˜ã™ï¼‰:
{outlines}
"""
    return _parse_score_lines(_ollama_generate(prompt), participants)

# ===== OpenAI =====
def _openai_client():
    """OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    from openai import OpenAI
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚")
    return OpenAI(api_key=OPENAI_API_KEY)

def _scores_openai(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """OpenAI ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    client = _openai_client()
    conv = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    plines = "\n".join([f"- {a} Ã— {b}" for a,b in _pairs(participants)])
    outlines = "\n".join([f"{a}-{b}:" for a,b in _pairs(participants)])
    prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å‚åŠ è€…ãã‚Œãã‚Œã®ã€Œä»²ã®è‰¯ã•ï¼ˆè¦ªå¯†åº¦ï¼‰ã€ã‚’ -1.0 ã€œ +1.0 ã®é–“ã®**å®Ÿæ•°ï¼ˆå°æ•°ç¬¬1ä½ã¾ã§ï¼‰**ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
0.0 ã¯ç‰¹ã«è¦ªã—ã•ã‚‚å¯¾ç«‹ã‚‚æ„Ÿã˜ãªã„ã€Œä¸­ç«‹çš„ãªçŠ¶æ…‹ã€ã§ã™ã€‚
ãã“ã‹ã‚‰ -1.0ï¼ˆå¼·ã„å¯¾ç«‹ï¼‰ ã€œ +1.0ï¼ˆéå¸¸ã«è¦ªã—ã„ï¼‰ ã«å‘ã‘ã¦ã€ã©ã‚Œãã‚‰ã„é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

æ³¨æ„:
- å›ºæœ‰åã¯ä¼šè©±ãƒ­ã‚°ã®è¡¨è¨˜ã«å³å¯†ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚
- ãƒ­ãƒœãƒƒãƒˆã¯å¿…ãšã€Œãƒ­ãƒœãƒƒãƒˆã€ã¨è¡¨è¨˜ã—ã€"Robot" ç­‰ã®è‹±èªè¡¨è¨˜ã‚’ä½¿ã‚ãªã„ã“ã¨ã€‚

è©•ä¾¡å¯¾è±¡:
{plines}

ä¼šè©±:
{conv}

å‡ºåŠ›å½¢å¼ï¼ˆå€¤ã ã‘ã‚’ã‚³ãƒ­ãƒ³ã®å³ã«è¨˜ã™ï¼‰:
{outlines}
"""
    res = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role":"user","content":prompt}],
        temperature=0,
    )
    txt = res.choices[0].message.content
    return _parse_score_lines(txt, participants)

# ===== Azure OpenAI =====
def _scores_azure(logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Azure OpenAI ãƒ™ãƒ¼ã‚¹ã§ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’æ¨å®š"""
    from azure_clients import get_azure_chat_completion_client, build_chat_completion_params

    client, deployment = get_azure_chat_completion_client(_CFG.llm, model_type="relation")
    if not client or not deployment:
        raise RuntimeError("Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    conv = "\n".join([f"[{L['speaker']}] {L['utterance']}" for L in logs])
    plines = "\n".join([f"- {a} Ã— {b}" for a,b in _pairs(participants)])
    outlines = "\n".join([f"{a}-{b}:" for a,b in _pairs(participants)])
    prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å‚åŠ è€…ãã‚Œãã‚Œã®ã€Œä»²ã®è‰¯ã•ï¼ˆè¦ªå¯†åº¦ï¼‰ã€ã‚’ -1.0 ã€œ +1.0 ã®é–“ã®**å®Ÿæ•°ï¼ˆå°æ•°ç¬¬1ä½ã¾ã§ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
0.0 ã¯ç‰¹ã«è¦ªã—ã•ã‚‚å¯¾ç«‹ã‚‚æ„Ÿã˜ãªã„ã€Œä¸­ç«‹çš„ãªçŠ¶æ…‹ã€ã§ã™ã€‚
ãã“ã‹ã‚‰ -1.0ï¼ˆå¼·ã„å¯¾ç«‹ï¼‰ ã€œ +1.0ï¼ˆéå¸¸ã«è¦ªã—ã„ï¼‰ ã«å‘ã‘ã¦ã€ã©ã‚Œãã‚‰ã„é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

æ³¨æ„:
- å›ºæœ‰åã¯ä¼šè©±ãƒ­ã‚°ã®è¡¨è¨˜ã«å³å¯†ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚
- ãƒ­ãƒœãƒƒãƒˆã¯å¿…ãšã€Œãƒ­ãƒœãƒƒãƒˆã€ã¨è¡¨è¨˜ã—ã€"Robot" ç­‰ã®è‹±èªè¡¨è¨˜ã‚’ä½¿ã‚ãªã„ã“ã¨ã€‚

è©•ä¾¡å¯¾è±¡:
{plines}

ä¼šè©±:
{conv}

å‡ºåŠ›å½¢å¼ï¼ˆå€¤ã ã‘ã‚’ã‚³ãƒ­ãƒ³ã®å³ã«è¨˜ã™ï¼‰:
{outlines}
"""
    messages = [{"role":"user","content":prompt}]
    params = build_chat_completion_params(deployment, messages, _CFG.llm, temperature=0)
    res = client.chat.completions.create(**params)
    txt = res.choices[0].message.content
    return _parse_score_lines(txt, participants)

# ===== å…±é€š: ãƒ‘ãƒ¼ã‚¹ & å®Œæˆ =====
def _parse_score_lines(text: str, participants: List[str]) -> Dict[Tuple[str,str], float]:
    """Ollama/OpenAI ã®å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒšã‚¢ã‚¹ã‚³ã‚¢è¾æ›¸ã«å¤‰æ›"""
    out: Dict[Tuple[str,str], float] = {}
    for line in text.strip().splitlines():
        if ":" not in line: continue
        key,val = line.split(":",1)
        if "-" not in key: continue
        a,b = [s.strip() for s in key.split("-",1)]
        # ã“ã“ã§è©±è€…åã‚’æ­£è¦åŒ–
        a = _norm_speaker(a)
        b = _norm_speaker(b)
        m = re.search(r"-?\d+(\.\d+)?", val)
        if not m: continue
        out[tuple(sorted((a,b)))] = _clip(float(m.group()))
    for a,b in _pairs(participants):
        out.setdefault((a,b), 0.0)
    return out

# ===== å…¬é–‹ã‚¯ãƒ©ã‚¹ï¼ˆEMAå†…è”µï¼‰ =====
class RelationScorer:
    """
    ä¼šè©±ãƒ­ã‚°ã‹ã‚‰ãƒšã‚¢ã‚¹ã‚³ã‚¢(-1..+1)ã‚’æ¨å®šã€‚EMAã§å¹³æ»‘åŒ–å¯èƒ½ã€‚
    """
    def __init__(self, backend: str|None=None, use_ema: bool=True, alpha: float=0.8, decay_factor: float = 1.5, verbose: bool=False):
        self.backend = (backend or BACKEND).lower()
        self.use_ema = use_ema
        # æ—¢å­˜äº’æ›: alpha å¼•æ•°ã¯æ®‹ã™ãŒã€å‹•çš„ Î±ï¼ˆdecay_factorÃ—ç™ºè©±æ¯”ï¼‰ã‚’å„ªå…ˆã—ã¦ç”¨ã„ã‚‹
        self.alpha = float(alpha)
        # æ—¢å­˜ community_analyzer.py ã¨åŒã˜å†…éƒ¨çŠ¶æ…‹
        self.scores: Dict[Tuple[str, str], float] = defaultdict(float)  # EMAå¾Œã®ä¿æŒå€¤
        self.history: Dict[Tuple[str, str], deque] = defaultdict(lambda: deque(maxlen=3))  # ãƒšã‚¢ã”ã¨ã®éå»ç™ºè©±æ•°ï¼ˆæœ€å¤§3ä»¶ï¼‰
        self.decay_factor: float = float(decay_factor)
        self.verbose = bool(verbose)
        # ç›´å‰æ›´æ–°æ™‚ç‚¹ã®ã€Œè©±è€…ã”ã¨ã®ç´¯ç©ç™ºè©±æ•°ã€ã‚’ä¿æŒï¼ˆå·®åˆ†ã§ session_utterance ã‚’å‡ºã™ãŸã‚ï¼‰
        # ä¾‹: {"A": 1, "B": 1, "ãƒ­ãƒœãƒƒãƒˆ": 1}
        self._last_totals: Dict[str, int] = defaultdict(int)

    def _instant(self, logs: List[Dict], participants: List[str]) -> Dict[Tuple[str,str], float]:
        """ä¼šè©±ãƒ­ã‚°ã‹ã‚‰ãƒšã‚¢ã‚¹ã‚³ã‚¢ã‚’ä¸€å›ã ã‘æ¨å®š"""
        if self.backend == "openai":
            return _scores_openai(logs, participants)
        if self.backend == "azure":
            return _scores_azure(logs, participants)
        if self.backend == "ollama":
            return _scores_ollama(logs, participants)
        return _scores_rule(logs, participants)

    def get_scores(self, logs: List[Dict], participants: List[str], return_trace: bool=False, update_state: bool=True):
        """
        æ—¢å­˜ community_analyzer.py ã¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã® EMA ã‚’é©ç”¨ã™ã‚‹:
          - ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®å„è©±è€…ã®ç™ºè©±æ•°ã‚’æ•°ãˆã‚‹
          - ãƒšã‚¢ã”ã¨ã« session_utterance = min(count[a], count[b])
          - total_past = ç›´è¿‘3ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç´¯ç©ç™ºè©±æ•°
          - ratio = session_utterance / (session_utterance + total_past)
          - alpha = clamp( decay_factor * ratio, 0.01, 1.0 )
          - updated = alpha * x_t + (1 - alpha) * prev
        """
        # --- å…¥åŠ›ãƒ­ã‚°ï¼†å‚åŠ è€…ã‚’æ­£è¦åŒ– ---
        norm_logs = []
        for L in logs:
            sp = _norm_speaker(L.get("speaker"))
            norm_logs.append({"speaker": sp, "utterance": L.get("utterance", "")})
        participants = [p for p in (_norm_speaker(p) for p in participants) if p is not None]

        # --- å†…éƒ¨çŠ¶æ…‹ã®å‚åŠ è€…åã‚’æ­£è¦åŒ– ---
        def _canon_key(k: Tuple[str,str]) -> Tuple[str,str]:
            a, b = _norm_speaker(k[0]), _norm_speaker(k[1])
            return tuple(sorted((a, b)))
        if self.scores:
            moved_scores = {}
            for k, v in self.scores.items():
                nk = _canon_key(k)
                moved_scores[nk] = v if nk not in moved_scores else moved_scores[nk]
            self.scores = defaultdict(float, moved_scores)
        if self.history:
            moved_hist: Dict[Tuple[str,str], deque] = {}
            for k, dq in self.history.items():
                nk = _canon_key(k)
                if nk not in moved_hist:
                    moved_hist[nk] = deque(dq, maxlen=3)
                else:
                    # ç‰‡æ–¹ã«æ—¢ã«å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯é•·ã„æ–¹ã‚’å„ªå…ˆï¼ˆç°¡æ˜“ï¼‰
                    if len(dq) > len(moved_hist[nk]):
                        moved_hist[nk] = deque(dq, maxlen=3)
            self.history = defaultdict(lambda: deque(maxlen=3), moved_hist)

        trace: List[str] = []
        trace.append(f"ğŸ‘¥ å‚åŠ è€…: {participants}")

        # === èª­ã¿å–ã‚Šå°‚ç”¨ï¼ˆäº‹å‰ï¼‰ãƒ¢ãƒ¼ãƒ‰ï¼šå†…éƒ¨EMAã‚’ä¸€åˆ‡å†è¨ˆç®—ã›ãšã€ä¿å­˜æ¸ˆã¿å€¤ã‚’è¿”ã™ ===
        if not update_state:
            out: Dict[Tuple[str, str], float] = {}
            for a, b in _pairs(participants):
                key = tuple(sorted((_norm_speaker(a), _norm_speaker(b))))
                if self.use_ema:
                    # ä¿å­˜æ¸ˆã¿EMAå€¤ãŒãªã‘ã‚Œã°0.0è¿”å´ï¼ˆâ€œå†è¨ˆç®—ãªã—â€ã‚’å¾¹åº•ï¼‰
                    out[key] = self.scores.get(key, 0.0)
                else:
                    # EMAæœªä½¿ç”¨æ™‚ã¯å³æ™‚æ¨å®šã‚’è¿”ã™ï¼ˆå¿…è¦ãªã¨ãã®ã¿è¨ˆç®—ï¼‰
                    out[key] = self._instant(norm_logs, participants).get((a, b), 0.0)
            trace.append("ï¼ˆå‚ç…§ï¼‰äº‹å‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: ä¿å­˜æ¸ˆã¿ã‚¹ã‚³ã‚¢ã‚’è¿”å´ï¼ˆå†è¨ˆç®—ãªã—ï¼‰")
            return (out, trace) if return_trace else out
        
        inst = self._instant(norm_logs, participants)

        # === ã“ã“ã‹ã‚‰é€šå¸¸ï¼ˆäº‹å¾Œï¼‰ãƒ¢ãƒ¼ãƒ‰ï¼šEMAã‚’æ›´æ–°ã—ã¦è¿”ã™ ===
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ç™ºè©±æ•°ã‚«ã‚¦ãƒ³ãƒˆï¼ˆè©±è€…åˆ¥ï¼‰
        utterance_counts: Dict[str, int] = defaultdict(int)
        for log in norm_logs:
            sp = log.get("speaker")
            if sp is not None:
                utterance_counts[sp] += 1
        trace.append(f"ğŸ—£ï¸ ç™ºè©±æ•°: {dict(utterance_counts)}")
        trace.append(f"ğŸ§  å³æ™‚ã‚¹ã‚³ã‚¢: {pformat(inst)}")

        out: Dict[Tuple[str, str], float] = {}

        # use_ema=Falseã®å ´åˆã¯ã€å³æ™‚ã‚¹ã‚³ã‚¢ã‚’ãã®ã¾ã¾è¿”ã™
        if not self.use_ema:
            for (a, b), x_t in inst.items():
                key = tuple(sorted((_norm_speaker(a), _norm_speaker(b))))
                out[key] = x_t
            trace.append("âš¡ EMAç„¡åŠ¹: å³æ™‚ã‚¹ã‚³ã‚¢ã‚’ãã®ã¾ã¾è¿”å´")
            return (out, trace) if return_trace else out

        # use_ema=Trueã®å ´åˆã¯ã€ä»¥ä¸‹ã®EMAå‡¦ç†ã‚’å®Ÿè¡Œ
        for (a, b), x_t in inst.items():
            key = tuple(sorted((_norm_speaker(a), _norm_speaker(b))))
            # ç›´å‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã¨ã®å·®åˆ†ã‹ã‚‰ã€Œä»Šå›ã®ã‚¹ãƒ†ãƒƒãƒ—å¢—åˆ†ã€ã‚’è¨ˆç®—
            da = max(0, utterance_counts.get(a, 0) - self._last_totals.get(a, 0))
            db = max(0, utterance_counts.get(b, 0) - self._last_totals.get(b, 0))
            session_utterance = min(da, db)
            past_utterances = self.history[key]
            total_past = sum(past_utterances)

            if key not in self.scores:
                # åˆå›ã¯ãã®ã¾ã¾æ¡ç”¨
                self.scores[key] = x_t
                out[key] = x_t
                trace.append(f"ğŸ†• åˆæœŸã‚¹ã‚³ã‚¢: {key} = {x_t:.2f}")
            else:
                # æ—¢å­˜å®Ÿè£…ã¨åŒä¸€ã® Î± è¨ˆç®—
                denom = (session_utterance + total_past)
                ratio = (session_utterance / denom) if denom > 0 else 0.0
                alpha_dyn = max(0.01, min(1.0, self.decay_factor * ratio))
                prev = self.scores[key]
                updated = alpha_dyn * x_t + (1.0 - alpha_dyn) * prev
                self.scores[key] = updated
                out[key] = updated
                trace.append(f"ğŸ”¢ Î±è¨ˆç®—: {key}, session={session_utterance}, past={total_past}, Î±={alpha_dyn:.2f}")
                trace.append(f"ğŸ” EMAæ›´æ–°: {key} = {alpha_dyn:.2f}Ã—{x_t:.2f} + {(1-alpha_dyn):.2f}Ã—{prev:.2f} â†’ {updated:.2f}")

            # ç›´è¿‘å±¥æ­´ã«ä»Šå›ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç™ºè©±æ•°ã‚’è¿½åŠ ï¼ˆæœ€å¤§3ä»¶ï¼‰
            past_utterances.append(session_utterance)

        # â˜… EMAæœ‰åŠ¹ã‹ã¤update_state=True ã®ã¨ãã ã‘ã€ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ç¾åœ¨å€¤ã«æ›´æ–°
        if update_state:
            self._last_totals = defaultdict(int, utterance_counts)

        trace.append(f"ğŸ“ˆ EMAå¾Œã‚¹ã‚³ã‚¢: {pformat(out)}")
        return (out, trace) if return_trace else out  # outã®ä¾‹: {("A","B"): 0.3, ("A","C"): -0.1, ("B","C"): 0.0}
