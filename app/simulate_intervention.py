#!/usr/bin/env python3
"""
è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

GPT5ï¼ˆAzure OpenAIï¼‰ã¾ãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®šã—ãŸæ™‚ã®
å ±é…¬ã‚„ä¼šè©±ã®æ§˜å­ã‚’ç¢ºèªã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

ä½¿ç”¨æ–¹æ³•:
    # GPT5ã‚’ä½¿ç”¨
    python simulate_intervention.py --model gpt5 --num-sessions 5
    
    # Qwen3ãªã©ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    python simulate_intervention.py --model local --num-sessions 5
"""

from __future__ import annotations

import argparse
import json
import sys
import time
from typing import Any, Dict, List, Optional

from azure_clients import get_azure_chat_completion_client
from config import get_config
from env.convo_env import ConversationEnv


class InterventionSimulator:
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""

    def __init__(
        self,
        model_type: str = "gpt5",
        max_steps: int = 6,
        num_sessions: int = 5,
        verbose: bool = True,
    ):
        """
        Args:
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt5" ã¾ãŸã¯ "local")
            max_steps: 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
            num_sessions: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°
            verbose: è©³ç´°ãªå‡ºåŠ›ã‚’è¡Œã†ã‹ã©ã†ã‹
        """
        self.model_type = model_type.lower()
        self.max_steps = max_steps
        self.num_sessions = num_sessions
        self.verbose = verbose

        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        cfg = get_config()

        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if self.model_type == "gpt5":
            self._init_gpt5_client(cfg)
        elif self.model_type == "local":
            self._init_local_client(cfg)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}")

        # ç’°å¢ƒã‚’åˆæœŸåŒ–
        personas = getattr(cfg.env, "personas", {})
        
        # max_stepsã‚’æ˜ç¤ºçš„ã«è¨­å®š
        # max_roundsã¯ä½¿ç”¨ã›ãšã€max_stepsã§çµ‚äº†æ¡ä»¶ã‚’åˆ¶å¾¡
        # max_historyã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ¸¡ã™ãŒã€envå†…éƒ¨ã§æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å„ªå…ˆã™ã‚‹
        self.env = ConversationEnv(
            max_steps=max_steps,
            personas=personas,
            include_robot=True,
            max_history=getattr(cfg.env, "max_history", 6),  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
            backend=getattr(cfg.scorer, "backend", "azure"),
            decay_factor=getattr(cfg.scorer, "decay_factor", 1.5),
            debug=getattr(cfg.env, "debug", False),
            reward_backend=getattr(cfg.env, "reward_backend", "rule"),
            evaluation_horizon=getattr(cfg.env, "evaluation_horizon", 3),
            time_penalty=getattr(cfg.env, "time_penalty", 0.01),
            terminal_bonus=getattr(cfg.env, "terminal_bonus", 0.25),
            intervention_cost=getattr(cfg.env, "intervention_cost", 0.02),
        )

        # çµ±è¨ˆæƒ…å ±
        self.session_stats: List[Dict[str, Any]] = []

    def _init_gpt5_client(self, cfg):
        """GPT5ï¼ˆAzure OpenAIï¼‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        llm_cfg = getattr(cfg, "llm", None)
        self.client, self.deployment = get_azure_chat_completion_client(llm_cfg)
        if not self.client or not self.deployment:
            raise RuntimeError("Azure OpenAI client could not be initialized")
        print(f"âœ“ GPT5ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† (deployment: {self.deployment})")

    def _init_local_client(self, cfg):
        """ãƒ­ãƒ¼ã‚«ãƒ«å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM
            import torch
        except ImportError:
            raise RuntimeError("transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install transformers torch")

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆconfigã‹ã‚‰ï¼‰
        ppo_cfg = getattr(cfg, "ppo", None)
        if not ppo_cfg:
            raise RuntimeError("config.ppo ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        self.model_name_or_path = getattr(ppo_cfg, "model_name_or_path", None)
        if not self.model_name_or_path:
            raise RuntimeError("config.ppo.model_name_or_path ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        print(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {self.model_name_or_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name_or_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
        )
        self.model.eval()
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†: {self.model_name_or_path}")

    def get_intervention_decision(self, observation: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†

        Args:
            observation: ç’°å¢ƒã‹ã‚‰ã®è¦³æ¸¬ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰

        Returns:
            ä»‹å…¥åˆ¤å®šã®æ•°å­—æ–‡å­—åˆ—ï¼ˆ1-4ï¼‰ã¾ãŸã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®JSONæ–‡å­—åˆ—
        """
        if self.model_type == "gpt5":
            return self._get_gpt5_decision(observation)
        elif self.model_type == "local":
            return self._get_local_decision(observation)
        else:
            return '4'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä»‹å…¥ã—ãªã„

    def _get_gpt5_decision(self, observation: str) -> str:
        """GPT5ã§ä»‹å…¥åˆ¤å®šã‚’è¡Œã†"""
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: æ–°ã—ã„æ•°å­—å½¢å¼
        system_content = """
ã‚ãªãŸã¯ã€ä¼šè©±ãŒä¸å®‰å®šã«ãªã£ã¦ã„ã‚‹ã¨ãã«ã€ãƒ­ãƒœãƒƒãƒˆãŒã©ã®ã‚ˆã†ã«ä»‹å…¥ã™ã‚Œã°é–¢ä¿‚ã‚’å®‰å®šåŒ–ã§ãã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¼šè©±ã¯ä¸‰è€…ï¼ˆA, B, Cï¼‰ã®é–“ã§è¡Œã‚ã‚Œã¦ãŠã‚Šã€ä¸€æ™‚çš„ãªå¯¾ç«‹ã‚„ä¸èª¿å’ŒãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚

å…¥åŠ›ã¨ã—ã¦ã€
- ä¸‰è€…ã®ä¼šè©±æ–‡è„ˆ
- å„ãƒšã‚¢ï¼ˆAB, BC, CAï¼‰ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆ-1ã€œ1ï¼‰
- ä»Šå›ã®ä»‹å…¥å¯¾è±¡è€…ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
- ãã®å¯¾è±¡é–¢ä¿‚ãƒšã‚¢ï¼ˆã‚¨ãƒƒã‚¸ï¼‰
ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚

ã‚ãªãŸã®ç›®çš„ã¯ã€ã“ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒå«ã¾ã‚Œã‚‹é–¢ä¿‚ï¼ˆã‚¨ãƒƒã‚¸ï¼‰ã‚’å®‰å®šåŒ–çŠ¶æ…‹ï¼ˆ+++ã€+--ã€-+-ã€--+ï¼‰ã¸è¿‘ã¥ã‘ã‚‹ãŸã‚ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªä»‹å…¥æˆ¦ç•¥ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã™ã€‚

æˆ¦ç•¥ã®é¸æŠè‚¢ï¼š
1. validate â€” å¯¾è±¡è€…ã®æ„Ÿæƒ…ã‚„æ„è¦‹ã‚’æ‰¿èªã—ã€å¿ƒç†çš„å®‰å…¨æ€§ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
2. bridge â€” å¯¾ç«‹ã™ã‚‹ç›¸æ‰‹ã¨ã®å…±é€šç‚¹ã‚„å”åŠ›ã®è»¸ã‚’è¦‹ã¤ã‘ã€é–¢ä¿‚ã‚’å†æ¥ç¶šã™ã‚‹ã€‚
3. plan â€” å¯¾è±¡è€…ã«æ¬¡ã®è¡Œå‹•ã‚„æ–¹é‡ã‚’ç¤ºã—ã€å‰å‘ããªé–¢ä¿‚æ”¹å–„ã‚’ä¿ƒã™ã€‚
4. no_intervention â€” ã¾ã ä»‹å…¥ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã¯ãªãã€è‡ªç„¶ãªå›å¾©ã‚’è¦‹å®ˆã‚‹ã€‚

å‡ºåŠ›å½¢å¼ï¼š
- æ•°å­—1æ¡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ1, 2, 3, ã¾ãŸã¯ 4ï¼‰
- èª¬æ˜ã‚„è£œè¶³ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
- ä¸ãˆã‚‰ã‚ŒãŸä¼šè©±æ–‡è„ˆãƒ»é–¢ä¿‚ã‚¹ã‚³ã‚¢ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæƒ…å ±ã«åŸºã¥ã„ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚
"""

        messages = [
            {
                "role": "system",
                "content": system_content
            },
            {
                "role": "user",
                "content": observation
            }
        ]

        max_attempts = 3
        for attempt in range(1, max_attempts + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=messages,
                )

                if response and hasattr(response, "choices") and response.choices:
                    message = response.choices[0].message
                    content = message.content if hasattr(message, "content") else ""
                    if content:
                        # ç”Ÿã®å‡ºåŠ›ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«è¡¨ç¤º
                        if self.verbose:
                            print(f"\nğŸ¤– GPT5ç”Ÿå‡ºåŠ›:")
                            print("-" * 80)
                            print(content)
                            print("-" * 80)
                        
                        # æ•°å­—ã‚’æŠ½å‡ºï¼ˆ1-4ã®ã„ãšã‚Œã‹ï¼‰
                        content = content.strip()
                        
                        # æ•°å­—ã®ã¿ã‚’æ¢ã™
                        for char in content:
                            if char in '1234':
                                return char

                        return content
            except Exception as e:
                if self.verbose:
                    print(f"[GPT5] ä»‹å…¥åˆ¤å®šè©¦è¡Œ {attempt}/{max_attempts} å¤±æ•—: {e}")
                if attempt < max_attempts:
                    time.sleep(0.5 * attempt)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»‹å…¥ã—ãªã„åˆ¤å®šã‚’è¿”ã™
        return '4'

    def _get_local_decision(self, observation: str) -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆQwen3ãªã©ï¼‰ã§ä»‹å…¥åˆ¤å®šã‚’è¡Œã†"""
        import torch
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: æ–°ã—ã„æ•°å­—å½¢å¼
        system_content = """
ã‚ãªãŸã¯ã€ä¼šè©±ãŒä¸€æ™‚çš„ã«ä¸å®‰å®šã«ãªã£ã¦ã„ã‚‹å ´é¢ã§ã€ãƒ­ãƒœãƒƒãƒˆãŒã©ã®ã‚ˆã†ãªä»‹å…¥ã‚’è¡Œãˆã°ã€ã¾ãŸã¯è¡Œã‚ãªã„ã“ã¨ã§ã€æœ€ã‚‚è‰¯ã„çµæœï¼ˆé–¢ä¿‚ã®å®‰å®šåŒ–ï¼‰ã‚’å°ã‘ã‚‹ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
ä¼šè©±ã«ã¯æ„Ÿæƒ…ã®ã‚ºãƒ¬ã‚„å¯¾ç«‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€çŠ¶æ³ã«ã‚ˆã£ã¦ã¯äººé–“åŒå£«ãŒè‡ªç„¶ã«å›å¾©ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚
ã—ãŸãŒã£ã¦ã€å¿…ãšã—ã‚‚ãƒ­ãƒœãƒƒãƒˆãŒç™ºè¨€ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
ä¼šè©±ã¯ä¸‰è€…ï¼ˆA, B, Cï¼‰ã®é–“ã§è¡Œã‚ã‚Œã¦ãŠã‚Šã€ä¸€æ™‚çš„ãªå¯¾ç«‹ã‚„ä¸èª¿å’ŒãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚

å…¥åŠ›ã¨ã—ã¦ã€
- ä¸‰è€…ã®ä¼šè©±æ–‡è„ˆ
- å„ãƒšã‚¢ï¼ˆAB, BC, CAï¼‰ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆ-1ã€œ1ï¼‰
- ä»Šå›ã®ä»‹å…¥å¯¾è±¡è€…ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
- ãã®å¯¾è±¡é–¢ä¿‚ãƒšã‚¢ï¼ˆã‚¨ãƒƒã‚¸ï¼‰
ãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚

ã‚ãªãŸã®ç›®çš„ã¯ã€ã“ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒå«ã¾ã‚Œã‚‹é–¢ä¿‚ï¼ˆã‚¨ãƒƒã‚¸ï¼‰ã‚’ã‚ˆã‚Šå®‰å®š(+)ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã«ã€ã€Œä»Šã“ã®ç¬é–“ã«ã©ã®æˆ¦ç•¥ã‚’é¸ã¶ã“ã¨ãŒæœ€ã‚‚åŠ¹æœçš„ã‹ã€ã‚’åˆ¤æ–­ã™ã‚‹ã“ã¨ã§ã™ã€‚

æˆ¦ç•¥ã®é¸æŠè‚¢ï¼š
1. validate â€” å¯¾è±¡è€…ã®æ„Ÿæƒ…ã‚„æ„è¦‹ã‚’æ‰¿èªã—ã€å¿ƒç†çš„å®‰å…¨æ€§ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
2. bridge â€” å¯¾ç«‹ã™ã‚‹ç›¸æ‰‹ã¨ã®å…±é€šç‚¹ã‚„å”åŠ›ã®è»¸ã‚’è¦‹ã¤ã‘ã€é–¢ä¿‚ã‚’å†æ¥ç¶šã™ã‚‹ã€‚
3. plan â€” å¯¾è±¡è€…ã«æ¬¡ã®è¡Œå‹•ã‚„æ–¹é‡ã‚’ç¤ºã—ã€å‰å‘ããªé–¢ä¿‚æ”¹å–„ã‚’ä¿ƒã™ã€‚
4. no_intervention â€” å¯¾ç«‹ãŒè»½åº¦ã§ã€ä»‹å…¥ãŒé€†åŠ¹æœã«ãªã‚Šãã†ãªã¨ãã‚„è‡ªç„¶å›å¾©ãŒè¦‹è¾¼ã‚ã‚‹æ™‚ã«é¸ã¶ã€‚

å‡ºåŠ›å½¢å¼ï¼š
- æ•°å­—1æ¡ã¨ç†ç”±ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ1, 2, 3, 4ï¼‰
- ç†ç”±ã¯æ–‡è„ˆã«æ²¿ã£ãŸã‚‚ã®ã¨ã—ã¦ãã ã•ã„
- èª¬æ˜ã‚„è£œè¶³ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
- ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›æƒ…å ±ã«åŸºã¥ã„ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ä¾‹
1,ç†ç”±ï¼šã€œ
2,ç†ç”±ï¼šã€œ
3,ç†ç”±ï¼šã€œ
4,ç†ç”±ï¼šã€œ
"""
        
        # Qwen3ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã®ã¿ã€\no_thinkã‚’è¿½åŠ 
        if hasattr(self, 'model_name_or_path') and self.model_name_or_path and "Qwen3" in self.model_name_or_path:
            system_content = "\\no_think\n" + system_content
        
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": observation}
        ]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        
        try:
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **model_inputs,
                    max_new_tokens=256,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.95,
                )
            
            generated_ids = [
                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            
            response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
            
            # ç”Ÿã®å‡ºåŠ›ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«è¡¨ç¤º
            if self.verbose:
                print(f"\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ç”Ÿå‡ºåŠ›:")
                print("-" * 80)
                print(response)
                print("-" * 80)
            
            # æ•°å­—ã‚’æŠ½å‡ºï¼ˆ1-4ã®ã„ãšã‚Œã‹ï¼‰
            response = response.strip()
            
            # æ•°å­—ã®ã¿ã‚’æ¢ã™
            for char in response:
                if char in '1234':
                    return char
            
            return response
            
        except Exception as e:
            if self.verbose:
                print(f"[ãƒ­ãƒ¼ã‚«ãƒ«] ä»‹å…¥åˆ¤å®šå¤±æ•—: {e}")
            return '4'

    def run_session(self, session_id: int) -> Dict[str, Any]:
        """
        1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆæƒ…å ±
        """
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} é–‹å§‹ (ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()})")
        print("=" * 80)

        # ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ
        observation = self.env.reset()

        print(f"\nğŸ“Œ è©±é¡Œ: {self.env.current_topic}")
        print(f"ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ: {', '.join(self.env.persona_pool)}")

        # åˆæœŸä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ï¼‰
        print(f"\nğŸ’¬ åˆæœŸä¼šè©±å±¥æ­´ï¼ˆreset()ã§ç”Ÿæˆã€ã‚¹ãƒ†ãƒƒãƒ—1ã®å…¥åŠ›ï¼‰:")
        from utils.log_filtering import filter_logs_by_human_count
        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.intervention_max_history, exclude_robot=False)
        for i, entry in enumerate(filtered_logs, 1):
            speaker = entry.get("speaker", "?")
            utterance = entry.get("utterance", "")
            print(f"  {i}. [{speaker}] {utterance}")

        # åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
        print(f"\nğŸ“Š åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§:")
        human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
        if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
            try:
                from utils.log_filtering import filter_logs_by_human_count
                participants = [p for p in self.env.persona_pool if p][:3]
                if len(participants) == 3:
                    filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                    scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                    from network_metrics import analyze_relations_from_scores
                    metrics = analyze_relations_from_scores(scores, participants)
                    print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {metrics.get('unstable_triads', '?')}")
                    edges = metrics.get("edges", {})
                    if edges:
                        print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                        for (p1, p2), score in sorted(edges.items()):
                            edge_name = f"{p1}{p2}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")
            except Exception as e:
                print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
        else:
            print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

        print("-" * 80)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        total_reward = 0.0
        interventions = 0
        steps_taken = 0
        conversation_log: List[Dict[str, Any]] = []
        
        # ä»‹å…¥æˆ¦ç•¥ã®çµ±è¨ˆ
        strategy_counts = {
            'validate': 0,
            'bridge': 0,
            'plan': 0,
            'no_intervention': 0
        }
        llm_inference_count = 0  # LLMã§æ¨è«–ã—ãŸå›æ•°ï¼ˆå®‰å®šçŠ¶æ…‹ã‚’é™¤ãï¼‰
        stable_skip_count = 0     # å®‰å®šçŠ¶æ…‹ã§ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå›æ•°

        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåˆæœŸçŠ¶æ…‹ç”¨ï¼‰
        previous_step_rel = None

        # ã‚¹ãƒ†ãƒƒãƒ—ãƒ«ãƒ¼ãƒ—
        done = False
        step = 0
        while not done:
            step += 1
            print(f"\n{'='*80}")
            print(f"ğŸ”¹ ã‚¹ãƒ†ãƒƒãƒ— {step}/{self.env.max_steps}")
            print(f"{'='*80}")

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ï¼ˆstep()å®Ÿè¡Œå‰ï¼‰ã®ä¼šè©±ãƒ­ã‚°ã‚’ä¿å­˜
            logs_before_step = [dict(entry) for entry in self.env.logs]

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤ºï¼ˆå‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ä½¿ç”¨ï¼‰
            is_stable_now = False
            if previous_step_rel is not None:
                # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
                unstable_triads = previous_step_rel.get('unstable_triads', 0)
                is_stable_now = unstable_triads == 0
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—1ã®å ´åˆã€åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡
                human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
                    try:
                        from utils.log_filtering import filter_logs_by_human_count
                        participants = [p for p in self.env.persona_pool if p][:3]
                        if len(participants) == 3:
                            filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                            scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                            from network_metrics import analyze_relations_from_scores
                            metrics = analyze_relations_from_scores(scores, participants)
                            unstable_triads = metrics.get('unstable_triads', 0)
                            is_stable_now = unstable_triads == 0
                            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {unstable_triads}")
                            edges = metrics.get("edges", {})
                            if edges:
                                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                                for (p1, p2), score in sorted(edges.items()):
                                    edge_name = f"{p1}{p2}"
                                    if score > 0.5:
                                        emoji = "ğŸ˜Š"
                                    elif score > 0:
                                        emoji = "ğŸ™‚"
                                    elif score > -0.5:
                                        emoji = "ğŸ˜"
                                    else:
                                        emoji = "ğŸ˜ "
                                    print(f"    {edge_name}: {score:+.3f} {emoji}")
                    except Exception as e:
                        print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
                else:
                    print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

            # å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ä»‹å…¥åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
            if is_stable_now:
                stable_skip_count += 1
                if self.verbose:
                    print(f"\nâ­ï¸  å®‰å®šçŠ¶æ…‹ã®ãŸã‚ä»‹å…¥åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—")
            else:
                # LLMã§æ¨è«–ã‚’å®Ÿè¡Œ
                llm_inference_count += 1
                
                # è¦³æ¸¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º
                if self.verbose:
                    print(f"\nğŸ“ è¦³æ¸¬æƒ…å ±ï¼ˆ{self.model_type.upper()}ã¸ã®å…¥åŠ›ï¼‰:")
                    print("-" * 80)
                    # ä¼šè©±å±¥æ­´éƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ï¼‰
                    if "å±¥æ­´:" in observation:
                        history_section = observation.split("å±¥æ­´:")[1].split("ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢")[0].strip()
                        history_lines = [line for line in history_section.split("\n") if line.strip()]

                        # ä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        from utils.log_filtering import filter_logs_by_human_count
                        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.intervention_max_history, exclude_robot=False)

                        print("  ä¼šè©±å±¥æ­´:")
                        for entry in filtered_logs:
                            speaker = entry.get("speaker", "?")
                            utterance = entry.get("utterance", "")
                            print(f"    [{speaker}] {utterance}")
                    # é–¢ä¿‚ã‚¹ã‚³ã‚¢éƒ¨åˆ†ã‚’æŠ½å‡º
                    if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in observation:
                        score_line = [line for line in observation.split("\n") if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in line]
                        if score_line:
                            print(f"  {score_line[0]}")
                    if "ã‚¨ãƒƒã‚¸" in observation:
                        edge_line = [line for line in observation.split("\n") if "ã‚¨ãƒƒã‚¸" in line]
                        if edge_line:
                            print(f"  {edge_line[0]}")
                    if "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ" in observation:
                        target_line = [line for line in observation.split("\n") if "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ" in line]
                        if target_line:
                            print(f"  {target_line[0]}")
                    print("-" * 80)

                # ãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®š
                action = self.get_intervention_decision(observation)
                
                # æˆ¦ç•¥ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                strategy_map = {
                    '1': 'validate',
                    '2': 'bridge',
                    '3': 'plan',
                    '4': 'no_intervention'
                }
                strategy = strategy_map.get(action.strip(), 'no_intervention')
                if strategy in strategy_counts:
                    strategy_counts[strategy] += 1

            # ä»‹å…¥åˆ¤å®šçµæœã‚’è¡¨ç¤ºï¼ˆå®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if self.verbose and not is_stable_now:
                print(f"\nğŸ¤– {self.model_type.upper()}ä»‹å…¥åˆ¤å®šçµæœ:")
                # æ•°å­—å½¢å¼ï¼ˆ1-4ï¼‰ã§å‡ºåŠ›ã•ã‚Œã‚‹
                strategy_map = {
                    '1': 'validate',
                    '2': 'bridge',
                    '3': 'plan',
                    '4': 'no_intervention'
                }
                strategy = strategy_map.get(action.strip(), 'unknown')
                
                if strategy == 'no_intervention':
                    print(f"  ä»‹å…¥åˆ¤å®š: âŒ ä»‹å…¥ã—ãªã„ (4)")
                elif strategy != 'unknown':
                    print(f"  ä»‹å…¥åˆ¤å®š: âœ… ä»‹å…¥ã™ã‚‹")
                    print(f"  æˆ¦ç•¥: {strategy} ({action.strip()})")
                    print(f"\n  â¡ï¸  ã“ã®åˆ¤å®šã«åŸºã¥ãã€step()å†…ã§ãƒ­ãƒœãƒƒãƒˆç™ºè©±ãŒç”Ÿæˆã•ã‚Œã¾ã™")
                    print(f"      edge_to_change ã¨ target_speaker ã¯ç’°å¢ƒå´ã§è‡ªå‹•æ±ºå®šã•ã‚Œã¾ã™")
                else:
                    print(f"  âš ï¸ ä¸æ˜ãªå‡ºåŠ›: {action}")

            # ç’°å¢ƒã§ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            print(f"\nâš™ï¸  ç’°å¢ƒstep()ã‚’å®Ÿè¡Œä¸­...")
            print(f"   â†’ step()ã®å†…éƒ¨å‡¦ç†:")
            print(f"      1. äººé–“ç™ºè©±ç”Ÿæˆ: ã‚¹ãƒ†ãƒƒãƒ—1ã¾ãŸã¯å‰ã‚¹ãƒ†ãƒƒãƒ—ã§ä»‹å…¥ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã€ãã‚Œä»¥å¤–ã¯1äººé–“ç™ºè©±ç”Ÿæˆ")
            print(f"      2. é–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆå®‰å®šãªã‚‰æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
            print(f"      3. ä¸å®‰å®šãªã‚‰ä»‹å…¥åˆ¤å®šå®Ÿè¡Œ")
            print(f"      4. ä»‹å…¥ã™ã‚‹å ´åˆ:")
            print(f"         - ãƒ­ãƒœãƒƒãƒˆç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
            print(f"         - å®‰å®šé”æˆæ™‚: æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯")
            print(f"      5. å ±é…¬è¨ˆç®—ã—ã¦è¿”å´")
            observation, reward, done, info = self.env.step(action)

            total_reward += reward
            steps_taken += 1
            if info.get("intervened", False):
                interventions += 1

            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œä¸­ã«ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ã‚’è¡¨ç¤º
            print(f"\nğŸ’¬ ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ï¼ˆstep()ã®å®Ÿè¡Œçµæœï¼‰:")
            print("-" * 80)

            # ã‚¹ãƒ†ãƒƒãƒ—å‰å¾Œã®å·®åˆ†ã‚’è¨ˆç®—
            new_entries = self.env.logs[len(logs_before_step):]

            if not new_entries:
                print("  ï¼ˆæ–°ã—ã„ç™ºè©±ãªã—ï¼‰")
            else:
                # å®Ÿéš›ã®ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                human_count = 0
                robot_count = 0
                for entry in new_entries:
                    speaker = entry.get("speaker", "ä¸æ˜")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        robot_count += 1
                    else:
                        human_count += 1

                # ä»‹å…¥ã—ãŸå ´åˆã¨ãã†ã§ãªã„å ´åˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
                if info.get("intervened", False):
                    print(f"  âœ… ä»‹å…¥ã‚ã‚Šï¼ˆåˆè¨ˆ{len(new_entries)}ç™ºè©±ï¼‰:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    print(f"     - ãƒ­ãƒœãƒƒãƒˆ: {robot_count}ç™ºè©±")
                    print(f"       â€»ãƒ­ãƒœãƒƒãƒˆ1ç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
                    print(f"        å®‰å®šé”æˆæ™‚ã¯æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã¯1ãƒ©ã‚¦ãƒ³ãƒ‰=3äººé–“ç™ºè©±ãŒæœ€å°å˜ä½ï¼‰")
                    print()
                else:
                    print(f"  âŒ ä»‹å…¥ãªã—:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    if step == 1:
                        print(f"       â€»ã‚¹ãƒ†ãƒƒãƒ—1ã¯ç™ºè©±ãªã—ï¼ˆreset()ã§ç”Ÿæˆæ¸ˆã¿ï¼‰ã€å®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³")
                    else:
                        print(f"       â€»1äººé–“ç™ºè©±ã®ã¿ï¼ˆå®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
                    print()

                # ç™ºè©±å†…å®¹ã‚’è¡¨ç¤º
                for i, entry in enumerate(new_entries, 1):
                    speaker = entry.get("speaker", "ä¸æ˜")
                    utterance = entry.get("utterance", "")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        print(f"\n  {i}. ğŸ¤– ã€ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ç™ºè©±ã€‘")
                        print(f"     æˆ¦ç•¥: {info.get('plan', {}).get('strategy', 'N/A') if info.get('plan') else 'N/A'}")
                        print(f"     ç™ºè©±: {utterance}")
                        print()
                    else:
                        print(f"  {i}. ğŸ‘¤ [{speaker}] {utterance}")

                # ç™ºè©±æ•°ã®ã‚µãƒãƒªãƒ¼
                print(f"\n  ğŸ“Š ç™ºè©±æ•°ã‚µãƒãƒªãƒ¼: äººé–“ {human_count}ç™ºè©±, ãƒ­ãƒœãƒƒãƒˆ {robot_count}ç™ºè©±, åˆè¨ˆ {len(new_entries)}ç™ºè©±")

            # evaluation_horizonå¾Œã®é–¢ä¿‚æ€§ï¼ˆä»‹å…¥ã—ã¦å®‰å®šã«ãªã£ãŸå ´åˆã®ã¿ï¼‰
            if info.get("intervened", False) and "rel_after_horizon" in info and info.get('stable_after_horizon', False):
                rel_after = info.get("rel_after_horizon", {})
                print(f"\nğŸ“Š evaluation_horizonå¾Œã®é–¢ä¿‚æ€§:")
                print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel_after.get('unstable_triads', 0)}")
                print(f"  å®‰å®šçŠ¶æ…‹: âœ… ã¯ã„")

                edges_after = rel_after.get("edges", {})
                if edges_after:
                    print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                    edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                    for edge_pair in edge_order:
                        if edge_pair in edges_after:
                            score = edges_after[edge_pair]
                            edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")

            # æœ€çµ‚çš„ãªé–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            rel = info.get("rel", {})
            print(f"\nğŸ“Š æœ€çµ‚çš„ãªé–¢ä¿‚æ€§è©•ä¾¡:")
            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel.get('unstable_triads', 0)}")
            print(f"  å®‰å®šçŠ¶æ…‹: {'âœ… ã¯ã„' if info.get('balanced', False) else 'âŒ ã„ã„ãˆ'}")

            # æ•°å€¤ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            edges = rel.get("edges", {})
            if edges:
                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                for edge_pair in edge_order:
                    if edge_pair in edges:
                        score = edges[edge_pair]
                        edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                        # ã‚¹ã‚³ã‚¢ã‚’è¦–è¦šåŒ–
                        if score > 0.5:
                            emoji = "ğŸ˜Š"
                        elif score > 0:
                            emoji = "ğŸ™‚"
                        elif score > -0.5:
                            emoji = "ğŸ˜"
                        else:
                            emoji = "ğŸ˜ "
                        print(f"    {edge_name}: {score:+.3f} {emoji}")

            # å ±é…¬ã®è©³ç´°
            print(f"\nğŸ’° å ±é…¬:")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {reward:.4f}")
            print(f"  ç´¯ç©å ±é…¬: {total_reward:.4f}")

            reward_breakdown = info.get("reward_breakdown", {})
            if reward_breakdown:
                print(f"  å ±é…¬å†…è¨³:")
                label_map = {
                    "delta_u_flip": "  ğŸ“ˆ é–¢ä¿‚æ€§æ”¹å–„åŠ¹æœ (Î”u_flip)",
                    "counterfactual_u_flip": "  ğŸ”® åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦",
                    "actual_u_flip": "  ğŸ“‰ å®Ÿéš›ã®ä¸å®‰å®šåº¦",
                    "intervention_cost": "  ğŸ’¸ ä»‹å…¥ã‚³ã‚¹ãƒˆ",
                    "time_penalty": "  â±ï¸  æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£",
                    "terminal_bonus": "  ğŸ çµ‚äº†ãƒœãƒ¼ãƒŠã‚¹"
                }
                for key, value in reward_breakdown.items():
                    label = label_map.get(key, f"  {key}")
                    print(f"    {label}: {value:.4f}")

            # åå®Ÿä»®æƒ³æƒ…å ±
            if self.verbose and info.get("counterfactual_u_flip") is not None:
                print(f"\nğŸ”® åå®Ÿä»®æƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
                print(f"  åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦: {info.get('counterfactual_u_flip', 0):.4f}")
                print(f"  å®Ÿéš›ã®ä¸å®‰å®šåº¦: {info.get('actual_u_flip', 0):.4f}")
                print(f"  æ”¹å–„åŠ¹æœ (å·®åˆ†): {info.get('delta_u_flip', 0):.4f}")

            # ä¼šè©±ãƒ­ã‚°ã«è¿½åŠ 
            conversation_log.append({
                "step": step,
                "action": action,
                "reward": reward,
                "intervened": info.get("intervened", False),
                "robot_utterance": info.get("robot_utterance"),
                "replies": info.get("replies", []),
                "balanced": info.get("balanced", False),
                "new_entries": new_entries,
            })

            # ã‚¹ãƒ†ãƒƒãƒ—ã‚µãƒãƒªãƒ¼
            print(f"\n{'â”€'*80}")
            print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ— {step} å®Œäº†")
            print(f"   ä»‹å…¥: {'ã‚ã‚Š' if info.get('intervened', False) else 'ãªã—'}")
            print(f"   å ±é…¬: {reward:.4f}")
            print(f"   ç´¯ç©å ±é…¬: {total_reward:.4f}")
            print(f"   å®‰å®šçŠ¶æ…‹: {'âœ…' if info.get('balanced', False) else 'âŒ'}")
            print(f"{'â”€'*80}")

            # æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã«æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            previous_step_rel = info.get("rel", {})

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} çµ‚äº†")
        print("=" * 80)
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {steps_taken}")
        print(f"ç·ä»‹å…¥å›æ•°: {llm_inference_count} (å®‰å®šçŠ¶æ…‹ã‚¹ã‚­ãƒƒãƒ—: {stable_skip_count}å›)")
        print(f"ç·å ±é…¬: {total_reward:.4f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {total_reward / steps_taken if steps_taken > 0 else 0:.4f}")
        
        # æˆ¦ç•¥ä½¿ç”¨çµ±è¨ˆ
        print(f"\nä»‹å…¥æˆ¦ç•¥ã®ä½¿ç”¨å›æ•°:")
        print(f"  validate: {strategy_counts['validate']}å›")
        print(f"  bridge: {strategy_counts['bridge']}å›")
        print(f"  plan: {strategy_counts['plan']}å›")
        print(f"  no_intervention: {strategy_counts['no_intervention']}å›")

        return {
            "session_id": session_id,
            "topic": self.env.current_topic,
            "total_reward": total_reward,
            "interventions": interventions,
            "steps": steps_taken,
            "average_reward": total_reward / steps_taken if steps_taken > 0 else 0,
            "conversation_log": conversation_log,
            "llm_inference_count": llm_inference_count,
            "stable_skip_count": stable_skip_count,
            "strategy_counts": strategy_counts,
            "interventions": interventions,
            "steps": steps_taken,
            "average_reward": total_reward / steps_taken if steps_taken > 0 else 0,
            "conversation_log": conversation_log,
        }

    def run(self) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        print("=" * 80)
        print(f"{self.model_type.upper()}ä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 80)
        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {self.num_sessions}")
        print(f"max_steps: {self.env.max_steps}")

        start_time = time.time()

        # å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        for i in range(1, self.num_sessions + 1):
            session_stats = self.run_session(i)
            self.session_stats.append(session_stats)

        elapsed_time = time.time() - start_time

        # å…¨ä½“ã®çµ±è¨ˆã‚’å‡ºåŠ›
        self.print_overall_statistics(elapsed_time)

    def print_overall_statistics(self, elapsed_time: float) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print("å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
        print("=" * 80)

        if not self.session_stats:
            print("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        total_rewards = [s["total_reward"] for s in self.session_stats]
        total_interventions = sum(s["interventions"] for s in self.session_stats)
        total_steps = sum(s["steps"] for s in self.session_stats)
        total_llm_inferences = sum(s["llm_inference_count"] for s in self.session_stats)
        total_stable_skips = sum(s["stable_skip_count"] for s in self.session_stats)
        
        # æˆ¦ç•¥çµ±è¨ˆã‚’é›†è¨ˆ
        total_strategy_counts = {
            'validate': 0,
            'bridge': 0,
            'plan': 0,
            'no_intervention': 0
        }
        for stat in self.session_stats:
            for strategy, count in stat["strategy_counts"].items():
                total_strategy_counts[strategy] += count

        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(self.session_stats)}")
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
        print(f"ç·ä»‹å…¥å›æ•°: {total_llm_inferences} (å®‰å®šçŠ¶æ…‹ã§ã‚¹ã‚­ãƒƒãƒ—: {total_stable_skips}å›)")
        print(f"  â€»å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ä»‹å…¥åˆ¤å®šLLMã‚’å‘¼ã³å‡ºã•ãšã«ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
        print()
        print(f"ç·å ±é…¬:")
        print(f"  åˆè¨ˆ: {sum(total_rewards):.4f}")
        print(f"  å¹³å‡: {sum(total_rewards) / len(total_rewards):.4f}")
        print(f"  æœ€å¤§: {max(total_rewards):.4f}")
        print(f"  æœ€å°: {min(total_rewards):.4f}")
        print()
        print(f"ä»‹å…¥æˆ¦ç•¥ã®ä½¿ç”¨çµ±è¨ˆ:")
        print(f"  validate: {total_strategy_counts['validate']}å› ({total_strategy_counts['validate']/max(total_llm_inferences,1)*100:.1f}%)")
        print(f"  bridge: {total_strategy_counts['bridge']}å› ({total_strategy_counts['bridge']/max(total_llm_inferences,1)*100:.1f}%)")
        print(f"  plan: {total_strategy_counts['plan']}å› ({total_strategy_counts['plan']/max(total_llm_inferences,1)*100:.1f}%)")
        print(f"  no_intervention: {total_strategy_counts['no_intervention']}å› ({total_strategy_counts['no_intervention']/max(total_llm_inferences,1)*100:.1f}%)")
        print()
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ä»‹å…¥å›æ•°: {total_interventions / len(self.session_stats):.2f}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps / len(self.session_stats):.2f}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ä»‹å…¥å›æ•°: {total_llm_inferences / len(self.session_stats):.2f}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®è©³ç´°
        print("\n" + "-" * 80)
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥è©³ç´°:")
        print("-" * 80)
        for stat in self.session_stats:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {stat['session_id']}:")
            print(f"  è©±é¡Œ: {stat['topic']}")
            print(f"  ç·å ±é…¬: {stat['total_reward']:.4f}")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {stat['steps']}")
            print(f"  ä»‹å…¥å›æ•°: {stat['llm_inference_count']} (å®‰å®šã‚¹ã‚­ãƒƒãƒ—: {stat['stable_skip_count']}å›)")
            
            # æˆ¦ç•¥ä½¿ç”¨çµ±è¨ˆ
            strategy_counts = stat['strategy_counts']
            total_inferences = stat['llm_inference_count']
            if total_inferences > 0:
                print(f"  æˆ¦ç•¥ä½¿ç”¨:")
                print(f"    validate: {strategy_counts['validate']}å› ({strategy_counts['validate']/total_inferences*100:.1f}%)")
                print(f"    bridge: {strategy_counts['bridge']}å› ({strategy_counts['bridge']/total_inferences*100:.1f}%)")
                print(f"    plan: {strategy_counts['plan']}å› ({strategy_counts['plan']/total_inferences*100:.1f}%)")
                print(f"    no_intervention: {strategy_counts['no_intervention']}å› ({strategy_counts['no_intervention']/total_inferences*100:.1f}%)")
            print()


def main():
    parser = argparse.ArgumentParser(
        description="è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=["gpt5", "local"],
        default="gpt5",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt5)",
    )
    parser.add_argument(
        "--num-sessions",
        type=int,
        default=5,
        help="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)",
    )
    parser.add_argument(
        "--max-steps",
        type=int,
        default=8,
        help="1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8)",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="è©³ç´°ãªå‡ºåŠ›ã‚’æŠ‘åˆ¶",
    )

    args = parser.parse_args()

    try:
        simulator = InterventionSimulator(
            model_type=args.model,
            max_steps=args.max_steps,
            num_sessions=args.num_sessions,
            verbose=not args.quiet,
        )
        simulator.run()
    except KeyboardInterrupt:
        print("\n\nã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
