#!/usr/bin/env python3
"""
è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

GPT5ï¼ˆAzure OpenAIï¼‰ã¾ãŸã¯Qwen3ã®å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®šã—ãŸæ™‚ã®
å ±é…¬ã‚„ä¼šè©±ã®æ§˜å­ã‚’ç¢ºèªã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

ä½¿ç”¨æ–¹æ³•:
    # GPT5ã‚’ä½¿ç”¨
    python simulate_intervention.py --model gpt5 --num-sessions 5
    
    # Qwen3å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    python simulate_intervention.py --model qwen3 --num-sessions 5
"""

from __future__ import annotations

import argparse
import json
import sys
import time
from typing import Any, Dict, List, Optional

from azure_clients import get_azure_chat_completion_client
from config import get_config
from env.convo_env import ConversationEnv


class InterventionSimulator:
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""

    def __init__(
        self,
        model_type: str = "gpt5",
        max_steps: int = 6,
        num_sessions: int = 5,
        verbose: bool = True,
    ):
        """
        Args:
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt5" ã¾ãŸã¯ "qwen3")
            max_steps: 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
            num_sessions: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°
            verbose: è©³ç´°ãªå‡ºåŠ›ã‚’è¡Œã†ã‹ã©ã†ã‹
        """
        self.model_type = model_type.lower()
        self.max_steps = max_steps
        self.num_sessions = num_sessions
        self.verbose = verbose

        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        cfg = get_config()

        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if self.model_type == "gpt5":
            self._init_gpt5_client(cfg)
        elif self.model_type == "qwen3":
            self._init_qwen3_client(cfg)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}")

        # ç’°å¢ƒã‚’åˆæœŸåŒ–
        personas = getattr(cfg.env, "personas", {})
        
        # max_stepsã‚’æ˜ç¤ºçš„ã«è¨­å®š
        # max_roundsã¯ä½¿ç”¨ã›ãšã€max_stepsã§çµ‚äº†æ¡ä»¶ã‚’åˆ¶å¾¡
        # max_historyã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ¸¡ã™ãŒã€envå†…éƒ¨ã§æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å„ªå…ˆã™ã‚‹
        self.env = ConversationEnv(
            max_steps=max_steps,
            personas=personas,
            include_robot=True,
            max_history=getattr(cfg.env, "max_history", 6),  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
            backend=getattr(cfg.scorer, "backend", "azure"),
            decay_factor=getattr(cfg.scorer, "decay_factor", 1.5),
            debug=getattr(cfg.env, "debug", False),
            reward_backend=getattr(cfg.env, "reward_backend", "rule"),
            evaluation_horizon=getattr(cfg.env, "evaluation_horizon", 3),
            time_penalty=getattr(cfg.env, "time_penalty", 0.01),
            terminal_bonus=getattr(cfg.env, "terminal_bonus", 0.25),
            intervention_cost=getattr(cfg.env, "intervention_cost", 0.02),
        )

        # çµ±è¨ˆæƒ…å ±
        self.session_stats: List[Dict[str, Any]] = []

    def _init_gpt5_client(self, cfg):
        """GPT5ï¼ˆAzure OpenAIï¼‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        llm_cfg = getattr(cfg, "llm", None)
        self.client, self.deployment = get_azure_chat_completion_client(llm_cfg)
        if not self.client or not self.deployment:
            raise RuntimeError("Azure OpenAI client could not be initialized")
        print(f"âœ“ GPT5ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† (deployment: {self.deployment})")

    def _init_qwen3_client(self, cfg):
        """Qwen3å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM
            import torch
        except ImportError:
            raise RuntimeError("transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install transformers torch")

        # Qwen3ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆconfigã‹ã‚‰ï¼‰
        ppo_cfg = getattr(cfg, "ppo", None)
        if not ppo_cfg:
            raise RuntimeError("config.ppo ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        model_path = getattr(ppo_cfg, "model_name_or_path", None)
        if not model_path:
            raise RuntimeError("config.ppo.model_name_or_path ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        print(f"ğŸ”„ Qwen3ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
        )
        self.model.eval()
        print(f"âœ“ Qwen3ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    def get_intervention_decision(self, observation: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†

        Args:
            observation: ç’°å¢ƒã‹ã‚‰ã®è¦³æ¸¬ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰

        Returns:
            ä»‹å…¥åˆ¤å®šã®JSONæ–‡å­—åˆ—
        """
        if self.model_type == "gpt5":
            return self._get_gpt5_decision(observation)
        elif self.model_type == "qwen3":
            return self._get_qwen3_decision(observation)
        else:
            return '{"intervene_now": false}'

    def _get_gpt5_decision(self, observation: str) -> str:
        """GPT5ã§ä»‹å…¥åˆ¤å®šã‚’è¡Œã†"""
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: å›ºå®šèª¬æ˜ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é›†ç´„
        system_content = """ã‚ãªãŸã¯é–¢ä¿‚æ€§ã‚’å®‰å®šã•ã›ã‚‹ãƒ­ãƒœãƒƒãƒˆã®ä»‹å…¥è¨ˆç”»ã‚’ææ¡ˆã™ã‚‹AIã§ã™ã€‚

ä¸‰è€…ä¼šè©±ï¼ˆè©±è€… A/B/Cï¼‰ã®é–¢ä¿‚ã‚’å®‰å®šåŒ–ã™ã‚‹ãŸã‚ã€ãƒ­ãƒœãƒƒãƒˆãŒé©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ä¸€è¨€ä»‹å…¥ã—ã¾ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ä¼šè©±å±¥æ­´ã¨å„ãƒšã‚¢ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆ-1..1ï¼‰ã‚’å—ã‘å–ã‚Šã€
ã€Œã§ãã‚‹ã ã‘æ—©ãé–¢ä¿‚æ€§ã‚’å®‰å®šçŠ¶æ…‹ï¼ˆ+++,+--,-+-,--+ï¼‰ã«ã™ã‚‹ã€ãŸã‚ã®ä»‹å…¥æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã™ã€‚
â€»ãƒ­ãƒœãƒƒãƒˆã®å®Ÿéš›ã®ç™ºè©±æ–‡ã¯åˆ¥LLMãŒç”Ÿæˆã—ã¾ã™ã€‚ã‚ãªãŸã¯ä»‹å…¥æ–¹æ³•ã ã‘ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

åˆ¶ç´„:
- å‡ºåŠ›ã¯ JSON ã®ã¿ã€‚èª¬æ˜ã‚„è£…é£¾ã¯ç¦æ­¢ã€‚
- intervene_now ã¯ä»Šã™ãä»‹å…¥ã™ã¹ãã‹ã‚’è¡¨ã™ã€‚ true|false ã®ã„ãšã‚Œã‹ã€‚
- edge_to_change ã¯ã©ã®é–¢ä¿‚ã‚’å¤‰æ›´ã™ã‚‹ã‹ã‚’è¡¨ã™ã€‚ "AB" | "BC" | "CA" ã®ã„ãšã‚Œã‹ã€‚
- strategy ã¯ä»‹å…¥æˆ¦ç•¥ã‚’è¡¨ã™ã€‚ "plan" | "validate" | "bridge" ã®ã„ãšã‚Œã‹ã€‚
  - "plan": ã€Œã“ã‚Œã‹ã‚‰ã©ã†ã™ã‚‹ã‹ã€ã¨ã„ã†æœªæ¥å¿—å‘ã®è¦–ç‚¹ã‚’æç¤ºã€‚å…·ä½“çš„ãªæ¬¡ã®ä¸€æ­©ã‚„å°ã•ãªè¡Œå‹•æ¡ˆã‚’ç¤ºã—ã€å‰å‘ããªè¡Œå‹•ã‚’ä¿ƒã™
  - "validate": å¯¾è±¡è€…ã®æ„Ÿæƒ…ãƒ»æ„è¦‹ã‚’æ‰¿èªã—ã€å¿ƒç†çš„å®‰å…¨æ€§ã‚’æ§‹ç¯‰
  - "bridge": å¯¾ç«‹ã™ã‚‹è€…ã®å…±é€šç‚¹ãƒ»ç›®æ¨™ã‚’æ˜ç¤ºã—ã€å”åŠ›é–¢ä¿‚ã‚’æ§‹ç¯‰
  â€»ã©ã®æˆ¦ç•¥ã‚’ã„ã¤ä½¿ã†ã‹ã¯ä¼šè©±æ–‡è„ˆã‚„é–¢ä¿‚ã‚¹ã‚³ã‚¢ã‹ã‚‰åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
- target_speaker ã¯ãã®ä»‹å…¥ã‚’èª°ã«å‘ã‘ã‚‹ã‹ã‚’è¡¨ã™ã€‚ edge_to_changeã§é¸ã‚“ã äººç‰©ã®ã„ãšã‚Œã‹ã€‚ï¼ˆ"AB"â†’"A" | "B"ã€"BC"â†’"B" | "C"ã€"CA"â†’"C" | "A"ï¼‰ ã€‚

å‡ºåŠ›ä¾‹(ã‚ãã¾ã§ä¾‹ã§ã™ã€‚36é€šã‚Šã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚Šã¾ã™):
{"intervene_now": true, "edge_to_change": "AB", "strategy": "validate", "target_speaker": "A"}
{"intervene_now": true, "edge_to_change": "BC", "strategy": "bridge", "target_speaker": "B"}
{"intervene_now": true, "edge_to_change": "CA", "strategy": "plan", "target_speaker": "C"}
{"intervene_now": false}
"""

    user_content = f"""
ä¼šè©±å±¥æ­´:
{history_text}
"""

        messages = [
            {
                "role": "system",
                "content": system_content
            },
            {
                "role": "user",
                "content": observation
            }
        ]

        max_attempts = 3
        for attempt in range(1, max_attempts + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=messages,
                )

                if response and hasattr(response, "choices") and response.choices:
                    message = response.choices[0].message
                    content = message.content if hasattr(message, "content") else ""
                    if content:
                        # ç”Ÿã®å‡ºåŠ›ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«è¡¨ç¤º
                        if self.verbose:
                            print(f"\nğŸ¤– GPT5ç”Ÿå‡ºåŠ›:")
                            print("-" * 80)
                            print(content)
                            print("-" * 80)
                        
                        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                        content = content.strip()
                        
                        # <think>ã‚¿ã‚°ã‚’é™¤å»
                        if "<think>" in content:
                            # </think>ã®å¾Œã‹ã‚‰å–å¾—
                            think_end = content.find("</think>")
                            if think_end != -1:
                                content = content[think_end + 8:].strip()
                        
                        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º
                        if "```json" in content:
                            start = content.find("```json") + 7
                            end = content.find("```", start)
                            if end > start:
                                content = content[start:end].strip()
                        elif "```" in content:
                            start = content.find("```") + 3
                            end = content.find("```", start)
                            if end > start:
                                content = content[start:end].strip()
                        
                        # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥æŠ½å‡ºï¼ˆ{...}ï¼‰
                        if "{" in content and "}" in content:
                            start = content.find("{")
                            end = content.rfind("}") + 1
                            if end > start:
                                content = content[start:end].strip()

                        return content
            except Exception as e:
                if self.verbose:
                    print(f"[GPT5] ä»‹å…¥åˆ¤å®šè©¦è¡Œ {attempt}/{max_attempts} å¤±æ•—: {e}")
                if attempt < max_attempts:
                    time.sleep(0.5 * attempt)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»‹å…¥ã—ãªã„åˆ¤å®šã‚’è¿”ã™
        return '{"intervene_now": false}'

    def _get_qwen3_decision(self, observation: str) -> str:
        """Qwen3å­¦ç¿’å‰ãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®šã‚’è¡Œã†"""
        import torch
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: å›ºå®šèª¬æ˜ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é›†ç´„
        system_content = """ã‚ãªãŸã¯é–¢ä¿‚æ€§ã‚’å®‰å®šã•ã›ã‚‹ãƒ­ãƒœãƒƒãƒˆã®ä»‹å…¥è¨ˆç”»ã‚’ææ¡ˆã™ã‚‹AIã§ã™ã€‚

ä¸‰è€…ä¼šè©±ï¼ˆè©±è€… A/B/Cï¼‰ã®é–¢ä¿‚ã‚’å®‰å®šåŒ–ã™ã‚‹ãŸã‚ã€ãƒ­ãƒœãƒƒãƒˆãŒé©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ä¸€è¨€ä»‹å…¥ã—ã¾ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ä¼šè©±å±¥æ­´ã¨å„ãƒšã‚¢ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆ-1..1ï¼‰ã‚’å—ã‘å–ã‚Šã€
ã€Œã§ãã‚‹ã ã‘æ—©ãé–¢ä¿‚æ€§ã‚’å®‰å®šçŠ¶æ…‹ï¼ˆ+++,+--,-+-,--+ï¼‰ã«ã™ã‚‹ã€ãŸã‚ã®ä»‹å…¥æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã™ã€‚
â€»ãƒ­ãƒœãƒƒãƒˆã®å®Ÿéš›ã®ç™ºè©±æ–‡ã¯åˆ¥LLMãŒç”Ÿæˆã—ã¾ã™ã€‚ã‚ãªãŸã¯ä»‹å…¥æ–¹æ³•ã ã‘ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

åˆ¶ç´„:
- å‡ºåŠ›ã¯ JSON ã®ã¿ã€‚èª¬æ˜ã‚„è£…é£¾ã¯ç¦æ­¢ã€‚
- intervene_now ã¯ä»Šã™ãä»‹å…¥ã™ã¹ãã‹ã‚’è¡¨ã™ã€‚ true|false ã®ã„ãšã‚Œã‹ã€‚
- edge_to_change ã¯ã©ã®é–¢ä¿‚ã‚’å¤‰æ›´ã™ã‚‹ã‹ã‚’è¡¨ã™ã€‚ "AB" | "BC" | "CA" ã®ã„ãšã‚Œã‹ã€‚
- strategy ã¯ä»‹å…¥æˆ¦ç•¥ã‚’è¡¨ã™ã€‚ "plan" | "validate" | "bridge" ã®ã„ãšã‚Œã‹ã€‚
  - "plan": ã€Œã“ã‚Œã‹ã‚‰ã©ã†ã™ã‚‹ã‹ã€ã¨ã„ã†æœªæ¥å¿—å‘ã®è¦–ç‚¹ã‚’æç¤ºã€‚å…·ä½“çš„ãªæ¬¡ã®ä¸€æ­©ã‚„å°ã•ãªè¡Œå‹•æ¡ˆã‚’ç¤ºã—ã€å‰å‘ããªè¡Œå‹•ã‚’ä¿ƒã™
  - "validate": å¯¾è±¡è€…ã®æ„Ÿæƒ…ãƒ»æ„è¦‹ã‚’æ‰¿èªã—ã€å¿ƒç†çš„å®‰å…¨æ€§ã‚’æ§‹ç¯‰
  - "bridge": å¯¾ç«‹ã™ã‚‹è€…ã®å…±é€šç‚¹ãƒ»ç›®æ¨™ã‚’æ˜ç¤ºã—ã€å”åŠ›é–¢ä¿‚ã‚’æ§‹ç¯‰
  â€»ã©ã®æˆ¦ç•¥ã‚’ã„ã¤ä½¿ã†ã‹ã¯ä¼šè©±æ–‡è„ˆã‚„é–¢ä¿‚ã‚¹ã‚³ã‚¢ã‹ã‚‰åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
- target_speaker ã¯ãã®ä»‹å…¥ã‚’èª°ã«å‘ã‘ã‚‹ã‹ã‚’è¡¨ã™ã€‚ edge_to_changeã§é¸ã‚“ã äººç‰©ã®ã„ãšã‚Œã‹ã€‚ï¼ˆ"AB"â†’"A" | "B"ã€"BC"â†’"B" | "C"ã€"CA"â†’"C" | "A"ï¼‰ ã€‚

å‡ºåŠ›ä¾‹(ã‚ãã¾ã§ä¾‹ã§ã™ã€‚36é€šã‚Šã®çµ„ã¿åˆã‚ã›ãŒã‚ã‚Šã¾ã™):
{"intervene_now": true, "edge_to_change": "AB", "strategy": "validate", "target_speaker": "A"}
{"intervene_now": true, "edge_to_change": "BC", "strategy": "bridge", "target_speaker": "B"}
{"intervene_now": true, "edge_to_change": "CA", "strategy": "plan", "target_speaker": "C"}
{"intervene_now": false}
"""
        
        # Qwen3ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€\no_thinkã‚’è¿½åŠ 
        system_content = "\\no_think\n" + system_content
        
        # Qwen3ã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": observation}
        ]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        
        try:
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **model_inputs,
                    max_new_tokens=512,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.95,
                )
            
            generated_ids = [
                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            
            response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
            
            # ç”Ÿã®å‡ºåŠ›ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«è¡¨ç¤º
            if self.verbose:
                print(f"\nğŸ¤– Qwen3ç”Ÿå‡ºåŠ›:")
                print("-" * 80)
                print(response)
                print("-" * 80)
            
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            response = response.strip()
            
            # <think>ã‚¿ã‚°ã‚’é™¤å»
            if "<think>" in response:
                # </think>ã®å¾Œã‹ã‚‰å–å¾—
                think_end = response.find("</think>")
                if think_end != -1:
                    response = response[think_end + 8:].strip()
            
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                if end > start:
                    response = response[start:end].strip()
            elif "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                if end > start:
                    response = response[start:end].strip()
            
            # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥æŠ½å‡ºï¼ˆ{...}ï¼‰
            if "{" in response and "}" in response:
                start = response.find("{")
                end = response.rfind("}") + 1
                if end > start:
                    response = response[start:end].strip()
            
            return response
            
        except Exception as e:
            if self.verbose:
                print(f"[Qwen3] ä»‹å…¥åˆ¤å®šå¤±æ•—: {e}")
            return '{"intervene_now": false}'

    def run_session(self, session_id: int) -> Dict[str, Any]:
        """
        1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆæƒ…å ±
        """
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} é–‹å§‹ (ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()})")
        print("=" * 80)

        # ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ
        observation = self.env.reset()

        print(f"\nğŸ“Œ è©±é¡Œ: {self.env.current_topic}")
        print(f"ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ: {', '.join(self.env.persona_pool)}")

        # åˆæœŸä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ï¼‰
        print(f"\nğŸ’¬ åˆæœŸä¼šè©±å±¥æ­´ï¼ˆreset()ã§ç”Ÿæˆã€ã‚¹ãƒ†ãƒƒãƒ—1ã®å…¥åŠ›ï¼‰:")
        from utils.log_filtering import filter_logs_by_human_count
        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.intervention_max_history, exclude_robot=False)
        for i, entry in enumerate(filtered_logs, 1):
            speaker = entry.get("speaker", "?")
            utterance = entry.get("utterance", "")
            print(f"  {i}. [{speaker}] {utterance}")

        # åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
        print(f"\nğŸ“Š åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§:")
        human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
        if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
            try:
                from utils.log_filtering import filter_logs_by_human_count
                participants = [p for p in self.env.persona_pool if p][:3]
                if len(participants) == 3:
                    filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                    scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                    from network_metrics import analyze_relations_from_scores
                    metrics = analyze_relations_from_scores(scores, participants)
                    print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {metrics.get('unstable_triads', '?')}")
                    edges = metrics.get("edges", {})
                    if edges:
                        print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                        for (p1, p2), score in sorted(edges.items()):
                            edge_name = f"{p1}{p2}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")
            except Exception as e:
                print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
        else:
            print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

        print("-" * 80)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        total_reward = 0.0
        interventions = 0
        steps_taken = 0
        conversation_log: List[Dict[str, Any]] = []

        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåˆæœŸçŠ¶æ…‹ç”¨ï¼‰
        previous_step_rel = None

        # ã‚¹ãƒ†ãƒƒãƒ—ãƒ«ãƒ¼ãƒ—
        done = False
        step = 0
        while not done:
            step += 1
            print(f"\n{'='*80}")
            print(f"ğŸ”¹ ã‚¹ãƒ†ãƒƒãƒ— {step}/{self.env.max_steps}")
            print(f"{'='*80}")

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ï¼ˆstep()å®Ÿè¡Œå‰ï¼‰ã®ä¼šè©±ãƒ­ã‚°ã‚’ä¿å­˜
            logs_before_step = [dict(entry) for entry in self.env.logs]

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤ºï¼ˆå‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ä½¿ç”¨ï¼‰
            is_stable_now = False
            if previous_step_rel is not None:
                # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
                unstable_triads = previous_step_rel.get('unstable_triads', 0)
                is_stable_now = unstable_triads == 0
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—1ã®å ´åˆã€åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡
                human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
                    try:
                        from utils.log_filtering import filter_logs_by_human_count
                        participants = [p for p in self.env.persona_pool if p][:3]
                        if len(participants) == 3:
                            filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                            scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                            from network_metrics import analyze_relations_from_scores
                            metrics = analyze_relations_from_scores(scores, participants)
                            unstable_triads = metrics.get('unstable_triads', 0)
                            is_stable_now = unstable_triads == 0
                            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {unstable_triads}")
                            edges = metrics.get("edges", {})
                            if edges:
                                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                                for (p1, p2), score in sorted(edges.items()):
                                    edge_name = f"{p1}{p2}"
                                    if score > 0.5:
                                        emoji = "ğŸ˜Š"
                                    elif score > 0:
                                        emoji = "ğŸ™‚"
                                    elif score > -0.5:
                                        emoji = "ğŸ˜"
                                    else:
                                        emoji = "ğŸ˜ "
                                    print(f"    {edge_name}: {score:+.3f} {emoji}")
                    except Exception as e:
                        print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
                else:
                    print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

            # å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ä»‹å…¥åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
            if is_stable_now:
                action = '{"intervene_now": false}'
            else:
                # è¦³æ¸¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º
                if self.verbose:
                    print(f"\nğŸ“ è¦³æ¸¬æƒ…å ±ï¼ˆ{self.model_type.upper()}ã¸ã®å…¥åŠ›ï¼‰:")
                    print("-" * 80)
                    # ä¼šè©±å±¥æ­´éƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ï¼‰
                    if "å±¥æ­´:" in observation:
                        history_section = observation.split("å±¥æ­´:")[1].split("ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢")[0].strip()
                        history_lines = [line for line in history_section.split("\n") if line.strip()]

                        # ä»‹å…¥åˆ¤å®šLLMç”¨ã®intervention_max_historyç™ºè©±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        from utils.log_filtering import filter_logs_by_human_count
                        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.intervention_max_history, exclude_robot=False)

                        print("  ä¼šè©±å±¥æ­´:")
                        for entry in filtered_logs:
                            speaker = entry.get("speaker", "?")
                            utterance = entry.get("utterance", "")
                            print(f"    [{speaker}] {utterance}")
                    # é–¢ä¿‚ã‚¹ã‚³ã‚¢éƒ¨åˆ†ã‚’æŠ½å‡º
                    if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in observation:
                        score_line = [line for line in observation.split("\n") if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in line]
                        if score_line:
                            print(f"  {score_line[0]}")
                    print("-" * 80)

                # ãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®š
                action = self.get_intervention_decision(observation)

            # ä»‹å…¥åˆ¤å®šçµæœã‚’è¡¨ç¤ºï¼ˆå®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if self.verbose and not is_stable_now:
                print(f"\nğŸ¤– {self.model_type.upper()}ä»‹å…¥åˆ¤å®šçµæœ:")
                try:
                    action_json = json.loads(action)
                    intervene_now = action_json.get('intervene_now', False)
                    print(f"  ä»‹å…¥åˆ¤å®š: {'âœ… ä»‹å…¥ã™ã‚‹' if intervene_now else 'âŒ ä»‹å…¥ã—ãªã„'}")
                    if intervene_now:
                        print(f"  å¯¾è±¡ã‚¨ãƒƒã‚¸: {action_json.get('edge_to_change', 'N/A')}")
                        print(f"  æˆ¦ç•¥: {action_json.get('strategy', 'N/A')}")
                        print(f"  å¯¾è±¡è©±è€…: {action_json.get('target_speaker', 'N/A')}")
                        if action_json.get('reasoning'):
                            print(f"  ç†ç”±: {action_json['reasoning']}")
                        print(f"\n  â¡ï¸  ã“ã®åˆ¤å®šã«åŸºã¥ãã€step()å†…ã§ãƒ­ãƒœãƒƒãƒˆç™ºè©±ãŒç”Ÿæˆã•ã‚Œã¾ã™")
                except json.JSONDecodeError:
                    print(f"  âš ï¸ JSONè§£æå¤±æ•—: {action[:100]}...")

            # ç’°å¢ƒã§ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            print(f"\nâš™ï¸  ç’°å¢ƒstep()ã‚’å®Ÿè¡Œä¸­...")
            print(f"   â†’ step()ã®å†…éƒ¨å‡¦ç†:")
            print(f"      1. äººé–“ç™ºè©±ç”Ÿæˆ: ã‚¹ãƒ†ãƒƒãƒ—1ã¾ãŸã¯å‰ã‚¹ãƒ†ãƒƒãƒ—ã§ä»‹å…¥ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã€ãã‚Œä»¥å¤–ã¯1äººé–“ç™ºè©±ç”Ÿæˆ")
            print(f"      2. é–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆå®‰å®šãªã‚‰æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
            print(f"      3. ä¸å®‰å®šãªã‚‰ä»‹å…¥åˆ¤å®šå®Ÿè¡Œ")
            print(f"      4. ä»‹å…¥ã™ã‚‹å ´åˆ:")
            print(f"         - ãƒ­ãƒœãƒƒãƒˆç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
            print(f"         - å®‰å®šé”æˆæ™‚: æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯")
            print(f"      5. å ±é…¬è¨ˆç®—ã—ã¦è¿”å´")
            observation, reward, done, info = self.env.step(action)

            total_reward += reward
            steps_taken += 1
            if info.get("intervened", False):
                interventions += 1

            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œä¸­ã«ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ã‚’è¡¨ç¤º
            print(f"\nğŸ’¬ ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ï¼ˆstep()ã®å®Ÿè¡Œçµæœï¼‰:")
            print("-" * 80)

            # ã‚¹ãƒ†ãƒƒãƒ—å‰å¾Œã®å·®åˆ†ã‚’è¨ˆç®—
            new_entries = self.env.logs[len(logs_before_step):]

            if not new_entries:
                print("  ï¼ˆæ–°ã—ã„ç™ºè©±ãªã—ï¼‰")
            else:
                # å®Ÿéš›ã®ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                human_count = 0
                robot_count = 0
                for entry in new_entries:
                    speaker = entry.get("speaker", "ä¸æ˜")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        robot_count += 1
                    else:
                        human_count += 1

                # ä»‹å…¥ã—ãŸå ´åˆã¨ãã†ã§ãªã„å ´åˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
                if info.get("intervened", False):
                    print(f"  âœ… ä»‹å…¥ã‚ã‚Šï¼ˆåˆè¨ˆ{len(new_entries)}ç™ºè©±ï¼‰:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    print(f"     - ãƒ­ãƒœãƒƒãƒˆ: {robot_count}ç™ºè©±")
                    print(f"       â€»ãƒ­ãƒœãƒƒãƒˆ1ç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
                    print(f"        å®‰å®šé”æˆæ™‚ã¯æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã¯1ãƒ©ã‚¦ãƒ³ãƒ‰=3äººé–“ç™ºè©±ãŒæœ€å°å˜ä½ï¼‰")
                    print()
                else:
                    print(f"  âŒ ä»‹å…¥ãªã—:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    if step == 1:
                        print(f"       â€»ã‚¹ãƒ†ãƒƒãƒ—1ã¯ç™ºè©±ãªã—ï¼ˆreset()ã§ç”Ÿæˆæ¸ˆã¿ï¼‰ã€å®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³")
                    else:
                        print(f"       â€»1äººé–“ç™ºè©±ã®ã¿ï¼ˆå®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
                    print()

                # ç™ºè©±å†…å®¹ã‚’è¡¨ç¤º
                for i, entry in enumerate(new_entries, 1):
                    speaker = entry.get("speaker", "ä¸æ˜")
                    utterance = entry.get("utterance", "")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        print(f"\n  {i}. ğŸ¤– ã€ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ç™ºè©±ã€‘")
                        print(f"     æˆ¦ç•¥: {info.get('plan', {}).get('strategy', 'N/A') if info.get('plan') else 'N/A'}")
                        print(f"     ç™ºè©±: {utterance}")
                        print()
                    else:
                        print(f"  {i}. ğŸ‘¤ [{speaker}] {utterance}")

                # ç™ºè©±æ•°ã®ã‚µãƒãƒªãƒ¼
                print(f"\n  ğŸ“Š ç™ºè©±æ•°ã‚µãƒãƒªãƒ¼: äººé–“ {human_count}ç™ºè©±, ãƒ­ãƒœãƒƒãƒˆ {robot_count}ç™ºè©±, åˆè¨ˆ {len(new_entries)}ç™ºè©±")

            # evaluation_horizonå¾Œã®é–¢ä¿‚æ€§ï¼ˆä»‹å…¥ã—ã¦å®‰å®šã«ãªã£ãŸå ´åˆã®ã¿ï¼‰
            if info.get("intervened", False) and "rel_after_horizon" in info and info.get('stable_after_horizon', False):
                rel_after = info.get("rel_after_horizon", {})
                print(f"\nğŸ“Š evaluation_horizonå¾Œã®é–¢ä¿‚æ€§:")
                print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel_after.get('unstable_triads', 0)}")
                print(f"  å®‰å®šçŠ¶æ…‹: âœ… ã¯ã„")

                edges_after = rel_after.get("edges", {})
                if edges_after:
                    print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                    edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                    for edge_pair in edge_order:
                        if edge_pair in edges_after:
                            score = edges_after[edge_pair]
                            edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")

            # æœ€çµ‚çš„ãªé–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            rel = info.get("rel", {})
            print(f"\nğŸ“Š æœ€çµ‚çš„ãªé–¢ä¿‚æ€§è©•ä¾¡:")
            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel.get('unstable_triads', 0)}")
            print(f"  å®‰å®šçŠ¶æ…‹: {'âœ… ã¯ã„' if info.get('balanced', False) else 'âŒ ã„ã„ãˆ'}")

            # æ•°å€¤ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            edges = rel.get("edges", {})
            if edges:
                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                for edge_pair in edge_order:
                    if edge_pair in edges:
                        score = edges[edge_pair]
                        edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                        # ã‚¹ã‚³ã‚¢ã‚’è¦–è¦šåŒ–
                        if score > 0.5:
                            emoji = "ğŸ˜Š"
                        elif score > 0:
                            emoji = "ğŸ™‚"
                        elif score > -0.5:
                            emoji = "ğŸ˜"
                        else:
                            emoji = "ğŸ˜ "
                        print(f"    {edge_name}: {score:+.3f} {emoji}")

            # å ±é…¬ã®è©³ç´°
            print(f"\nğŸ’° å ±é…¬:")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {reward:.4f}")
            print(f"  ç´¯ç©å ±é…¬: {total_reward:.4f}")

            reward_breakdown = info.get("reward_breakdown", {})
            if reward_breakdown:
                print(f"  å ±é…¬å†…è¨³:")
                label_map = {
                    "delta_u_flip": "  ğŸ“ˆ é–¢ä¿‚æ€§æ”¹å–„åŠ¹æœ (Î”u_flip)",
                    "counterfactual_u_flip": "  ğŸ”® åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦",
                    "actual_u_flip": "  ğŸ“‰ å®Ÿéš›ã®ä¸å®‰å®šåº¦",
                    "intervention_cost": "  ğŸ’¸ ä»‹å…¥ã‚³ã‚¹ãƒˆ",
                    "time_penalty": "  â±ï¸  æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£",
                    "terminal_bonus": "  ğŸ çµ‚äº†ãƒœãƒ¼ãƒŠã‚¹"
                }
                for key, value in reward_breakdown.items():
                    label = label_map.get(key, f"  {key}")
                    print(f"    {label}: {value:.4f}")

            # åå®Ÿä»®æƒ³æƒ…å ±
            if self.verbose and info.get("counterfactual_u_flip") is not None:
                print(f"\nğŸ”® åå®Ÿä»®æƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
                print(f"  åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦: {info.get('counterfactual_u_flip', 0):.4f}")
                print(f"  å®Ÿéš›ã®ä¸å®‰å®šåº¦: {info.get('actual_u_flip', 0):.4f}")
                print(f"  æ”¹å–„åŠ¹æœ (å·®åˆ†): {info.get('delta_u_flip', 0):.4f}")

            # ä¼šè©±ãƒ­ã‚°ã«è¿½åŠ 
            conversation_log.append({
                "step": step,
                "action": action,
                "reward": reward,
                "intervened": info.get("intervened", False),
                "robot_utterance": info.get("robot_utterance"),
                "replies": info.get("replies", []),
                "balanced": info.get("balanced", False),
                "new_entries": new_entries,
            })

            # ã‚¹ãƒ†ãƒƒãƒ—ã‚µãƒãƒªãƒ¼
            print(f"\n{'â”€'*80}")
            print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ— {step} å®Œäº†")
            print(f"   ä»‹å…¥: {'ã‚ã‚Š' if info.get('intervened', False) else 'ãªã—'}")
            print(f"   å ±é…¬: {reward:.4f}")
            print(f"   ç´¯ç©å ±é…¬: {total_reward:.4f}")
            print(f"   å®‰å®šçŠ¶æ…‹: {'âœ…' if info.get('balanced', False) else 'âŒ'}")
            print(f"{'â”€'*80}")

            # æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã«æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            previous_step_rel = info.get("rel", {})

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} çµ‚äº†")
        print("=" * 80)
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {steps_taken}")
        print(f"ç·ä»‹å…¥å›æ•°: {interventions}")
        print(f"ç·å ±é…¬: {total_reward:.4f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {total_reward / steps_taken if steps_taken > 0 else 0:.4f}")

        return {
            "session_id": session_id,
            "topic": self.env.current_topic,
            "total_reward": total_reward,
            "interventions": interventions,
            "steps": steps_taken,
            "average_reward": total_reward / steps_taken if steps_taken > 0 else 0,
            "conversation_log": conversation_log,
        }

    def run(self) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        print("=" * 80)
        print(f"{self.model_type.upper()}ä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 80)
        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {self.num_sessions}")
        print(f"max_steps: {self.env.max_steps}")

        start_time = time.time()

        # å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        for i in range(1, self.num_sessions + 1):
            session_stats = self.run_session(i)
            self.session_stats.append(session_stats)

        elapsed_time = time.time() - start_time

        # å…¨ä½“ã®çµ±è¨ˆã‚’å‡ºåŠ›
        self.print_overall_statistics(elapsed_time)

    def print_overall_statistics(self, elapsed_time: float) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print("å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
        print("=" * 80)

        if not self.session_stats:
            print("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        total_rewards = [s["total_reward"] for s in self.session_stats]
        total_interventions = sum(s["interventions"] for s in self.session_stats)
        total_steps = sum(s["steps"] for s in self.session_stats)

        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(self.session_stats)}")
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
        print(f"ç·ä»‹å…¥å›æ•°: {total_interventions}")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
        print()
        print(f"ç·å ±é…¬:")
        print(f"  åˆè¨ˆ: {sum(total_rewards):.4f}")
        print(f"  å¹³å‡: {sum(total_rewards) / len(total_rewards):.4f}")
        print(f"  æœ€å¤§: {max(total_rewards):.4f}")
        print(f"  æœ€å°: {min(total_rewards):.4f}")
        print()
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ä»‹å…¥å›æ•°: {total_interventions / len(self.session_stats):.2f}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps / len(self.session_stats):.2f}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®è©³ç´°
        print("\n" + "-" * 80)
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥è©³ç´°:")
        print("-" * 80)
        for stat in self.session_stats:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {stat['session_id']}:")
            print(f"  è©±é¡Œ: {stat['topic']}")
            print(f"  ç·å ±é…¬: {stat['total_reward']:.4f}")
            print(f"  ä»‹å…¥å›æ•°: {stat['interventions']}")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {stat['steps']}")
            print()


def main():
    parser = argparse.ArgumentParser(
        description="è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=["gpt5", "qwen3"],
        default="gpt5",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt5)",
    )
    parser.add_argument(
        "--num-sessions",
        type=int,
        default=5,
        help="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)",
    )
    parser.add_argument(
        "--max-steps",
        type=int,
        default=8,
        help="1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8)",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="è©³ç´°ãªå‡ºåŠ›ã‚’æŠ‘åˆ¶",
    )

    args = parser.parse_args()

    try:
        simulator = InterventionSimulator(
            model_type=args.model,
            max_steps=args.max_steps,
            num_sessions=args.num_sessions,
            verbose=not args.quiet,
        )
        simulator.run()
    except KeyboardInterrupt:
        print("\n\nã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
