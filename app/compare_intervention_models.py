#!/usr/bin/env python3
"""
ä»‹å…¥åˆ¤å®šãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

GPT5ï¼ˆAzure OpenAIï¼‰ã¨Qwen3å­¦ç¿’å‰å…ƒãƒ¢ãƒ‡ãƒ«ã®ä»‹å…¥åˆ¤å®šæ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
ãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ãƒ†ã‚¹ãƒˆã§ãã‚‹æ±ç”¨çš„ãªãƒ„ãƒ¼ãƒ«ã€‚

ä½¿ç”¨æ–¹æ³•:
    # GPT5ã§ãƒ†ã‚¹ãƒˆ
    python compare_intervention_models.py --model gpt5 --num-sessions 5 --max-steps 6

    # Qwen3å­¦ç¿’å‰å…ƒãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    python compare_intervention_models.py --model qwen3 --num-sessions 5 --max-steps 6
"""

from __future__ import annotations

import argparse
import json
import sys
import time
import torch
from typing import Any, Dict, List, Optional
from pathlib import Path

from azure_clients import get_azure_chat_completion_client
from config import get_config
from env.convo_env import ConversationEnv

# Qwen3ç”¨ã®import
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig


class InterventionModelComparator:
    """ä»‹å…¥åˆ¤å®šãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""

    def __init__(
        self,
        model_type: str = "gpt5",  # "gpt5" or "qwen3"
        max_steps: int = 6,
        num_sessions: int = 5,
        verbose: bool = True,
    ):
        """
        Args:
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("gpt5" or "qwen3")
            max_steps: éæ¨å¥¨ã€‚config.local.yamlã®max_roundsãŒå„ªå…ˆã•ã‚Œã¾ã™ã€‚
            num_sessions: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°
            verbose: è©³ç´°ãªå‡ºåŠ›ã‚’è¡Œã†ã‹ã©ã†ã‹
        """
        self.model_type = model_type.lower()
        self.max_steps = max_steps
        self.num_sessions = num_sessions
        self.verbose = verbose

        if self.model_type not in ["gpt5", "qwen3"]:
            raise ValueError(f"Unsupported model type: {model_type}. Use 'gpt5' or 'qwen3'")

        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        cfg = get_config()

        # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®åˆæœŸåŒ–
        if self.model_type == "gpt5":
            self._init_gpt5(cfg)
        else:  # qwen3
            self._init_qwen3(cfg)

        # ç’°å¢ƒã‚’åˆæœŸåŒ–
        personas = getattr(cfg.env, "personas", {})
        self.env = ConversationEnv(
            max_steps=max_steps,
            personas=personas,
            include_robot=True,
            max_history=getattr(cfg.env, "max_history", 8),
            backend=getattr(cfg.scorer, "backend", "azure"),
            decay_factor=getattr(cfg.scorer, "decay_factor", 1.5),
            debug=getattr(cfg.env, "debug", False),
            reward_backend=getattr(cfg.env, "reward_backend", "rule"),
            evaluation_horizon=getattr(cfg.env, "evaluation_horizon", 3),
            time_penalty=getattr(cfg.env, "time_penalty", 0.01),
            terminal_bonus=getattr(cfg.env, "terminal_bonus", 0.25),
            intervention_cost=getattr(cfg.env, "intervention_cost", 0.02),
        )

        # çµ±è¨ˆæƒ…å ±
        self.session_stats: List[Dict[str, Any]] = []

    def _init_gpt5(self, cfg):
        """GPT5 (Azure OpenAI) ã®åˆæœŸåŒ–"""
        llm_cfg = getattr(cfg, "llm", None)
        self.client, self.deployment = get_azure_chat_completion_client(llm_cfg)
        if not self.client or not self.deployment:
            raise RuntimeError("Azure OpenAI client could not be initialized")

        print(f"âœ… GPT5 (Azure OpenAI) initialized: {self.deployment}")

    def _init_qwen3(self, cfg):
        """Qwen3å­¦ç¿’å‰å…ƒãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        ppo_cfg = getattr(cfg, "ppo", None)
        if not ppo_cfg:
            raise RuntimeError("PPO config not found")

        model_name_or_path = getattr(ppo_cfg, "model_name_or_path", None)
        if not model_name_or_path:
            raise RuntimeError("model_name_or_path not found in ppo config")

        print(f"ğŸ”„ Loading Qwen3 base model: {model_name_or_path}")

        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name_or_path,
            trust_remote_code=True
        )
        if self.tokenizer.pad_token_id is None:
            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
        self.tokenizer.padding_side = "left"

        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆ4bité‡å­åŒ–ï¼‰
        device_map = "auto"
        use_quant = torch.cuda.is_available()

        model_kwargs = {
            "device_map": device_map,
            "trust_remote_code": True,
            "low_cpu_mem_usage": True,
        }

        if use_quant:
            quant_cfg = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.float16,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
            )
            model_kwargs["quantization_config"] = quant_cfg
        else:
            model_kwargs["torch_dtype"] = torch.float16 if torch.cuda.is_available() else torch.float32

        self.qwen3_model = AutoModelForCausalLM.from_pretrained(
            model_name_or_path, **model_kwargs
        )
        self.qwen3_model.eval()

        # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.gen_kwargs = {
            "do_sample": True,
            "temperature": getattr(ppo_cfg, "temperature", 0.7),
            "top_p": getattr(ppo_cfg, "top_p", 0.9),
            "max_new_tokens": getattr(ppo_cfg, "max_new_tokens", 64),
            "pad_token_id": self.tokenizer.pad_token_id,
            "eos_token_id": self.tokenizer.eos_token_id,
        }

        print(f"âœ… Qwen3 base model loaded: {model_name_or_path}")

    def get_intervention_decision_gpt5(self, observation: str) -> tuple[str, str]:
        """
        GPT5ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†

        Args:
            observation: ç’°å¢ƒã‹ã‚‰ã®è¦³æ¸¬ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰

        Returns:
            (ä»‹å…¥åˆ¤å®šã®JSONæ–‡å­—åˆ—, ç”Ÿã®å‡ºåŠ›)
        """
        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯ä¼šè©±ã®é–¢ä¿‚æ€§ã‚’å®‰å®šåŒ–ã™ã‚‹ãŸã‚ã®ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚"
                "æŒ‡ç¤ºã«å¾“ã£ã¦ã€JSONå½¢å¼ã§ä»‹å…¥è¨ˆç”»ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
            },
            {
                "role": "user",
                "content": observation
            }
        ]

        max_attempts = 3
        raw_output = ""

        for attempt in range(1, max_attempts + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.deployment,
                    messages=messages,
                )

                if response and hasattr(response, "choices") and response.choices:
                    message = response.choices[0].message
                    content = message.content if hasattr(message, "content") else ""
                    if content:
                        raw_output = content

                        # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆ```json ... ```ãŒã‚ã‚Œã°ï¼‰
                        content = content.strip()
                        if "```json" in content:
                            start = content.find("```json") + 7
                            end = content.find("```", start)
                            if end > start:
                                content = content[start:end].strip()
                        elif "```" in content:
                            start = content.find("```") + 3
                            end = content.find("```", start)
                            if end > start:
                                content = content[start:end].strip()

                        return content, raw_output
            except Exception as e:
                if self.verbose:
                    print(f"[GPT5] ä»‹å…¥åˆ¤å®šè©¦è¡Œ {attempt}/{max_attempts} å¤±æ•—: {e}")
                if attempt < max_attempts:
                    time.sleep(0.5 * attempt)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»‹å…¥ã—ãªã„åˆ¤å®šã‚’è¿”ã™
        fallback = '{"intervene_now": false}'
        return fallback, raw_output or f"Error: All {max_attempts} attempts failed"

    def get_intervention_decision_qwen3(self, observation: str) -> tuple[str, str]:
        """
        Qwen3å­¦ç¿’å‰å…ƒãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ä»‹å…¥åˆ¤å®šã‚’è¡Œã†

        Args:
            observation: ç’°å¢ƒã‹ã‚‰ã®è¦³æ¸¬ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰

        Returns:
            (ä»‹å…¥åˆ¤å®šã®JSONæ–‡å­—åˆ—, ç”Ÿã®å‡ºåŠ›)
        """
        # observationã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’æ§‹ç¯‰
        # GPT5ã¨åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ã‚’ä½¿ç”¨
        from ppo_train import build_robot_messages

        try:
            # ç’°å¢ƒã®ç¾åœ¨ã®ãƒ­ã‚°ã¨ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
            messages = build_robot_messages(self.env.logs, self.env.personas, env=self.env)
        except Exception as e:
            if self.verbose:
                print(f"[Qwen3] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            messages = [
                {"role": "system", "content": "You are a robot intervention planner. Output JSON format intervention decision."},
                {"role": "user", "content": observation}
            ]

        max_attempts = 3
        raw_output = ""

        for attempt in range(1, max_attempts + 1):
            try:
                # ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨
                prompt = self.tokenizer.apply_chat_template(
                    messages, tokenize=False, add_generation_prompt=True
                )

                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                encoded = self.tokenizer(prompt, return_tensors="pt").to(self.qwen3_model.device)

                # ç”Ÿæˆ
                with torch.no_grad():
                    generated = self.qwen3_model.generate(
                        **encoded,
                        **self.gen_kwargs,
                    )

                # ãƒ‡ã‚³ãƒ¼ãƒ‰
                gen_ids = generated[0, encoded["input_ids"].shape[-1]:]
                raw_output = self.tokenizer.decode(gen_ids, skip_special_tokens=True).strip()

                # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                content = raw_output

                # think tagsã‚’é™¤å»
                if "</think>" in content:
                    content = content.split("</think>")[-1].strip()

                # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                start = content.find("{")
                end = content.rfind("}")
                if start != -1 and end != -1 and end > start:
                    json_candidate = content[start:end + 1]
                    try:
                        # JSONå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                        json.loads(json_candidate)
                        return json_candidate, raw_output
                    except json.JSONDecodeError:
                        pass

                # JSONæŠ½å‡ºå¤±æ•—æ™‚ã¯å…¨ä½“ã‚’è¿”ã™
                return content, raw_output

            except Exception as e:
                if self.verbose:
                    print(f"[Qwen3] ä»‹å…¥åˆ¤å®šè©¦è¡Œ {attempt}/{max_attempts} å¤±æ•—: {e}")
                if attempt < max_attempts:
                    time.sleep(0.1 * attempt)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        fallback = '{"intervene_now": false}'
        return fallback, raw_output or f"Error: All {max_attempts} attempts failed"

    def get_intervention_decision(self, observation: str) -> tuple[str, str]:
        """
        é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ä»‹å…¥åˆ¤å®šã‚’è¡Œã†

        Args:
            observation: ç’°å¢ƒã‹ã‚‰ã®è¦³æ¸¬ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰

        Returns:
            (ä»‹å…¥åˆ¤å®šã®JSONæ–‡å­—åˆ—, ç”Ÿã®å‡ºåŠ›)
        """
        if self.model_type == "gpt5":
            return self.get_intervention_decision_gpt5(observation)
        else:  # qwen3
            return self.get_intervention_decision_qwen3(observation)

    def run_session(self, session_id: int) -> Dict[str, Any]:
        """
        1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID

        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆæƒ…å ±
        """
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} é–‹å§‹ ({self.model_type.upper()})")
        print("=" * 80)

        # ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ
        observation = self.env.reset()

        print(f"\nğŸ“Œ è©±é¡Œ: {self.env.current_topic}")
        print(f"ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ: {', '.join(self.env.persona_pool)}")
        print(f"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")

        # åˆæœŸä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®max_historyç™ºè©±ï¼‰
        print(f"\nğŸ’¬ åˆæœŸä¼šè©±å±¥æ­´ï¼ˆreset()ã§ç”Ÿæˆã€ã‚¹ãƒ†ãƒƒãƒ—1ã®å…¥åŠ›ï¼‰:")
        from utils.log_filtering import filter_logs_by_human_count
        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.max_history, exclude_robot=False)
        for i, entry in enumerate(filtered_logs, 1):
            speaker = entry.get("speaker", "?")
            utterance = entry.get("utterance", "")
            print(f"  {i}. [{speaker}] {utterance}")

        # åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
        print(f"\nğŸ“Š åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§:")
        human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
        if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
            try:
                from utils.log_filtering import filter_logs_by_human_count
                participants = [p for p in self.env.persona_pool if p][:3]
                if len(participants) == 3:
                    filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                    scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                    from network_metrics import analyze_relations_from_scores
                    metrics = analyze_relations_from_scores(scores, participants)
                    print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {metrics.get('unstable_triads', '?')}")
                    edges = metrics.get("edges", {})
                    if edges:
                        print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                        for (p1, p2), score in sorted(edges.items()):
                            edge_name = f"{p1}{p2}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")
            except Exception as e:
                print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
        else:
            print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

        print("-" * 80)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        total_reward = 0.0
        interventions = 0
        steps_taken = 0
        conversation_log: List[Dict[str, Any]] = []

        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåˆæœŸçŠ¶æ…‹ç”¨ï¼‰
        previous_step_rel = None

        # ã‚¹ãƒ†ãƒƒãƒ—ãƒ«ãƒ¼ãƒ—
        done = False
        step = 0
        target_utterances = self.env.target_human_utterances
        while not done:
            step += 1
            print(f"\n{'='*80}")
            human_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
            print(f"ğŸ”¹ ã‚¹ãƒ†ãƒƒãƒ— {step} (äººé–“ç™ºè©±: {human_count}/{target_utterances})")
            print(f"{'='*80}")

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ï¼ˆstep()å®Ÿè¡Œå‰ï¼‰ã®ä¼šè©±ãƒ­ã‚°ã‚’ä¿å­˜
            logs_before_step = [dict(entry) for entry in self.env.logs]

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚’è¡¨ç¤ºï¼ˆå‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’ä½¿ç”¨ï¼‰
            is_stable_now = False
            if previous_step_rel is not None:
                # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’è¡¨ç¤º
                unstable_triads = previous_step_rel.get('unstable_triads', 0)
                is_stable_now = unstable_triads == 0
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—1ã®å ´åˆã€åˆæœŸçŠ¶æ…‹ã®é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡
                human_utterance_count = sum(1 for log in self.env.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if hasattr(self.env, 'scorer') and human_utterance_count >= 3:
                    try:
                        from utils.log_filtering import filter_logs_by_human_count
                        participants = [p for p in self.env.persona_pool if p][:3]
                        if len(participants) == 3:
                            filtered = filter_logs_by_human_count(self.env.logs, self.env.max_history_relation, exclude_robot=True)
                            scores = self.env.scorer.get_scores(filtered, participants, return_trace=False, update_state=False)
                            from network_metrics import analyze_relations_from_scores
                            metrics = analyze_relations_from_scores(scores, participants)
                            unstable_triads = metrics.get('unstable_triads', 0)
                            is_stable_now = unstable_triads == 0
                            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {unstable_triads}")
                            edges = metrics.get("edges", {})
                            if edges:
                                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                                for (p1, p2), score in sorted(edges.items()):
                                    edge_name = f"{p1}{p2}"
                                    if score > 0.5:
                                        emoji = "ğŸ˜Š"
                                    elif score > 0:
                                        emoji = "ğŸ™‚"
                                    elif score > -0.5:
                                        emoji = "ğŸ˜"
                                    else:
                                        emoji = "ğŸ˜ "
                                    print(f"    {edge_name}: {score:+.3f} {emoji}")
                    except Exception as e:
                        print(f"  ï¼ˆé–¢ä¿‚æ€§è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}ï¼‰")
                else:
                    print(f"  ï¼ˆã¾ã 3ç™ºè©±æœªæº€ï¼‰")

            # å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ä»‹å…¥åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
            raw_output = ""
            if is_stable_now:
                action = '{"intervene_now": false}'
                raw_output = "å®‰å®šçŠ¶æ…‹ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—"
            else:
                # è¦³æ¸¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º
                if self.verbose:
                    print(f"\nğŸ“ è¦³æ¸¬æƒ…å ±ï¼ˆ{self.model_type.upper()}ã¸ã®å…¥åŠ›ï¼‰:")
                    print("-" * 80)
                    # ä¼šè©±å±¥æ­´éƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºï¼ˆä»‹å…¥åˆ¤å®šLLMç”¨ã®max_historyç™ºè©±ï¼‰
                    if "å±¥æ­´:" in observation:
                        history_section = observation.split("å±¥æ­´:")[1].split("ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢")[0].strip()
                        history_lines = [line for line in history_section.split("\n") if line.strip()]

                        # ä»‹å…¥åˆ¤å®šLLMç”¨ã®max_historyç™ºè©±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        from utils.log_filtering import filter_logs_by_human_count
                        filtered_logs = filter_logs_by_human_count(self.env.logs, self.env.max_history, exclude_robot=False)

                        print("  ä¼šè©±å±¥æ­´:")
                        for entry in filtered_logs:
                            speaker = entry.get("speaker", "?")
                            utterance = entry.get("utterance", "")
                            print(f"    [{speaker}] {utterance}")
                    # é–¢ä¿‚ã‚¹ã‚³ã‚¢éƒ¨åˆ†ã‚’æŠ½å‡º
                    if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in observation:
                        score_line = [line for line in observation.split("\n") if "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢" in line]
                        if score_line:
                            print(f"  {score_line[0]}")
                    print("-" * 80)

                # ä»‹å…¥åˆ¤å®šã‚’å®Ÿè¡Œ
                action, raw_output = self.get_intervention_decision(observation)

            # ä»‹å…¥åˆ¤å®šçµæœã‚’è¡¨ç¤ºï¼ˆå®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if self.verbose and not is_stable_now:
                print(f"\nğŸ¤– {self.model_type.upper()}ä»‹å…¥åˆ¤å®šçµæœ:")

                # ç”Ÿã®å‡ºåŠ›ã‚’è¡¨ç¤º
                print(f"\nğŸ“‹ ç”Ÿå‡ºåŠ› ({self.model_type.upper()}):")
                print("-" * 60)
                print(raw_output)
                print("-" * 60)

                # JSONè§£æçµæœã‚’è¡¨ç¤º
                try:
                    action_json = json.loads(action)
                    intervene_now = action_json.get('intervene_now', False)
                    print(f"\nğŸ“Š è§£æçµæœ:")
                    print(f"  ä»‹å…¥åˆ¤å®š: {'âœ… ä»‹å…¥ã™ã‚‹' if intervene_now else 'âŒ ä»‹å…¥ã—ãªã„'}")
                    if intervene_now:
                        print(f"  å¯¾è±¡ã‚¨ãƒƒã‚¸: {action_json.get('edge_to_change', 'N/A')}")
                        print(f"  æˆ¦ç•¥: {action_json.get('strategy', 'N/A')}")
                        print(f"  å¯¾è±¡è©±è€…: {action_json.get('target_speaker', 'N/A')}")
                        if action_json.get('reasoning'):
                            print(f"  ç†ç”±: {action_json['reasoning']}")
                        print(f"\n  â¡ï¸  ã“ã®åˆ¤å®šã«åŸºã¥ãã€step()å†…ã§ãƒ­ãƒœãƒƒãƒˆç™ºè©±ãŒç”Ÿæˆã•ã‚Œã¾ã™")
                except json.JSONDecodeError:
                    print(f"  âš ï¸ JSONè§£æå¤±æ•—: {action[:100]}...")

            # ç’°å¢ƒã§ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            print(f"\nâš™ï¸  ç’°å¢ƒstep()ã‚’å®Ÿè¡Œä¸­...")
            print(f"   â†’ step()ã®å†…éƒ¨å‡¦ç†:")
            print(f"      1. äººé–“ç™ºè©±ç”Ÿæˆ: ã‚¹ãƒ†ãƒƒãƒ—1ã¾ãŸã¯å‰ã‚¹ãƒ†ãƒƒãƒ—ã§ä»‹å…¥ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã€ãã‚Œä»¥å¤–ã¯1äººé–“ç™ºè©±ç”Ÿæˆ")
            print(f"      2. é–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆå®‰å®šãªã‚‰æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
            print(f"      3. ä¸å®‰å®šãªã‚‰ä»‹å…¥åˆ¤å®šå®Ÿè¡Œ")
            print(f"      4. ä»‹å…¥ã™ã‚‹å ´åˆ:")
            print(f"         - ãƒ­ãƒœãƒƒãƒˆç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
            print(f"         - å®‰å®šé”æˆæ™‚: æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯")
            print(f"      5. å ±é…¬è¨ˆç®—ã—ã¦è¿”å´")
            observation, reward, done, info = self.env.step(action)

            total_reward += reward
            steps_taken += 1
            if info.get("intervened", False):
                interventions += 1

            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œä¸­ã«ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ã‚’è¡¨ç¤º
            print(f"\nğŸ’¬ ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã•ã‚ŒãŸä¼šè©±ï¼ˆstep()ã®å®Ÿè¡Œçµæœï¼‰:")
            print("-" * 80)

            # ã‚¹ãƒ†ãƒƒãƒ—å‰å¾Œã®å·®åˆ†ã‚’è¨ˆç®—
            new_entries = self.env.logs[len(logs_before_step):]

            if not new_entries:
                print("  ï¼ˆæ–°ã—ã„ç™ºè©±ãªã—ï¼‰")
            else:
                # å®Ÿéš›ã®ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                human_count = 0
                robot_count = 0
                for entry in new_entries:
                    speaker = entry.get("speaker", "ä¸æ˜")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        robot_count += 1
                    else:
                        human_count += 1

                # ä»‹å…¥ã—ãŸå ´åˆã¨ãã†ã§ãªã„å ´åˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
                if info.get("intervened", False):
                    print(f"  âœ… ä»‹å…¥ã‚ã‚Šï¼ˆåˆè¨ˆ{len(new_entries)}ç™ºè©±ï¼‰:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    print(f"     - ãƒ­ãƒœãƒƒãƒˆ: {robot_count}ç™ºè©±")
                    print(f"       â€»ãƒ­ãƒœãƒƒãƒˆ1ç™ºè©± + evaluation_horizon={self.env.evaluation_horizon}äººé–“ç™ºè©±")
                    print(f"        å®‰å®šé”æˆæ™‚ã¯æœ€ä½terminal_bonus_duration={self.env.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã¯1ãƒ©ã‚¦ãƒ³ãƒ‰=3äººé–“ç™ºè©±ãŒæœ€å°å˜ä½ï¼‰")
                    print()
                else:
                    print(f"  âŒ ä»‹å…¥ãªã—:")
                    print(f"     - äººé–“: {human_count}ç™ºè©±")
                    if step == 1:
                        print(f"       â€»ã‚¹ãƒ†ãƒƒãƒ—1ã¯ç™ºè©±ãªã—ï¼ˆreset()ã§ç”Ÿæˆæ¸ˆã¿ï¼‰ã€å®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³")
                    else:
                        print(f"       â€»1äººé–“ç™ºè©±ã®ã¿ï¼ˆå®‰å®šçŠ¶æ…‹ã§æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼‰")
                    print()

                # ç™ºè©±å†…å®¹ã‚’è¡¨ç¤º
                for i, entry in enumerate(new_entries, 1):
                    speaker = entry.get("speaker", "ä¸æ˜")
                    utterance = entry.get("utterance", "")
                    if speaker == "ãƒ­ãƒœãƒƒãƒˆ":
                        print(f"\n  {i}. ğŸ¤– ã€ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ç™ºè©±ã€‘")
                        print(f"     æˆ¦ç•¥: {info.get('plan', {}).get('strategy', 'N/A') if info.get('plan') else 'N/A'}")
                        print(f"     ç™ºè©±: {utterance}")
                        print()
                    else:
                        print(f"  {i}. ğŸ‘¤ [{speaker}] {utterance}")

                # ç™ºè©±æ•°ã®ã‚µãƒãƒªãƒ¼
                print(f"\n  ğŸ“Š ç™ºè©±æ•°ã‚µãƒãƒªãƒ¼: äººé–“ {human_count}ç™ºè©±, ãƒ­ãƒœãƒƒãƒˆ {robot_count}ç™ºè©±, åˆè¨ˆ {len(new_entries)}ç™ºè©±")

            # evaluation_horizonå¾Œã®é–¢ä¿‚æ€§ï¼ˆä»‹å…¥ã—ã¦å®‰å®šã«ãªã£ãŸå ´åˆã®ã¿ï¼‰
            if info.get("intervened", False) and "rel_after_horizon" in info and info.get('stable_after_horizon', False):
                rel_after = info.get("rel_after_horizon", {})
                print(f"\nğŸ“Š evaluation_horizonå¾Œã®é–¢ä¿‚æ€§:")
                print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel_after.get('unstable_triads', 0)}")
                print(f"  å®‰å®šçŠ¶æ…‹: âœ… ã¯ã„")

                edges_after = rel_after.get("edges", {})
                if edges_after:
                    print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                    edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                    for edge_pair in edge_order:
                        if edge_pair in edges_after:
                            score = edges_after[edge_pair]
                            edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                            if score > 0.5:
                                emoji = "ğŸ˜Š"
                            elif score > 0:
                                emoji = "ğŸ™‚"
                            elif score > -0.5:
                                emoji = "ğŸ˜"
                            else:
                                emoji = "ğŸ˜ "
                            print(f"    {edge_name}: {score:+.3f} {emoji}")

            # æœ€çµ‚çš„ãªé–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            rel = info.get("rel", {})
            print(f"\nğŸ“Š æœ€çµ‚çš„ãªé–¢ä¿‚æ€§è©•ä¾¡:")
            print(f"  ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {rel.get('unstable_triads', 0)}")
            print(f"  å®‰å®šçŠ¶æ…‹: {'âœ… ã¯ã„' if info.get('balanced', False) else 'âŒ ã„ã„ãˆ'}")

            # æ•°å€¤ã‚¹ã‚³ã‚¢ã®å‡ºåŠ›
            edges = rel.get("edges", {})
            if edges:
                print(f"  ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢:")
                edge_order = [("A", "B"), ("B", "C"), ("A", "C")]
                for edge_pair in edge_order:
                    if edge_pair in edges:
                        score = edges[edge_pair]
                        edge_name = f"{edge_pair[0]}{edge_pair[1]}"
                        # ã‚¹ã‚³ã‚¢ã‚’è¦–è¦šåŒ–
                        if score > 0.5:
                            emoji = "ğŸ˜Š"
                        elif score > 0:
                            emoji = "ğŸ™‚"
                        elif score > -0.5:
                            emoji = "ğŸ˜"
                        else:
                            emoji = "ğŸ˜ "
                        print(f"    {edge_name}: {score:+.3f} {emoji}")

            # å ±é…¬ã®è©³ç´°
            print(f"\nğŸ’° å ±é…¬:")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {reward:.4f}")
            print(f"  ç´¯ç©å ±é…¬: {total_reward:.4f}")

            reward_breakdown = info.get("reward_breakdown", {})
            if reward_breakdown:
                print(f"  å ±é…¬å†…è¨³:")
                label_map = {
                    "delta_u_flip": "  ğŸ“ˆ é–¢ä¿‚æ€§æ”¹å–„åŠ¹æœ (Î”u_flip)",
                    "counterfactual_u_flip": "  ğŸ”® åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦",
                    "actual_u_flip": "  ğŸ“‰ å®Ÿéš›ã®ä¸å®‰å®šåº¦",
                    "intervention_cost": "  ğŸ’¸ ä»‹å…¥ã‚³ã‚¹ãƒˆ",
                    "time_penalty": "  â±ï¸  æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£",
                    "terminal_bonus": "  ğŸ çµ‚äº†ãƒœãƒ¼ãƒŠã‚¹"
                }
                for key, value in reward_breakdown.items():
                    label = label_map.get(key, f"  {key}")
                    print(f"    {label}: {value:.4f}")

            # åå®Ÿä»®æƒ³æƒ…å ±
            if self.verbose and info.get("counterfactual_u_flip") is not None:
                print(f"\nğŸ”® åå®Ÿä»®æƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
                print(f"  åå®Ÿä»®æƒ³ä¸å®‰å®šåº¦: {info.get('counterfactual_u_flip', 0):.4f}")
                print(f"  å®Ÿéš›ã®ä¸å®‰å®šåº¦: {info.get('actual_u_flip', 0):.4f}")
                print(f"  æ”¹å–„åŠ¹æœ (å·®åˆ†): {info.get('delta_u_flip', 0):.4f}")

            # ä¼šè©±ãƒ­ã‚°ã«è¿½åŠ 
            conversation_log.append({
                "step": step,
                "action": action,
                "raw_output": raw_output,
                "reward": reward,
                "intervened": info.get("intervened", False),
                "robot_utterance": info.get("robot_utterance"),
                "replies": info.get("replies", []),
                "balanced": info.get("balanced", False),
                "new_entries": new_entries,
            })

            # ã‚¹ãƒ†ãƒƒãƒ—ã‚µãƒãƒªãƒ¼
            print(f"\n{'â”€'*80}")
            print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ— {step} å®Œäº†")
            print(f"   ä»‹å…¥: {'ã‚ã‚Š' if info.get('intervened', False) else 'ãªã—'}")
            print(f"   å ±é…¬: {reward:.4f}")
            print(f"   ç´¯ç©å ±é…¬: {total_reward:.4f}")
            print(f"   å®‰å®šçŠ¶æ…‹: {'âœ…' if info.get('balanced', False) else 'âŒ'}")
            print(f"{'â”€'*80}")

            # æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã«æœ€çµ‚é–¢ä¿‚æ€§ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            previous_step_rel = info.get("rel", {})

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {session_id} çµ‚äº† ({self.model_type.upper()})")
        print("=" * 80)
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {steps_taken}")
        print(f"ç·ä»‹å…¥å›æ•°: {interventions}")
        print(f"ç·å ±é…¬: {total_reward:.4f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—å ±é…¬: {total_reward / steps_taken if steps_taken > 0 else 0:.4f}")

        return {
            "session_id": session_id,
            "model_type": self.model_type,
            "topic": self.env.current_topic,
            "total_reward": total_reward,
            "interventions": interventions,
            "steps": steps_taken,
            "average_reward": total_reward / steps_taken if steps_taken > 0 else 0,
            "conversation_log": conversation_log,
        }

    def run(self) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        print("=" * 80)
        print(f"{self.model_type.upper()}ä»‹å…¥åˆ¤å®šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 80)
        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {self.num_sessions}")
        print(f"è¨­å®šã•ã‚ŒãŸãƒ©ã‚¦ãƒ³ãƒ‰æ•°: {self.env.max_rounds}")
        print(f"1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ãŸã‚Šã®ç›®æ¨™äººé–“ç™ºè©±æ•°: {self.env.target_human_utterances}")

        start_time = time.time()

        # å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        for i in range(1, self.num_sessions + 1):
            session_stats = self.run_session(i)
            self.session_stats.append(session_stats)

        elapsed_time = time.time() - start_time

        # å…¨ä½“ã®çµ±è¨ˆã‚’å‡ºåŠ›
        self.print_overall_statistics(elapsed_time)

    def print_overall_statistics(self, elapsed_time: float) -> None:
        """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print(f"å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ ({self.model_type.upper()})")
        print("=" * 80)

        if not self.session_stats:
            print("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        total_rewards = [s["total_reward"] for s in self.session_stats]
        total_interventions = sum(s["interventions"] for s in self.session_stats)
        total_steps = sum(s["steps"] for s in self.session_stats)

        print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_type.upper()}")
        print(f"ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(self.session_stats)}")
        print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
        print(f"ç·ä»‹å…¥å›æ•°: {total_interventions}")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
        print()
        print(f"ç·å ±é…¬:")
        print(f"  åˆè¨ˆ: {sum(total_rewards):.4f}")
        print(f"  å¹³å‡: {sum(total_rewards) / len(total_rewards):.4f}")
        print(f"  æœ€å¤§: {max(total_rewards):.4f}")
        print(f"  æœ€å°: {min(total_rewards):.4f}")
        print()
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ä»‹å…¥å›æ•°: {total_interventions / len(self.session_stats):.2f}")
        print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps / len(self.session_stats):.2f}")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã®è©³ç´°
        print("\n" + "-" * 80)
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥è©³ç´°:")
        print("-" * 80)
        for stat in self.session_stats:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ {stat['session_id']}:")
            print(f"  è©±é¡Œ: {stat['topic']}")
            print(f"  ç·å ±é…¬: {stat['total_reward']:.4f}")
            print(f"  ä»‹å…¥å›æ•°: {stat['interventions']}")
            print(f"  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {stat['steps']}")
            print()


def main():
    parser = argparse.ArgumentParser(
        description="ä»‹å…¥åˆ¤å®šãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=["gpt5", "qwen3"],
        default="gpt5",
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« (gpt5: Azure OpenAI GPT5, qwen3: Qwen3å­¦ç¿’å‰å…ƒãƒ¢ãƒ‡ãƒ«) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt5)",
    )
    parser.add_argument(
        "--num-sessions",
        type=int,
        default=5,
        help="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)",
    )
    parser.add_argument(
        "--max-steps",
        type=int,
        default=6,
        help="éæ¨å¥¨: config.local.yamlã®max_roundsã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6)",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="è©³ç´°ãªå‡ºåŠ›ã‚’æŠ‘åˆ¶",
    )

    args = parser.parse_args()

    try:
        simulator = InterventionModelComparator(
            model_type=args.model,
            max_steps=args.max_steps,
            num_sessions=args.num_sessions,
            verbose=not args.quiet,
        )
        simulator.run()
    except KeyboardInterrupt:
        print("\n\nã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()