"""
Azure OpenAI ãƒ™ãƒ¼ã‚¹ã®äººé–“åŒå£«ä¼šè©±ãƒ†ã‚¹ãƒˆï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ä½¿ç”¨ç‰ˆï¼‰

ä½¿ã„æ–¹:
    python app/test_azure_human_convo.py

ç‰¹å¾´:
- æœ¬ç•ªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconvo_env.py, humans_ollama.py, network_metrics.pyãªã©ï¼‰ã®é–¢æ•°ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
- reset()ã®å†…éƒ¨å‡¦ç†ã‚’1ç™ºè©±ãšã¤å¯è¦–åŒ–
- ç†æƒ³çš„ãªæŒ™å‹•ã‚’ç¢ºèªå¯èƒ½

ç†æƒ³çš„ãªæŒ™å‹•:
1. 1äººãŒç™ºè©±ã—ãŸã‚‰ã™ãã«é–¢ä¿‚æ€§æ¨å®šã‚’å®Ÿè¡Œï¼ˆ3ç™ºè©±ä»¥ä¸Šã®å ´åˆï¼‰
2. å®‰å®šãªã‚‰ä½•ã‚‚ã—ãªã„ï¼ˆæ¬¡ã®äººé–“ç™ºè©±ã¸ï¼‰
3. ä¸å®‰å®šãªã‚‰ä»‹å…¥åˆ¤å®š
4. ä»‹å…¥ã™ã‚‹å ´åˆ:
   - ãƒ­ãƒœãƒƒãƒˆç™ºè©±
   - evaluation_horizonå›ã®äººé–“ç™ºè©±ã‚’ç”Ÿæˆï¼ˆ1äººãšã¤ï¼‰
   - é–¢ä¿‚æ€§åˆ¤æ–­
   - å®‰å®šã«ãªã£ãŸã‚‰ã€terminal_bonus_durationå›è¿½åŠ ã§äººé–“ç™ºè©±ã‚’ç”Ÿæˆã—ã¦å®‰å®šæŒç¶šã‚’ç¢ºèª
   - å ±é…¬è¨ˆç®—
5. ä»‹å…¥ã—ãªã„å ´åˆ:
   - ã‚¿ã‚¤ãƒ ãƒšãƒŠãƒ«ãƒ†ã‚£ã®ã¿
"""
from __future__ import annotations
import json
import os
from typing import List, Dict, Tuple

from azure_clients import get_azure_chat_completion_client, build_chat_completion_params
from config import get_config
from env.convo_env import ConversationEnv
from utils import filter_logs_by_human_count
from network_metrics import analyze_relations_from_scores
from humans_ollama import human_reply


def run_conversation_test(max_turns: int = 20):
    """
    ä¼šè©±ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰

    Args:
        max_turns: æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°
    """
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    cfg = get_config()

    # ConversationEnvã‚’åˆæœŸåŒ–
    personas = getattr(cfg.env, "personas", {})
    env = ConversationEnv(
        max_steps=max_turns,
        personas=personas,
        include_robot=True,
        max_history=getattr(cfg.env, "max_history", 12),
        backend=getattr(cfg.scorer, "backend", "azure"),
        decay_factor=getattr(cfg.scorer, "decay_factor", 1.5),
        debug=getattr(cfg.env, "debug", False),
        reward_backend=getattr(cfg.env, "reward_backend", "rule"),
        evaluation_horizon=getattr(cfg.env, "evaluation_horizon", 2),
        time_penalty=getattr(cfg.env, "time_penalty", 0.01),
        terminal_bonus=getattr(cfg.env, "terminal_bonus", 0.25),
        intervention_cost=getattr(cfg.env, "intervention_cost", 0.02),
    )

    print("\n" + "=" * 80)
    print("ä¼šè©±ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ä½¿ç”¨ï¼‰")
    print("=" * 80)

    # ============================================================================
    # reset()ã®å†…éƒ¨å‡¦ç†ã‚’æ‰‹å‹•ã§å±•é–‹ï¼ˆ1ç™ºè©±ãšã¤å¯è¦–åŒ–ã™ã‚‹ãŸã‚ï¼‰
    # ============================================================================

    # reset()ã®åˆæœŸåŒ–éƒ¨åˆ†ï¼ˆconvo_env.py:150-161è¡Œç›®ç›¸å½“ï¼‰
    env.episode += 1
    env._episode_step = 0
    env.t = 0
    env.logs = []
    env.scorer = type(env.scorer)(**env._scorer_kwargs)
    env.steps_since_last_intervention = 0
    env.stable_step_start = None
    env.terminal_bonus_given = False

    # ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆconvo_env.py:163-165è¡Œç›®ç›¸å½“ï¼‰
    env.current_topic = env._get_topic_suggestion()
    env.used_topics.append(env.current_topic)

    print(f"\nğŸ“Œ è©±é¡Œ: {env.current_topic}")
    if env.current_topic_trigger:
        print(f"ğŸ¯ é¸ã°ã‚ŒãŸåœ°é›·ãƒ¯ãƒ¼ãƒ‰: {env.current_topic_trigger}")
    else:
        print(f"ğŸ¯ é¸ã°ã‚ŒãŸåœ°é›·ãƒ¯ãƒ¼ãƒ‰: ãªã—")
    print(f"ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ: {', '.join(env.persona_pool)}")

    print("\n" + "=" * 80)
    print("åˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆä¸å®‰å®šã‚·ãƒ¼ãƒ‰ç”Ÿæˆï¼‰")
    print("=" * 80)

    # _bootstrap_humans(evaluation_horizon)ã‚’1äººãšã¤å±•é–‹ï¼ˆconvo_env.py:167è¡Œç›®ç›¸å½“ï¼‰
    print(f"\nğŸ’¬ åˆæœŸä¼šè©±ç”Ÿæˆï¼ˆ1äººãšã¤{env.evaluation_horizon}å›ã€å„ç™ºè©±å¾Œã«é–¢ä¿‚æ€§æ¨å®šï¼‰")

    persona_index = 0
    initial_turns = 0
    target_initial_turns = env.evaluation_horizon

    while initial_turns < target_initial_turns:
        current_persona = env.persona_pool[persona_index % len(env.persona_pool)]
        persona_index += 1

        print(f"\nğŸ‘¤ [{current_persona}] ç™ºè©±ç”Ÿæˆä¸­...")
        # æœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®human_reply()ã‚’ä½¿ç”¨ï¼ˆ1äººãšã¤ï¼‰
        replies = human_reply(
            env.logs,
            [current_persona],
            topic=env.current_topic,
            topic_trigger=env.current_topic_trigger
        )
        env.logs.extend(replies)

        # ç™ºè©±ã‚’è¡¨ç¤º
        for reply in replies:
            speaker = reply.get("speaker", "?")
            utterance = reply.get("utterance", "")
            print(f"[{speaker}] {utterance}")

        # äººé–“ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        human_count = sum(1 for log in env.logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ")

        # æ¯å›é–¢ä¿‚æ€§æ¨å®šã‚’è©¦ã¿ã‚‹ï¼ˆ3ç™ºè©±æœªæº€ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—è¡¨ç¤ºï¼‰
        if human_count >= env.start_relation_check_after_utterances:
            participants = env._participants(env.logs)
            filtered_logs = filter_logs_by_human_count(env.logs, env.max_history, exclude_robot=True)
            scores, _ = env._relation_state(filtered_logs, update_state=True)

            print(f"\nğŸ“Š é–¢ä¿‚æ€§æ¨å®šï¼ˆ{human_count}ç™ºè©±æ™‚ç‚¹ï¼‰:")
            for (a, b), v in sorted(scores.items()):
                print(f"  relation {a}-{b}: {v:+.2f}")

            # å®‰å®šåˆ¤å®š
            metrics, _ = env._metrics_state(scores, participants)
            unstable_triads = metrics.get("unstable_triads", 0)
            is_stable = unstable_triads == 0

            if is_stable:
                print(f"  çŠ¶æ…‹: å®‰å®š")
            else:
                print(f"  çŠ¶æ…‹: ä¸å®‰å®šï¼ˆä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°={unstable_triads}ï¼‰")
        else:
            print(f"ï¼ˆäººé–“ç™ºè©±æ•° {human_count} < {env.start_relation_check_after_utterances}ã€é–¢ä¿‚æ€§æ¨å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        print()

        initial_turns += 1

    # _ensure_unstable_seed()ã‚’å±•é–‹ï¼ˆconvo_env.py:168è¡Œç›®ç›¸å½“ï¼‰
    print(f"ğŸ”„ ä¸å®‰å®šã‚·ãƒ¼ãƒ‰ç¢ºä¿ä¸­ï¼ˆå®‰å®šãªã‚‰è¿½åŠ ã§ä¼šè©±ç”Ÿæˆï¼‰...")

    attempts = 0
    while env._is_balanced() and attempts < env.max_steps:
        print(f"\n  âš ï¸ ã¾ã å®‰å®šçŠ¶æ…‹ â†’ 1äººãšã¤{env.evaluation_horizon}å›è¿½åŠ ç”Ÿæˆï¼ˆå„ç™ºè©±å¾Œã«é–¢ä¿‚æ€§æ¨å®šï¼‰")

        for turn_in_attempt in range(env.evaluation_horizon):
            current_persona = env.persona_pool[persona_index % len(env.persona_pool)]
            persona_index += 1

            print(f"\n  ğŸ‘¤ [{current_persona}] ç™ºè©±ç”Ÿæˆä¸­...")
            replies = human_reply(
                env.logs,
                [current_persona],
                topic=env.current_topic,
                topic_trigger=env.current_topic_trigger
            )
            env.logs.extend(replies)

            # ç™ºè©±ã‚’è¡¨ç¤º
            for reply in replies:
                speaker = reply.get("speaker", "?")
                utterance = reply.get("utterance", "")
                print(f"  [{speaker}] {utterance}")

            # äººé–“ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            human_count = sum(1 for log in env.logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ")

            # æ¯å›é–¢ä¿‚æ€§æ¨å®šã‚’è©¦ã¿ã‚‹ï¼ˆ3ç™ºè©±æœªæº€ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—è¡¨ç¤ºï¼‰
            if human_count >= env.start_relation_check_after_utterances:
                participants = env._participants(env.logs)
                filtered_logs = filter_logs_by_human_count(env.logs, env.max_history, exclude_robot=True)
                scores, _ = env._relation_state(filtered_logs, update_state=True)

                print(f"\n  ğŸ“Š é–¢ä¿‚æ€§æ¨å®šï¼ˆ{human_count}ç™ºè©±æ™‚ç‚¹ï¼‰:")
                for (a, b), v in sorted(scores.items()):
                    print(f"    relation {a}-{b}: {v:+.2f}")

                metrics, _ = env._metrics_state(scores, participants)
                unstable_triads = metrics.get("unstable_triads", 0)
                is_stable = unstable_triads == 0

                if is_stable:
                    print(f"    çŠ¶æ…‹: å®‰å®š")
                else:
                    print(f"    çŠ¶æ…‹: ä¸å®‰å®šï¼ˆä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°={unstable_triads}ï¼‰")
            else:
                print(f"  ï¼ˆäººé–“ç™ºè©±æ•° {human_count} < {env.start_relation_check_after_utterances}ã€é–¢ä¿‚æ€§æ¨å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            print()

        attempts += 1

    print(f"âœ… ä¸å®‰å®šã‚·ãƒ¼ãƒ‰ç¢ºä¿å®Œäº†ï¼ˆç·{len(env.logs)}ç™ºè©±ï¼‰")

    # ============================================================================
    # ã“ã“ã‹ã‚‰é€šå¸¸ã®ä¼šè©±ãƒ•ãƒ­ãƒ¼
    # ============================================================================

    print("\n" + "=" * 80)
    print("ä¼šè©±ãƒ•ãƒ­ãƒ¼é–‹å§‹ï¼ˆ1äººãšã¤ç™ºè©±â†’é–¢ä¿‚æ€§æ¨å®šï¼‰")
    print("=" * 80)

    # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    start_relation_check_after_utterances = env.start_relation_check_after_utterances
    evaluation_horizon = env.evaluation_horizon
    terminal_bonus_duration = env.terminal_bonus_duration
    time_penalty = env.time_penalty
    intervention_cost = env.intervention_cost
    terminal_bonus = env.terminal_bonus
    max_history = env.max_history

    turn_count = 0

    while turn_count < max_turns:
        turn_count += 1
        print(f"\n{'â”€' * 80}")
        print(f"ã‚¿ãƒ¼ãƒ³ {turn_count}")
        print(f"{'â”€' * 80}")

        # ç¾åœ¨ã®è©±è€…ã‚’æ±ºå®š
        current_persona = env.persona_pool[persona_index % len(env.persona_pool)]
        persona_index += 1

        # 1. äººé–“ç™ºè©±ã‚’1äººåˆ†ç”Ÿæˆï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®human_replyé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        print(f"\nğŸ‘¤ [{current_persona}] ç™ºè©±ç”Ÿæˆä¸­...")
        replies = human_reply(
            env.logs,
            [current_persona],  # 1äººã ã‘æ¸¡ã™
            topic=env.current_topic,
            topic_trigger=env.current_topic_trigger
        )

        # logsã«è¿½åŠ 
        env.logs.extend(replies)

        # ç™ºè©±ã‚’è¡¨ç¤º
        for reply in replies:
            speaker = reply.get("speaker", "?")
            utterance = reply.get("utterance", "")
            print(f"[{speaker}] {utterance}")

        # äººé–“ç™ºè©±æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        human_count = sum(1 for log in env.logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ")

        # 2. é–¢ä¿‚æ€§æ¨å®šï¼ˆ3ç™ºè©±ä»¥ä¸Šã®å ´åˆï¼‰
        if human_count < start_relation_check_after_utterances:
            print(f"  ï¼ˆäººé–“ç™ºè©±æ•° {human_count} < {start_relation_check_after_utterances}ã€é–¢ä¿‚æ€§æ¨å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            continue

        print(f"\nğŸ“Š é–¢ä¿‚æ€§æ¨å®šä¸­...")

        # é–¢ä¿‚æ€§LLMç”¨: ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’é™¤å¤–ï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã¨åŒã˜å‡¦ç†ï¼‰
        participants = env._participants(env.logs)
        filtered_logs = filter_logs_by_human_count(env.logs, max_history, exclude_robot=True)
        scores, _ = env._relation_state(filtered_logs, update_state=True)

        # ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
        for (a, b), v in sorted(scores.items()):
            print(f"  relation {a}-{b}: {v:+.2f}")

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        metrics, _ = env._metrics_state(scores, participants)
        unstable_triads = metrics.get("unstable_triads", 0)
        is_stable = unstable_triads == 0

        # 3. å®‰å®šåˆ¤å®š
        if is_stable:
            print("ï¼ˆé–¢ä¿‚æ€§æ¨å®šï¼šå®‰å®šï¼‰")
            print("  â†’ ä»‹å…¥åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—")
            continue

        print(f"ï¼ˆé–¢ä¿‚æ€§æ¨å®šï¼šä¸å®‰å®šã€ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°={unstable_triads}ï¼‰")

        # 4. ä»‹å…¥åˆ¤å®šï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
        print(f"\nğŸ¤– ä»‹å…¥åˆ¤å®šä¸­...")

        # è¦³æ¸¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
        observation = env._make_observation()

        # Azure OpenAIã§ä»‹å…¥åˆ¤å®šã‚’å®Ÿè¡Œï¼ˆæœ¬ç•ªã¨åŒã˜è¨­å®šã‚’ä½¿ç”¨ï¼‰
        client, deployment = get_azure_chat_completion_client(getattr(cfg, "llm", None), model_type="intervention")
        if not client or not deployment:
            print("  âš ï¸ Azure OpenAI client unavailable, fallback to no intervention")
            plan = {"intervene_now": False}
        else:
            messages = [
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ä¼šè©±ã®é–¢ä¿‚æ€§ã‚’å®‰å®šåŒ–ã™ã‚‹ãŸã‚ã®ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚"
                               "æŒ‡ç¤ºã«å¾“ã£ã¦ã€JSONå½¢å¼ã§ä»‹å…¥è¨ˆç”»ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                },
                {"role": "user", "content": observation}
            ]

            try:
                params = build_chat_completion_params(deployment, messages, cfg.llm)
                res = client.chat.completions.create(**params)
                if res and getattr(res, "choices", None):
                    choice = res.choices[0]
                    message = getattr(choice, "message", None)
                    if isinstance(message, dict):
                        action_text = message.get("content", "")
                    else:
                        action_text = getattr(message, "content", "")

                    # JSONã‚’æŠ½å‡º
                    action_text = action_text.strip()
                    if "```json" in action_text:
                        start = action_text.find("```json") + 7
                        end = action_text.find("```", start)
                        if end > start:
                            action_text = action_text[start:end].strip()
                    elif "```" in action_text:
                        start = action_text.find("```") + 3
                        end = action_text.find("```", start)
                        if end > start:
                            action_text = action_text[start:end].strip()

                    # ãƒ‘ãƒ¼ã‚¹ï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
                    plan, plan_error, _ = env._parse_plan(action_text)
                    if plan_error:
                        print(f"  âš ï¸ ãƒ—ãƒ©ãƒ³ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {plan_error}, fallback to no intervention")
                        plan = {"intervene_now": False}
                else:
                    plan = {"intervene_now": False}
            except Exception as e:
                print(f"  âš ï¸ ä»‹å…¥åˆ¤å®šLLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}, fallback to no intervention")
                plan = {"intervene_now": False}

        intervene_now = plan.get("intervene_now", False)
        print(f"ï¼ˆä»‹å…¥åˆ¤æ–­ï¼š{'ä»‹å…¥' if intervene_now else 'ä»‹å…¥ã—ãªã„'}ï¼‰")

        if intervene_now:
            print(f"  å¯¾è±¡ã‚¨ãƒƒã‚¸: {plan.get('edge_to_change', 'N/A')}")
            print(f"  æˆ¦ç•¥: {plan.get('strategy', 'N/A')}")
            print(f"  å¯¾è±¡è©±è€…: {plan.get('target_speaker', 'N/A')}")

        # 5. ä»‹å…¥å®Ÿè¡Œã¾ãŸã¯å ±é…¬è¨ˆç®—
        if not intervene_now:
            # ä»‹å…¥ã—ãªã„å ´åˆ: ã‚¿ã‚¤ãƒ ãƒšãƒŠãƒ«ãƒ†ã‚£ã®ã¿
            reward = -time_penalty
            print(f"ï¼ˆå ±é…¬ç¢ºå®šï¼š{reward:+.4f} = -time_penaltyï¼‰")
            continue

        # 6. ä»‹å…¥ã™ã‚‹å ´åˆ
        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’ç”Ÿæˆï¼ˆæœ¬ç•ªã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
        print(f"\nğŸ¤– ãƒ­ãƒœãƒƒãƒˆç™ºè©±ç”Ÿæˆä¸­...")
        robot_entry = env._render_intervention(plan, simulate=False)
        robot_utterance = robot_entry.get("utterance", "")
        env.logs.append(robot_entry)
        print(f"ï¼ˆãƒ­ãƒœãƒƒãƒˆï¼š{robot_utterance}ï¼‰")

        # evaluation_horizonå›ã®äººé–“ç™ºè©±ã‚’ç”Ÿæˆï¼ˆ1äººãšã¤ï¼‰
        print(f"\nï¼ˆå ±é…¬ç¢ºå®šã¾ã§äººé–“ç™ºè©± {evaluation_horizon} å›ç”Ÿæˆ...ï¼‰")
        for _ in range(evaluation_horizon):
            current_persona_eval = env.persona_pool[persona_index % len(env.persona_pool)]
            persona_index += 1

            replies_eval = human_reply(
                env.logs,
                [current_persona_eval],
                topic=env.current_topic,
                topic_trigger=env.current_topic_trigger
            )
            env.logs.extend(replies_eval)

            # ç™ºè©±ã‚’è¡¨ç¤º
            for reply in replies_eval:
                speaker = reply.get("speaker", "?")
                utterance = reply.get("utterance", "")
                print(f"[{speaker}] {utterance}")

        # é–¢ä¿‚æ€§åˆ¤æ–­
        print(f"\nğŸ“Š é–¢ä¿‚æ€§åˆ¤æ–­ä¸­...")
        participants_after = env._participants(env.logs)
        filtered_logs_after = filter_logs_by_human_count(env.logs, max_history, exclude_robot=True)
        scores_after, _ = env._relation_state(filtered_logs_after, update_state=True)

        for (a, b), v in sorted(scores_after.items()):
            print(f"  relation {a}-{b}: {v:+.2f}")

        metrics_after, _ = env._metrics_state(scores_after, participants_after)
        is_stable_after = metrics_after.get("unstable_triads", 0) == 0

        if is_stable_after:
            print("ï¼ˆé–¢ä¿‚æ€§åˆ¤æ–­ï¼šå®‰å®šï¼‰")
            print(f"ï¼ˆå®‰å®šæŒç¶šã™ã‚‹ã‹ç¢ºèª {terminal_bonus_duration} å›...ï¼‰")

            # å®‰å®šæŒç¶šç¢ºèªï¼ˆ1äººãšã¤ï¼‰
            stability_maintained = True
            for i in range(terminal_bonus_duration):
                current_persona_check = env.persona_pool[persona_index % len(env.persona_pool)]
                persona_index += 1

                replies_check = human_reply(
                    env.logs,
                    [current_persona_check],
                    topic=env.current_topic,
                    topic_trigger=env.current_topic_trigger
                )
                env.logs.extend(replies_check)

                # ç™ºè©±ã‚’è¡¨ç¤º
                for reply in replies_check:
                    speaker = reply.get("speaker", "?")
                    utterance = reply.get("utterance", "")
                    print(f"[{speaker}] {utterance}")

                # é–¢ä¿‚æ€§åˆ¤æ–­
                participants_check = env._participants(env.logs)
                filtered_check = filter_logs_by_human_count(env.logs, max_history, exclude_robot=True)
                scores_check, _ = env._relation_state(filtered_check, update_state=True)
                metrics_check, _ = env._metrics_state(scores_check, participants_check)

                if metrics_check.get("unstable_triads", 0) > 0:
                    print("  ï¼ˆé–¢ä¿‚æ€§åˆ¤æ–­ï¼šä¸å®‰å®šï¼‰")
                    print("  ï¼ˆæŒç¶šãªã—ï¼‰")
                    stability_maintained = False
                    break
                else:
                    print(f"  å®‰å®šç¶­æŒ {i+1}/{terminal_bonus_duration}")

            if stability_maintained:
                print("ï¼ˆå®‰å®šæŒç¶šï¼‰")
                reward = -time_penalty - intervention_cost + terminal_bonus
                print(f"ï¼ˆå ±é…¬ç¢ºå®šï¼š{reward:+.4f} = -time_penalty -{intervention_cost:.4f} +{terminal_bonus:.4f}ï¼‰")
            else:
                reward = -time_penalty - intervention_cost
                print(f"ï¼ˆå ±é…¬ç¢ºå®šï¼š{reward:+.4f} = -time_penalty -{intervention_cost:.4f}ï¼‰")
        else:
            print("ï¼ˆé–¢ä¿‚æ€§åˆ¤æ–­ï¼šä¸å®‰å®šï¼‰")
            reward = -time_penalty - intervention_cost
            print(f"ï¼ˆå ±é…¬ç¢ºå®šï¼š{reward:+.4f} = -time_penalty -{intervention_cost:.4f}ï¼‰")

    print("\n" + "=" * 80)
    print("ä¼šè©±ãƒ†ã‚¹ãƒˆçµ‚äº†")
    print("=" * 80)


if __name__ == "__main__":
    run_conversation_test(max_turns=20)
