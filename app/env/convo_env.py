from __future__ import annotations

import asyncio
import copy
import json
import math
from typing import Any, Dict, Iterable, List, Optional, Tuple

from azure_clients import get_azure_chat_completion_client, build_chat_completion_params
from config import get_config
from context_reward import score_context_alignment
from humans_ollama import human_reply
from network_metrics import BALANCED, UNBALANCED, analyze_relations_from_scores
from relation_scorer import RelationScorer
from utils import filter_logs_by_human_count

_PLANNER_STRATEGIES = ("plan", "validate", "bridge")

# ãƒ—ãƒ©ãƒ³æ¤œè¨¼ç”¨ã®å®šæ•°
_TARGET_EDGES = {"AB", "BC", "CA"}  # å¤‰æ›´å¯¾è±¡ã¨ãªã‚‹ã‚¨ãƒƒã‚¸ï¼ˆãƒšã‚¢é–¢ä¿‚ï¼‰
_ALLOWED_STRATEGIES = _PLANNER_STRATEGIES  # è¨±å¯ã•ã‚Œã‚‹ä»‹å…¥æˆ¦ç•¥
_TARGET_SPEAKERS = {"A", "B", "C"}  # ä»‹å…¥å¯¾è±¡ã¨ãªã‚‹è©±è€…

_STABLE_SIGN_PATTERNS: Dict[str, Dict[str, int]] = {
    "+++": {"AB": +1, "BC": +1, "CA": +1},
    "+--": {"AB": +1, "BC": -1, "CA": -1},
    "-+-": {"AB": -1, "BC": +1, "CA": -1},
    "--+": {"AB": -1, "BC": -1, "CA": +1},
}


def _strip_quotes(text: str) -> str:
    # å…ˆé ­ãƒ»æœ«å°¾ã®å¼•ç”¨ç¬¦ã‚„æ‹¬å¼§ã‚’å‰Šã‚‹
    return text.strip().strip("\"'\u300c\u300d\u300e\u300f()[]ï¼ˆï¼‰ã€ã€‘")


def _coerce_bool(value: Any) -> Optional[bool]:
    # Boolean ã¸ã®å¤‰æ›ã‚’è©¦ã¿ã‚‹
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        lowered = value.strip().lower()
        if lowered in {"true", "1", "yes"}:
            return True
        if lowered in {"false", "0", "no"}:
            return False
    return None


def _coerce_int(value: Any) -> Optional[int]:
    # Integer ã¸ã®å¤‰æ›ã‚’è©¦ã¿ã‚‹
    try:
        return int(value)
    except (TypeError, ValueError):
        return None


def select_target_edge_and_speaker(
    edges: Dict[Any, float],
    debug: bool = False,
    debug_prefix: str = ""
) -> Tuple[str, str]:
    """
    é–¢ä¿‚æ€§ã‚¨ãƒƒã‚¸ã‹ã‚‰æ”¹å–„å¯¾è±¡ã‚¨ãƒƒã‚¸ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã‚’é¸æŠã™ã‚‹ã€‚
    
    ãƒ­ã‚¸ãƒƒã‚¯:
    1. çµ¶å¯¾å€¤ãŒæœ€å°ï¼ˆæœ€ã‚‚0ã«è¿‘ã„ï¼‰è² ã®ã‚¨ãƒƒã‚¸ã‚’é¸æŠ
    2. è² ã®ã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆã¯æœ€å°ã‚¹ã‚³ã‚¢ã®ã‚¨ãƒƒã‚¸ã‚’é¸æŠ
    3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã¯ã‚¨ãƒƒã‚¸ã®2äººã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    
    Args:
        edges: ã‚¨ãƒƒã‚¸è¾æ›¸ {(A,B): score, ...} ã¾ãŸã¯ {"AB": score, ...}
        debug: ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        debug_prefix: ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
        
    Returns:
        (edge_to_change, target_speaker) ã®ã‚¿ãƒ—ãƒ«
        edge_to_change ã¯æ­£è¦åŒ–æ¸ˆã¿ ("AB", "BC", "CA" ã®ã„ãšã‚Œã‹)
    """
    import random
    
    edge_to_change = None
    
    if debug:
        print(f"{debug_prefix} edgeså–å¾—: {edges}")
    
    # è² ã®ã‚¨ãƒƒã‚¸ã®ã¿ã‚’æŠ½å‡ºã—ã€çµ¶å¯¾å€¤ã§ã‚½ãƒ¼ãƒˆ
    negative_edges = []
    for edge_key, score in edges.items():
        if score < 0:
            # edge_keyãŒæ–‡å­—åˆ—ã§ãªã„å ´åˆã¯å¤‰æ›
            if isinstance(edge_key, tuple):
                edge_str = "".join(str(c) for c in edge_key)
            else:
                edge_str = str(edge_key)
            negative_edges.append((edge_str, score))
            if debug:
                print(f"{debug_prefix} è² ã‚¨ãƒƒã‚¸è¿½åŠ : {edge_str} = {score} (çµ¶å¯¾å€¤: {abs(score)})")
    
    if negative_edges:
        # çµ¶å¯¾å€¤ãŒæœ€å°ï¼ˆæœ€ã‚‚0ã«è¿‘ã„ï¼‰è² ã®ã‚¨ãƒƒã‚¸ã‚’é¸æŠ
        negative_edges.sort(key=lambda x: abs(x[1]))
        edge_to_change = negative_edges[0][0]
        if debug:
            print(f"{debug_prefix} ã‚½ãƒ¼ãƒˆå¾Œ: {negative_edges}")
            print(f"{debug_prefix} é¸æŠ: {edge_to_change} (ã‚¹ã‚³ã‚¢: {negative_edges[0][1]})")
    else:
        # è² ã®ã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆã¯ã€æœ€å°ã‚¹ã‚³ã‚¢ã®ã‚¨ãƒƒã‚¸ã‚’é¸æŠ
        if edges:
            min_edge = min(edges.items(), key=lambda x: x[1])
            if isinstance(min_edge[0], tuple):
                edge_to_change = "".join(str(c) for c in min_edge[0])
            else:
                edge_to_change = str(min_edge[0])
            if debug:
                print(f"{debug_prefix} è² ã‚¨ãƒƒã‚¸ãªã—ã€æœ€å°é¸æŠ: {edge_to_change}")
    
    
    # edge_to_changeã‚’æ­£è¦åŒ–
    edge_before_norm = edge_to_change
    edge_to_change = edge_to_change.replace(",", "").replace(" ", "").upper()
    if edge_to_change not in {"AB", "BC", "CA"}:
        if len(edge_to_change) == 2 and edge_to_change[1] + edge_to_change[0] in {"AB", "BC", "CA"}:
            edge_to_change = edge_to_change[1] + edge_to_change[0]
            if debug:
                print(f"{debug_prefix} åè»¢: {edge_before_norm} â†’ {edge_to_change}")
        else:
            edge_to_change = "AB"
            if debug:
                print(f"{debug_prefix} ä¸æ­£ãªã‚¨ãƒƒã‚¸ã€ABã«ä¿®æ­£: {edge_before_norm}")
    else:
        if debug:
            print(f"{debug_prefix} æ­£è¦åŒ–: {edge_before_norm} â†’ {edge_to_change}")
    
    # target_speaker: edge_to_changeã®2äººã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    target_speaker = random.choice(list(edge_to_change))
    
    return edge_to_change, target_speaker


class ConversationEnv:
    """ ä¸‰è€…ä¼šè©±ç’°å¢ƒ """

    def __init__(
        self,
        *,
        max_steps: int,
        personas: Optional[Iterable[str]] = None,
        include_robot: bool = True,
        max_history: int = 12,
        backend: Optional[str] = None,
        decay_factor: float = 1.5,
        debug: bool = False,
        reward_backend: str = "rule",
        evaluation_horizon: int = 2,
        time_penalty: Optional[float] = None,
        terminal_bonus: Optional[float] = None,
        intervention_cost: Optional[float] = None,
        max_auto_skip: Optional[int] = None,
    ) -> None:
        cfg = get_config()
        use_ema_cfg = getattr(cfg.scorer, "use_ema", True)
        if use_ema_cfg is None:
            use_ema_cfg = False

        self.max_steps = max(1, int(max_steps))  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™

        # max_rounds ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦ç›®æ¨™äººé–“ç™ºè©±æ•°ã‚’è¨ˆç®—
        # max_rounds ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€max_steps ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
        max_rounds_cfg = getattr(cfg.env, "max_rounds", None)
        if max_rounds_cfg is not None:
            self.max_rounds = max(1, int(max_rounds_cfg))
            # 1ãƒ©ã‚¦ãƒ³ãƒ‰ = len(persona_pool) äººé–“ç™ºè©±ï¼ˆé€šå¸¸3ç™ºè©±ï¼‰
            # persona_pool ã¯ã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„ã®ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3ã‚’ä½¿ç”¨
            self.target_human_utterances = self.max_rounds * 3
        else:
            # max_rounds ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€max_steps ã‹ã‚‰æ¨å®š
            self.max_rounds = self.max_steps
            self.target_human_utterances = self.max_steps * 3

        self.include_robot = bool(include_robot)
        
        # å¾Œæ–¹äº’æ›æ€§: max_historyãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        intervention_max_history_cfg = getattr(cfg.env, "intervention_max_history", None)
        robot_max_history_cfg = getattr(cfg.env, "robot_max_history", None)
        
        if intervention_max_history_cfg is not None:
            self.intervention_max_history = max(1, int(intervention_max_history_cfg))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: max_history ã¾ãŸã¯å¼•æ•°ã‹ã‚‰
            self.intervention_max_history = max(1, int(getattr(cfg.env, "max_history", max_history)))
        
        if robot_max_history_cfg is not None:
            self.robot_max_history = max(1, int(robot_max_history_cfg))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: max_history ã¾ãŸã¯å¼•æ•°ã‹ã‚‰
            self.robot_max_history = max(1, int(getattr(cfg.env, "max_history", max_history)))
        
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€max_historyã‚‚æ®‹ã™ï¼ˆéæ¨å¥¨ï¼‰
        self.max_history = self.intervention_max_history  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä»‹å…¥åˆ¤å®šç”¨ã¨åŒã˜
        
        self.max_history_human = max(1, int(getattr(cfg.env, "max_history_human", 12)))  # äººé–“LLMç”¨
        self.max_history_relation = max(1, int(getattr(cfg.env, "max_history_relation", 3)))  # é–¢ä¿‚æ€§LLMç”¨
        self.debug = bool(debug)
        self.reward_backend = (reward_backend or "rule").lower()
        self.evaluation_horizon = max(1, int(evaluation_horizon))
        self.start_relation_check_after_utterances = getattr(cfg.env, "start_relation_check_after_utterances", 3)

        # å ±é…¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’YAMLã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆå¼•æ•°ã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
        self.time_penalty = float(time_penalty) if time_penalty is not None else float(getattr(cfg.env, "time_penalty", 0.01))
        self.terminal_bonus = float(terminal_bonus) if terminal_bonus is not None else float(getattr(cfg.env, "terminal_bonus", 0.25))
        self.intervention_cost = float(intervention_cost) if intervention_cost is not None else float(getattr(cfg.env, "intervention_cost", 0.02))

        # æ–°ã—ã„å ±é…¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºãƒ™ãƒ¼ã‚¹ï¼‰
        self.stable_bonus = float(getattr(cfg.env, "stable_bonus", 2.0))
        self.preference_match_bonus = float(getattr(cfg.env, "preference_match_bonus", 0.5))

        # ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’YAMLã‹ã‚‰èª­ã¿è¾¼ã¿
        self.min_robot_intervention_lookback = int(getattr(cfg.env, "min_robot_intervention_lookback", 6))
        self.terminal_bonus_duration = int(getattr(cfg.env, "terminal_bonus_duration", 2))

        # auto-skip ã®æœ€å¤§è©¦è¡Œå›æ•°ï¼ˆãƒ†ã‚¹ãƒˆã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å±æ€§ã¨ã—ã¦ä¿æŒï¼‰
        # ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿å¼•æ•°ã§æŒ‡å®šã•ã‚Œã¦ã„ãªã‘ã‚Œã°è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’å‚ç…§ã—ã€ç„¡ã‘ã‚Œã° 10 ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã™ã‚‹
        self.max_auto_skip = int(max_auto_skip) if max_auto_skip is not None else int(getattr(cfg.env, "max_auto_skip", 10))

        # ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å±¥æ­´ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
        self.steps_since_last_intervention: int = 0  # æœ€å¾Œã®ä»‹å…¥ã‹ã‚‰ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
        self.stable_step_start: Optional[int] = None  # å®‰å®šçŠ¶æ…‹ãŒé–‹å§‹ã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ï¼ˆNoneãªã‚‰æœªå®‰å®šï¼‰
        self.terminal_bonus_given: bool = False  # terminal_bonusãŒæ—¢ã«ä¸ãˆã‚‰ã‚ŒãŸã‹ã©ã†ã‹

        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®çŠ¶æ…‹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
        self.previous_intervened: bool = False
        self.previous_rel_after_horizon: Optional[Dict[str, Any]] = None
        self.previous_rel_after_bonus: Optional[Dict[str, Any]] = None

        # personasã®å‡¦ç†ï¼ˆListå½¢å¼ã¨Dictå½¢å¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆï¼‰
        if personas is None:
            # personasãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€è¨­å®šã‹ã‚‰èª­ã¿è¾¼ã‚€
            personas_cfg = getattr(cfg.env, "personas", None)
            if debug:
                print(f"[ConvoEnv.__init__] personas_cfg type: {type(personas_cfg)}")
                print(f"[ConvoEnv.__init__] personas_cfg keys: {personas_cfg.keys() if isinstance(personas_cfg, dict) else 'N/A'}")
            if personas_cfg and isinstance(personas_cfg, dict):
                self.persona_pool: List[str] = sorted(personas_cfg.keys())
                self.persona_triggers: Dict[str, List[str]] = {
                    name: info.get("triggers", []) if isinstance(info, dict) else []
                    for name, info in personas_cfg.items()
                }
                if debug:
                    print(f"[ConvoEnv.__init__] persona_pool: {self.persona_pool}")
                    print(f"[ConvoEnv.__init__] persona_triggers: {self.persona_triggers}")
            else:
                self.persona_pool: List[str] = []
                self.persona_triggers: Dict[str, List[str]] = {}
                if debug:
                    print(f"[ConvoEnv.__init__] personas_cfg is None or not dict, persona_triggers set to empty")
        elif isinstance(personas, dict):
            # Dictå½¢å¼: {"A": {"triggers": [...]}, "B": {...}, ...}
            self.persona_pool = sorted(personas.keys())
            self.persona_triggers = {
                name: info.get("triggers", []) if isinstance(info, dict) else []
                for name, info in personas.items()
            }
            if debug:
                print(f"[ConvoEnv.__init__] Dict personas provided")
                print(f"[ConvoEnv.__init__] persona_pool: {self.persona_pool}")
                print(f"[ConvoEnv.__init__] persona_triggers: {self.persona_triggers}")
        else:
            # Listå½¢å¼ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰: ["A", "B", "C"]
            persona_list = [p for p in personas if p]
            self.persona_pool = list(persona_list)
            self.persona_triggers = {}
            if debug:
                print(f"[ConvoEnv.__init__] List personas provided, persona_triggers set to empty")

        # persona_pool ãŒåˆæœŸåŒ–ã•ã‚ŒãŸã®ã§ã€æ­£ç¢ºãª target_human_utterances ã‚’è¨ˆç®—
        num_personas = len(self.persona_pool) if self.persona_pool else 3
        self.target_human_utterances = self.max_rounds * num_personas

        self._scorer_kwargs = {
            "backend": backend,
            "use_ema": use_ema_cfg,
            "decay_factor": float(decay_factor),
            "verbose": bool(debug),
        }
        self.scorer = RelationScorer(**self._scorer_kwargs)

        self.logs: List[Dict[str, Any]] = []
        self.episode = 0
        self._episode_step = 0
        self.t = 0
        self.total_steps = 0
        self.used_topics: List[str] = []  # æ—¢ã«ä½¿ç”¨ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ
        self.used_triggers: List[str] = []  # æ—¢ã«ä½¿ç”¨ã—ãŸåœ°é›·ã®ãƒªã‚¹ãƒˆ
        self.current_topic: Optional[str] = None  # ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯
        self.current_topic_trigger: Optional[str] = None  # ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯ã®å…ƒã«ãªã£ãŸåœ°é›·
        self._last_step_relations: Optional[Dict[str, Any]] = None  # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ï¼ˆevaluation_horizonå¾Œã¾ãŸã¯terminal_bonus_durationå¾Œï¼‰

        self._last_observation: Optional[str] = None
        self.reset()

    def reset(self) -> str:
        # ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦åˆæœŸçŠ¶æ…‹ã‚’è¿”ã™
        self.episode += 1
        self._episode_step = 0
        self._unstable_step = 0  # ä¸å®‰å®šãªã‚¿ãƒ¼ãƒ³ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã‚‹ã‚¿ãƒ¼ãƒ³ï¼‰ã®ã‚«ã‚¦ãƒ³ãƒˆ
        self.t = 0
        self.logs = []
        self.scorer = RelationScorer(**self._scorer_kwargs)

        # ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å±¥æ­´ã®ãƒªã‚»ãƒƒãƒˆ
        self.steps_since_last_intervention = 0
        self.stable_step_start = None
        self.terminal_bonus_given = False
        self._last_step_relations = None  # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®é–¢ä¿‚æ€§ã‚’ãƒªã‚»ãƒƒãƒˆ

        # å‰ã‚¹ãƒ†ãƒƒãƒ—çŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆ
        self.previous_intervened = False
        self.previous_rel_after_horizon = None
        self.previous_rel_after_bonus = None

        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã«å„è©±è€…ã®éæ¿€åº¦ã‚’è¨­å®šï¼ˆ50%ã®ç¢ºç‡ã§ãƒã‚¤ãƒ«ãƒ‰ã¾ãŸã¯éæ¿€ï¼‰
        import random
        self.speaker_aggressiveness = {}
        for speaker in self.persona_pool:
            self.speaker_aggressiveness[speaker] = random.random() < 0.5  # True=éæ¿€, False=ãƒã‚¤ãƒ«ãƒ‰

        if self.debug:
            aggr_str = ", ".join([f"{s}: {'éæ¿€' if is_aggr else 'ãƒã‚¤ãƒ«ãƒ‰'}"
                                   for s, is_aggr in self.speaker_aggressiveness.items()])
            print(f"[reset] Episode {self.episode} è©±è€…éæ¿€åº¦è¨­å®š: {aggr_str}")

        # æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦
        emotional_needs_pool = ["recognition", "mediation", "solution", "independence"]
        self.persona_emotional_needs = {}
        for speaker in self.persona_pool:
            self.persona_emotional_needs[speaker] = random.choice(emotional_needs_pool)

        if self.debug:
            needs_str = ", ".join([f"{s}: {need}" for s, need in self.persona_emotional_needs.items()])
            print(f"  ğŸ’­ æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºå‰²ã‚Šå½“ã¦: {needs_str}")

        # ãƒˆãƒ”ãƒƒã‚¯ã‚’ç”Ÿæˆ
        self.current_topic = self._get_topic_suggestion()
        self.used_topics.append(self.current_topic)

        # åˆæœŸä¼šè©±ã‚’ç”Ÿæˆï¼ˆevaluation_horizonå›ã®ã‚¿ãƒ¼ãƒ³ = é€šå¸¸1ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
        self._bootstrap_humans(self.evaluation_horizon)

        # å®‰å®šçŠ¶æ…‹ã®è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåˆæœŸä¼šè©±ã§ã‚‚é©ç”¨ï¼‰
        # step()ã¨åŒæ§˜ã«ã€å®‰å®šã§ã‚ã‚Œã°max_auto_skipå›ã¾ã§äººé–“ç™ºè©±ã‚’ç”Ÿæˆ
        auto_skip_count = 0
        max_auto_skip = int(getattr(self, "max_auto_skip", 10))
        initial_conversation_log = []  # åˆæœŸä¼šè©±ã‚’è¨˜éŒ²

        if self.debug:
            print(f"  [reset auto_skip] max_auto_skip={max_auto_skip}")

        # åˆæœŸä¼šè©±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        for log_entry in self.logs:
            if log_entry.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ":
                initial_conversation_log.append({
                    "speaker": log_entry.get("speaker"),
                    "utterance": log_entry.get("utterance"),
                })

        while auto_skip_count < max_auto_skip:
            # é–¢ä¿‚æ€§ã‚’è©•ä¾¡
            participants = self._participants(self.logs)
            human_utterance_count = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')

            if human_utterance_count >= self.start_relation_check_after_utterances:
                filtered_logs = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
                try:
                    scores, _ = self._relation_state(filtered_logs, update_state=True)
                    metrics, _ = self._metrics_state(scores, participants)
                    unstable_count = metrics.get("unstable_triads", 0)

                    # ä¸å®‰å®šãªã‚‰æŠœã‘ã‚‹
                    if unstable_count > 0:
                        if self.debug:
                            print(f"  [reset auto_skip] ä¸å®‰å®šã«ãªã£ãŸã®ã§ãƒ«ãƒ¼ãƒ—çµ‚äº† (unstable_triads={unstable_count}, auto_skip_count={auto_skip_count})")
                        break

                    # å®‰å®šãªã‚‰äººé–“ç™ºè©±ã‚’1ã¤ç”Ÿæˆ
                    auto_skip_count += 1
                    if self.debug:
                        print(f"  [reset auto_skip] å®‰å®šçŠ¶æ…‹ã‚’æ¤œå‡ºã€äººé–“ç™ºè©±ã‚’è‡ªå‹•ç”Ÿæˆ ({auto_skip_count}/{max_auto_skip})")

                    replies = human_reply(self.logs, self.persona_pool, topic=self.current_topic, topic_trigger=self.current_topic_trigger, num_speakers=1, speaker_aggressiveness=self.speaker_aggressiveness)
                    if replies:
                        self.logs.extend(replies)
                        # åˆæœŸä¼šè©±ãƒ­ã‚°ã«ã‚‚è¿½åŠ 
                        for r in replies:
                            if r.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ":
                                initial_conversation_log.append({
                                    "speaker": r.get("speaker"),
                                    "utterance": r.get("utterance"),
                                })
                    else:
                        if self.debug:
                            print(f"  [reset auto_skip] ç™ºè©±ç”Ÿæˆå¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—çµ‚äº† (auto_skip_count={auto_skip_count})")
                        break

                except Exception as e:
                    if self.debug:
                        print(f"  [reset auto_skip] é–¢ä¿‚æ€§è©•ä¾¡ã«å¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—çµ‚äº†: {e}")
                    break
            else:
                # ã¾ã 3ç™ºè©±ã«é”ã—ã¦ã„ãªã„ã®ã§æŠœã‘ã‚‹
                if self.debug:
                    print(f"  [reset auto_skip] ã¾ã {self.start_relation_check_after_utterances}ç™ºè©±æœªæº€ã€ã‚¹ã‚­ãƒƒãƒ—çµ‚äº†")
                break

        # åˆæœŸä¼šè©±ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆstep()ã§å‚ç…§ã§ãã‚‹ã‚ˆã†ã«ï¼‰
        self.initial_conversation_log = initial_conversation_log

        # max_auto_skipå›è©¦ã—ã¦ã‚‚ä¸å®‰å®šã«ãªã‚‰ãªã‹ã£ãŸå ´åˆã¯è©±é¡Œã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
        if auto_skip_count >= max_auto_skip:
            if self.debug:
                print(f"  [reset auto_skip] {max_auto_skip}å›è©¦ã—ã¦ã‚‚ä¸å®‰å®šã«ãªã‚‰ãš â†’ è©±é¡Œã‚’åˆ‡ã‚Šæ›¿ãˆ")

            # æ–°ã—ã„è©±é¡Œã‚’ç”Ÿæˆ
            self.current_topic = self._get_topic_suggestion()
            self.used_topics.append(self.current_topic)

            # ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢ã—ã¦æ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯ã§åˆæœŸä¼šè©±ã‚’ç”Ÿæˆ
            self.logs = []
            self.scorer = RelationScorer(**self._scorer_kwargs)
            self._bootstrap_humans(self.evaluation_horizon)

        observation = self._make_observation()
        self._last_observation = observation
        return observation

    def step(self, action: str) -> Tuple[str, float, bool, Dict[str, Any]]:
        """
        ç’°å¢ƒã«1ã‚¹ãƒ†ãƒƒãƒ—ä½œç”¨ã‚’ä¸ãˆã€(æ¬¡çŠ¶æ…‹, å ±é…¬, çµ‚äº†ãƒ•ãƒ©ã‚°, æƒ…å ±è¾æ›¸) ã‚’è¿”ã™

        å³åº§å ±é…¬ã®è¨­è¨ˆï¼ˆIMMEDIATE_REWARD_DESIGN.mdã‚’å‚ç…§ï¼‰:
        1. äººé–“ç™ºè©±ã‚’1å›ç”Ÿæˆ
        2. é–¢ä¿‚æ€§ã‚’è©•ä¾¡
        3. å®‰å®šãªã‚‰å ±é…¬ãªã—ã§çµ‚äº†
        4. ä¸å®‰å®šãªã‚‰ä»‹å…¥åˆ¤å®š
        5. ä»‹å…¥ã™ã‚‹å ´åˆ:
           - evaluation_horizonå›ã®äººé–“ç™ºè©±ã‚’å†…éƒ¨ç”Ÿæˆï¼ˆä¸¦è¡Œå‡¦ç†ï¼‰
           - åå®Ÿä»®æƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸¦è¡Œå®Ÿè¡Œ
           - å®‰å®šã«ãªã£ãŸã‚‰terminal_bonus_durationå›è¿½åŠ 
        6. å ±é…¬ã‚’è¨ˆç®—ã—ã¦å³åº§ã«è¿”ã™

        ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€PPOãŒå­¦ç¿’å¯èƒ½ãªå³åº§å ±é…¬ã‚’å®Ÿç¾
        """
        if self.debug:
            print(f"\nğŸ”§ [DEBUG] step() é–‹å§‹")
            print(f"  ç¾åœ¨ã®ãƒ­ã‚°æ•°: {len(self.logs)}")
            print(f"  _episode_step: {self._episode_step}")
            print(f"  steps_since_last_intervention: {self.steps_since_last_intervention}")
            print(f"  previous_intervened: {self.previous_intervened}")

        # å‰ã‚¹ãƒ†ãƒƒãƒ—ã®ä»‹å…¥çŠ¶æ…‹ã«åŸºã¥ã„ã¦å‡¦ç†
        human_replies_before = []  # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ç”Ÿæˆã—ãŸäººé–“ç™ºè©±ã‚’ä¿å­˜

        # äººé–“ç™ºè©±ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æ¡ä»¶ï¼š
        # 1. å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä»‹å…¥ã—ãŸå ´åˆï¼ˆevaluation_horizonå¾Œã®ç™ºè©±ãŒæ—¢ã«ç”Ÿæˆæ¸ˆã¿ï¼‰
        # 2. ã‚¹ãƒ†ãƒƒãƒ—1ã®å ´åˆï¼ˆreset()ã§3ç™ºè©±ãŒæ—¢ã«ç”Ÿæˆæ¸ˆã¿ï¼‰
        skip_human_generation = self.previous_intervened or self._episode_step == 0

        if skip_human_generation:
            # å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€çµ‚é–¢ä¿‚æ€§ã‚’å¼•ãç¶™ãï¼ˆrel_after_bonus ã‚’å„ªå…ˆï¼‰
            if self.previous_intervened:
                if self.previous_rel_after_bonus:
                    rel_before_snapshot = self.previous_rel_after_bonus
                    if self.debug:
                        print(f"  ä½¿ç”¨: å‰ã®rel_after_bonus")
                elif self.previous_rel_after_horizon:
                    rel_before_snapshot = self.previous_rel_after_horizon
                    if self.debug:
                        print(f"  ä½¿ç”¨: å‰ã®rel_after_horizon")
                else:
                    rel_before_snapshot = {}
                    if self.debug:
                        print(f"  ä½¿ç”¨: ç©ºã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ")
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—1: reset()ã§æ—¢ã«ç™ºè©±ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹
                rel_before_snapshot = self.relation_snapshot()
                if self.debug:
                    print(f"  ã‚¹ãƒ†ãƒƒãƒ—1: reset()ã§æ—¢ã«{len(self.logs)}ç™ºè©±ç”Ÿæˆæ¸ˆã¿")
        else:
            # äººé–“1ç™ºè©±ç”Ÿæˆ
            replies = human_reply(self.logs, self.persona_pool, topic=self.current_topic, topic_trigger=self.current_topic_trigger, num_speakers=1, speaker_aggressiveness=self.speaker_aggressiveness)
            if replies:
                self.logs.extend(replies)
                human_replies_before = replies  # ç”Ÿæˆã—ãŸäººé–“ç™ºè©±ã‚’ä¿å­˜
                if self.debug:
                    print(f"  ç”Ÿæˆã—ãŸäººé–“ç™ºè©±: {len(replies)}ä»¶")
            # é–¢ä¿‚æ€§ã®äº‹å‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            rel_before_snapshot = self.relation_snapshot()
            if self.debug:
                print(f"  rel_before_snapshotå–å¾—")

        # å®‰å®šçŠ¶æ…‹ã®è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—ï¼ˆPPOå­¦ç¿’ã®åŠ¹ç‡åŒ–ï¼‰
        # filter_zero_rewards=trueã®å ´åˆã€å®‰å®šçŠ¶æ…‹ã§ã¯ä¸å®‰å®šã«ãªã‚‹ã¾ã§äººé–“ç™ºè©±ã‚’è‡ªå‹•ç”Ÿæˆ
        skip_stable = getattr(get_config().ppo, "filter_zero_rewards", False)
        auto_skip_count = 0
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å±æ€§ã‚’ä½¿ã†ï¼ˆã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã‚„è¨­å®šã§å¤‰æ›´å¯èƒ½ï¼‰
        max_auto_skip = int(getattr(self, "max_auto_skip", 10))

        # skip_stableãŒç„¡åŠ¹ã®å ´åˆã¯ã€auto_skipã‚’å®Ÿè¡Œã—ãªã„
        if not skip_stable:
            max_auto_skip = 0

        # auto-skip loop: å®‰å®šçŠ¶æ…‹ã®é–“ã€äººé–“ç™ºè©±ã‚’è‡ªå‹•ç”Ÿæˆã—ã¦é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡ã™ã‚‹
        # ä¸å®‰å®šã«ãªã‚‹ã¾ã§äººé–“ç™ºè©±ã‚’ç”Ÿæˆã—ç¶šã‘ã€human_replies_beforeã«è“„ç©ã™ã‚‹
        # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã®é–¢ä¿‚æ€§è©•ä¾¡çµæœã‚’ä¿å­˜
        final_rel_metrics = None
        final_rel_scores = None

        # ãƒ«ãƒ¼ãƒ—é–‹å§‹å‰ã«åˆæœŸé–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆprevious_intervenedã®å ´åˆã¯è©•ä¾¡ãŒå¿…è¦ï¼‰
        if skip_stable and rel_before_snapshot.get("metrics", {}).get("unstable_triads") is None:
            # metricsãŒãªã„å ´åˆã¯æ–°è¦è©•ä¾¡
            try:
                participants = self._participants(self.logs)
                human_utterance_count = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if human_utterance_count >= self.start_relation_check_after_utterances:
                    filtered_logs = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
                    scores_init, _ = self._relation_state(filtered_logs, update_state=False)
                    metrics_init, _ = self._metrics_state(scores_init, participants)
                    rel_before_snapshot = {
                        "metrics": metrics_init,
                        "unstable_triads": metrics_init.get("unstable_triads", 0),
                        "edges": metrics_init.get("edges", {}),
                    }
                    if self.debug:
                        print(f"  [auto_skip] åˆæœŸé–¢ä¿‚æ€§ã‚’è©•ä¾¡: unstable_triads={metrics_init.get('unstable_triads', 0)}")
            except Exception as e:
                if self.debug:
                    print(f"  [auto_skip] åˆæœŸé–¢ä¿‚æ€§è©•ä¾¡ã«å¤±æ•—: {e}")

        if self.debug:
            print(f"  [auto_skip] skip_stable={skip_stable}, max_auto_skip={max_auto_skip}")
            print(f"  [auto_skip] ç¾åœ¨ã®é–¢ä¿‚æ€§: unstable_triads={rel_before_snapshot.get('metrics', {}).get('unstable_triads', 'N/A')}")

        while skip_stable and auto_skip_count < max_auto_skip:
            # rel_before_snapshot ã¯å‰ãƒ«ãƒ¼ãƒ—ã§ã®è©•ä¾¡çµæœã‚’è¡¨ã™
            current_rel = rel_before_snapshot
            if isinstance(current_rel, dict):
                if "metrics" in current_rel:
                    unstable_count = current_rel["metrics"].get("unstable_triads", 0)
                else:
                    unstable_count = current_rel.get("unstable_triads", 0)
            else:
                unstable_count = 0

            # ä¸å®‰å®šãªã‚‰æŠœã‘ã‚‹
            if unstable_count > 0:
                if self.debug:
                    print(f"  [auto_skip] ä¸å®‰å®šã«ãªã£ãŸã®ã§ãƒ«ãƒ¼ãƒ—çµ‚äº† (unstable_triads={unstable_count}, auto_skip_count={auto_skip_count})")
                break

            # å®‰å®šãªã‚‰äººé–“ç™ºè©±ã‚’1ã¤ç”Ÿæˆã—ã¦å†è©•ä¾¡
            auto_skip_count += 1
            if self.debug:
                print(f"  [auto_skip] å®‰å®šçŠ¶æ…‹ã‚’æ¤œå‡ºã€äººé–“ç™ºè©±ã‚’è‡ªå‹•ç”Ÿæˆ ({auto_skip_count}/{max_auto_skip})")

            replies = human_reply(self.logs, self.persona_pool, topic=self.current_topic, topic_trigger=self.current_topic_trigger, num_speakers=1, speaker_aggressiveness=self.speaker_aggressiveness)
            if replies:
                # å®‰å®šæ™‚ã«ç”Ÿæˆã•ã‚ŒãŸç™ºè©±ã‚’ self.logs ã«è¿½åŠ ï¼ˆå®Ÿç’°å¢ƒã®ä¼šè©±å±¥æ­´ã¨ã—ã¦ä¿å­˜ï¼‰
                self.logs.extend(replies)
                # human_replies_before ã«ã‚‚è¿½åŠ ï¼ˆinfoè¾æ›¸ã§è¿”ã™ãŸã‚ï¼‰
                human_replies_before.extend(replies)

                # é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡ã™ã‚‹ï¼ˆupdate_state=True ã§æ°¸ç¶šçš„ã«æ›´æ–°ï¼‰
                try:
                    scores_new, _ = self._relation_state(self.logs, update_state=True)
                    metrics_new, _ = self._metrics_state(scores_new, self._participants(self.logs))
                    rel_before_snapshot = {
                        "metrics": metrics_new,
                        "unstable_triads": metrics_new.get("unstable_triads", 0),
                        "edges": metrics_new.get("edges", {}),
                    }
                    # ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã«ä½¿ã†ãŸã‚ã«ä¿å­˜
                    final_rel_metrics = metrics_new
                    final_rel_scores = scores_new

                    if self.debug:
                        print(f"  [auto_skip] é–¢ä¿‚æ€§å†è©•ä¾¡å®Œäº†: unstable_triads={metrics_new.get('unstable_triads', 0)}, auto_skip_count={auto_skip_count}")
                except Exception as e:
                    # ä¸‡ä¸€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§å¤±æ•—ã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦å®‰å…¨å´ã«
                    if self.debug:
                        print(f"  [auto_skip] é–¢ä¿‚æ€§è©•ä¾¡ã«å¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—çµ‚äº†: {e}")
                    break
            else:
                # ç™ºè©±ç”Ÿæˆã«å¤±æ•—ã—ãŸã‚‰æŠœã‘ã‚‹
                if self.debug:
                    print(f"  [auto_skip] ç™ºè©±ç”Ÿæˆå¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—çµ‚äº† (auto_skip_count={auto_skip_count})")
                break

        if self.debug:
            print(f"  [auto_skip] ãƒ«ãƒ¼ãƒ—çµ‚äº†: auto_skip_count={auto_skip_count}, human_replies_before={len(human_replies_before)}ä»¶")

        # auto_skipãƒ«ãƒ¼ãƒ—ã®çµæœã‚’è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        reached_max_auto_skip = auto_skip_count >= max_auto_skip

        # ä»‹å…¥åˆ¤å®š
        current_rel = rel_before_snapshot
        # rel_before_snapshotã®æ§‹é€ ã«å¯¾å¿œ: relation_snapshot()ã¯metricsã‚­ãƒ¼ã‚ã‚Šã€info["rel_after_*"]ã¯metricsã‚­ãƒ¼ãªã—
        if isinstance(current_rel, dict):
            if "metrics" in current_rel:
                unstable_count = current_rel["metrics"].get("unstable_triads", 0)
                edges = current_rel["metrics"].get("edges", {})
            else:
                unstable_count = current_rel.get("unstable_triads", 0)
                edges = current_rel.get("edges", {})
        else:
            unstable_count = 0
            edges = {}

        # é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãŒä¸å®Œå…¨ãªå ´åˆï¼ˆedgesãŒç©ºï¼‰ã¯ä»‹å…¥åˆ¤å®šã‚’è¡Œã†
        # ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ç™ºè©±ãŒç”Ÿæˆã•ã‚ŒãŸå¾Œã«å¿…ãšä»‹å…¥åˆ¤å®šãŒè¡Œã‚ã‚Œã‚‹
        is_relation_incomplete = (not edges) or (not current_rel)
        should_skip_intervention_check = (unstable_count == 0) and (not is_relation_incomplete)

        if self.debug:
            print(f"  é–¢ä¿‚æ€§è©•ä¾¡: ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {unstable_count}, edges: {len(edges)}, é–¢ä¿‚æ€§ä¸å®Œå…¨: {is_relation_incomplete}")
            print(f"  ä»‹å…¥åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—: {should_skip_intervention_check}")

        if should_skip_intervention_check:
            # å®‰å®šçŠ¶æ…‹ â†’ æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå ±é…¬ãªã—ï¼‰
            intervened = False  # å®‰å®šçŠ¶æ…‹ã®ãŸã‚ä»‹å…¥ã—ã¦ã„ãªã„
            final_balanced = unstable_count == 0
            final_metrics = current_rel.get("metrics", {}) if isinstance(current_rel, dict) else {}
            reward = 0.0
            reward_breakdown = {}
            next_observation = self._make_observation()

            # ã‚¹ãƒ†ãƒƒãƒ—ã‚«ã‚¦ãƒ³ã‚¿ã‚’æ›´æ–°
            self.steps_since_last_intervention += 1
            self._episode_step += 1
            self.t += 1
            self.total_steps += 1

            # çµ‚äº†æ¡ä»¶
            # 1. max_auto_skipå›è©¦ã—ã¦ä¸å®‰å®šã«ãªã‚‰ãªã‹ã£ãŸå ´åˆ
            # 2. max_stepsã«é”ã—ãŸå ´åˆ
            # 3. skip_stableãŒæœ‰åŠ¹ã§å®‰å®šçŠ¶æ…‹ãŒç¶šãå ´åˆï¼ˆfilter_zero_rewardsã®æ„å›³ï¼‰
            if reached_max_auto_skip:
                done = True
                if self.debug:
                    print(f"  [auto_skip] {max_auto_skip}å›è©¦ã—ã¦ã‚‚ä¸å®‰å®šã«ãªã‚‰ãš â†’ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†")
            elif self.t >= self.max_steps:
                done = True
                if self.debug:
                    print(f"  max_stepsã«é”ã—ãŸãŸã‚ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº† (t={self.t}, max_steps={self.max_steps})")
            elif skip_stable and max_auto_skip > 0:
                # filter_zero_rewardsãŒæœ‰åŠ¹ãªå ´åˆã€å®‰å®šçŠ¶æ…‹ã§å ±é…¬0ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é¿ã‘ã‚‹ãŸã‚çµ‚äº†
                done = True
                if self.debug:
                    print(f"  [filter_zero_rewards] å®‰å®šçŠ¶æ…‹ã®ãŸã‚ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ï¼ˆå ±é…¬0ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            else:
                done = False

            # infoè¾æ›¸
            info: Dict[str, Any] = {
                "plan": None,
                "plan_error": None,
                "intervened": False,
                "balanced": final_balanced,
                "robot_utterance": None,
                "replies": human_replies_before,  # ç”Ÿæˆã—ãŸäººé–“ç™ºè©±ã‚’è¿½åŠ ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
                "human_utterance_before_relation": human_replies_before,  # ãƒ­ã‚°é †åºèª¿æ•´ç”¨
                "rel": final_metrics,
                "reward_breakdown": reward_breakdown,
                "personas": list(self.persona_pool),
                # ãƒ‡ãƒãƒƒã‚°ç”¨: ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆmetricsã‚’å«ã‚€ï¼‰
                "rel_before": rel_before_snapshot.get("metrics") if isinstance(rel_before_snapshot, dict) else {},
                "next_observation": next_observation,
            }

            # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§çŠ¶æ…‹ã‚’è¿½åŠ 
            # rel_before_snapshotã®æ§‹é€ ã«å¯¾å¿œ
            if isinstance(rel_before_snapshot, dict):
                if "metrics" in rel_before_snapshot:
                    rel_before_metrics = rel_before_snapshot["metrics"]
                else:
                    rel_before_metrics = rel_before_snapshot
            else:
                rel_before_metrics = {}
            unstable_count_before = rel_before_metrics.get("unstable_triads", 0)
            info["status"] = {
                "is_stable": unstable_count_before == 0,
                "edges": rel_before_metrics.get("edges", {}),
            }

            # å ±é…¬ã®å†…è¨³ãŒç©ºã®å ´åˆã¯æ³¨è¨˜
            if not reward_breakdown:
                info.setdefault("reward_notes", "no_breakdown_or_stable_no_reward")

            # previousæ›´æ–°
            self.previous_intervened = intervened
            self.previous_rel_after_horizon = None
            self.previous_rel_after_bonus = None

            self._last_observation = next_observation

            if self.debug:
                print(f"  âœ… å®‰å®šçŠ¶æ…‹ â†’ æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå ±é…¬ãªã—ï¼‰")
                print(f"    æœ€çµ‚å ±é…¬: {reward:.4f}")
                print(f"    done: {done}")

            return next_observation, reward, done, info

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ï¼ˆäººé–“ç™ºè©±ç”Ÿæˆå¾Œã€ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å‰ï¼‰
        snapshot_logs = [dict(entry) for entry in self.logs]

        # é–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆäººé–“ç™ºè©±ç”Ÿæˆå¾Œã®ãƒ­ã‚°ã‚’ä½¿ç”¨ï¼‰
        participants = self._participants(self.logs)
        human_utterance_count = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')

        # 3ç™ºè©±ä»¥ä¸Šã®å ´åˆã®ã¿é–¢ä¿‚æ€§è©•ä¾¡ã‚’è¡Œã„ã€å®‰å®šåˆ¤å®šã«ä½¿ç”¨
        if human_utterance_count >= self.start_relation_check_after_utterances:
            # auto_skipãƒ«ãƒ¼ãƒ—ã§æ—¢ã«è©•ä¾¡æ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼ˆå†è©•ä¾¡ã‚’é¿ã‘ã‚‹ï¼‰
            if final_rel_metrics is not None and final_rel_scores is not None:
                rel = final_rel_scores
                metrics = final_rel_metrics
                trace_scores = []
                trace_metrics = []
                if self.debug:
                    print(f"  [auto_skip] ãƒ«ãƒ¼ãƒ—å†…ã§è©•ä¾¡ã—ãŸé–¢ä¿‚æ€§ã‚’ä½¿ç”¨ï¼ˆå†è©•ä¾¡ãªã—ï¼‰")
            else:
                # ãƒ«ãƒ¼ãƒ—ãŒå®Ÿè¡Œã•ã‚Œãªã‹ã£ãŸå ´åˆã®ã¿æ–°è¦è©•ä¾¡
                filtered_logs = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
                rel, trace_scores = self._relation_state(filtered_logs, update_state=True)
                metrics, trace_metrics = self._metrics_state(rel, participants)

            is_stable = metrics.get("unstable_triads", 0) == 0 and bool(self.logs)

            if self.debug:
                print(f"  ğŸ“Š é–¢ä¿‚æ€§è©•ä¾¡:")
                print(f"    ä¸å®‰å®šãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ•°: {metrics.get('unstable_triads', 0)}")
                print(f"    å®‰å®šçŠ¶æ…‹: {is_stable}")

            # å®‰å®šãªå ´åˆã¯å ±é…¬ãªã—ã§çµ‚äº†
            if is_stable:
                if self.debug:
                    print(f"  âœ… å®‰å®šçŠ¶æ…‹ â†’ æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå ±é…¬ãªã—ï¼‰")
                    print(f"    ç”Ÿæˆã•ã‚ŒãŸäººé–“ç™ºè©±: {len(human_replies_before)}ä»¶")
                    print(f"    edges: {metrics.get('edges', {})}")

                # steps_since_last_interventionã‚’æ›´æ–°ï¼ˆä»‹å…¥ã—ãªã‹ã£ãŸã®ã§ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆï¼‰
                self.steps_since_last_intervention += 1

                self._episode_step += 1
                self.t += 1
                self.total_steps += 1

                # çµ‚äº†æ¡ä»¶: å®‰å®šçŠ¶æ…‹ã§ã¯ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ãªã„
                # FiniteOnlineDataset.__iter__()ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã€ä¸å®‰å®šã«ãªã‚‹ã¾ã§ç¶™ç¶š
                done = False

                next_observation = self._make_observation()
                self._last_observation = next_observation

                info = {
                    "plan": None,
                    "plan_error": None,
                    "intervened": False,
                    "balanced": True,
                    "robot_utterance": None,
                    "replies": [entry for entry in self.logs[len(snapshot_logs):]],
                    "human_utterance_before_relation": human_replies_before,  # ãƒ­ã‚°é †åºèª¿æ•´ç”¨
                    "rel": metrics,
                    "reward_breakdown": {},
                    "personas": list(self.persona_pool),
                    "next_observation": next_observation,
                    "status": {
                        "is_stable": True,
                        "edges": metrics.get("edges", {}),
                    },
                }

                return next_observation, 0.0, done, info
        else:
            # 3ç™ºè©±æœªæº€ã®å ´åˆã¯é–¢ä¿‚æ€§è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€ä»‹å…¥åˆ¤å®šã«é€²ã‚€
            rel = {}
            trace_scores = []
            metrics = {}
            trace_metrics = []
            is_stable = False

            if self.debug:
                print(f"  â­ï¸  é–¢ä¿‚æ€§è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆäººé–“ç™ºè©±æ•° {human_utterance_count} < {self.start_relation_check_after_utterances}ï¼‰")
                print(f"    ä»‹å…¥åˆ¤å®šã«é€²ã¿ã¾ã™")

        # ä¸å®‰å®šãªå ´åˆã¯ä»‹å…¥åˆ¤å®š
        if self.debug:
            print(f"  âŒ ä¸å®‰å®šçŠ¶æ…‹ â†’ ä»‹å…¥åˆ¤å®šã‚’å®Ÿè¡Œ")

        plan, plan_error, direct_utterance = self._parse_plan(action)

        if self.debug:
            print(f"  ğŸ“‹ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è§£æ:")
            if plan:
                print(f"    intervene_now: {plan.get('intervene_now', False)}")
                if plan.get('intervene_now'):
                    print(f"    edge_to_change: {plan.get('edge_to_change')}")
                    print(f"    strategy: {plan.get('strategy')}")
                    print(f"    target_speaker: {plan.get('target_speaker')}")
            if plan_error:
                print(f"    âš ï¸ ãƒ—ãƒ©ãƒ³ã‚¨ãƒ©ãƒ¼: {plan_error}")

        # ä»‹å…¥åˆ¤å®š
        robot_entry: Optional[Dict[str, Any]] = None
        intervened = False
        if plan and plan.get("intervene_now"):
            if self.debug:
                print(f"  ğŸ¤– ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ã‚’å®Ÿè¡Œ")
            robot_entry = self._render_intervention(plan, simulate=False)
            intervened = True
            if self.debug:
                print(f"    ç™ºè©±å†…å®¹: {robot_entry.get('utterance', '')[:80]}...")
        elif direct_utterance:
            robot_entry = {"speaker": "ãƒ­ãƒœãƒƒãƒˆ", "utterance": _strip_quotes(direct_utterance)}
            intervened = True
        else:
            if self.debug:
                print(f"  â­ï¸  ä»‹å…¥ã—ãªã„é¸æŠ")

        # å ±é…¬ã®åˆæœŸåŒ–
        reward = 0.0
        reward_breakdown: Dict[str, float] = {}

        # planã‹ã‚‰æˆ¦ç•¥æƒ…å ±ã‚’å–å¾—
        edge_to_change = plan.get("edge_to_change", "AB") if plan else "AB"
        target_speaker = plan.get("target_speaker", "A") if plan else "A"
        strategy = plan.get("strategy", "plan") if plan else "plan"

        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’è¿½åŠ ï¼ˆä»‹å…¥ã™ã‚‹å ´åˆã®ã¿ï¼‰
        if intervened:
            self.logs.append(robot_entry)

        # evaluation_horizonå›ã®äººé–“ç™ºè©±ã‚’ç”Ÿæˆ
        if self.debug:
            print(f"  ğŸ”„ {self.evaluation_horizon}å›ã®äººé–“ç™ºè©±ã‚’ç”Ÿæˆ")

        # æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºã¨æ­£è§£æˆ¦ç•¥ãƒ•ãƒ©ã‚°ã‚’æº–å‚™
        emotional_needs = self.persona_emotional_needs.copy()
        is_correct_strategy_flags = {}

        # å„è©±è€…ã«ã¤ã„ã¦æ­£è§£æˆ¦ç•¥ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        for speaker in self.persona_pool:
            preferred = self._get_human_preferred_strategy(speaker)
            # å¯¾è±¡è©±è€…ã®å ´åˆã¯å®Ÿéš›ã®æˆ¦ç•¥ã¨æ¯”è¼ƒã€ãã‚Œä»¥å¤–ã¯False
            if speaker == target_speaker:
                is_correct_strategy_flags[speaker] = (strategy == preferred)
            else:
                is_correct_strategy_flags[speaker] = False

        self._bootstrap_humans(
            self.evaluation_horizon,
            emotional_needs=emotional_needs,
            is_correct_strategy_flags=is_correct_strategy_flags
        )

        # evaluation_horizonå¾Œã®é–¢ä¿‚æ€§ã‚’è©•ä¾¡
        participants_after = self._participants(self.logs)
        human_utterance_count_after = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')

        if human_utterance_count_after >= self.start_relation_check_after_utterances:
            filtered_logs_after = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
            rel_after, _ = self._relation_state(filtered_logs_after, update_state=True)
        else:
            rel_after = {}

        metrics_after, _ = self._metrics_state(rel_after, participants_after)
        is_stable_after = metrics_after.get("unstable_triads", 0) == 0

        # å¯¾è±¡ã‚¨ãƒƒã‚¸ã®ã‚¹ã‚³ã‚¢ã‚’å–å¾—ï¼ˆstable_bonusåˆ¤å®šã«ä½¿ç”¨ï¼‰
        def get_edge_score(edge_str: str, scores_dict: Dict[Tuple[str, str], float]) -> float:
            """ã‚¨ãƒƒã‚¸æ–‡å­—åˆ—ï¼ˆ"AB"ãªã©ï¼‰ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
            if len(edge_str) >= 2:
                # ("A", "B") ã¾ãŸã¯ ("B", "A") ã‚’è©¦ã™
                edge_tuple1 = (edge_str[0], edge_str[1])
                edge_tuple2 = (edge_str[1], edge_str[0])
                return scores_dict.get(edge_tuple1, scores_dict.get(edge_tuple2, 0.0))
            return 0.0

        target_edge_score_after = get_edge_score(edge_to_change, rel_after)
        target_edge_positive_after = target_edge_score_after > 0

        if self.debug:
            print(f"  ğŸ“Š evaluation_horizonå¾Œã®é–¢ä¿‚æ€§:")
            print(f"    å®‰å®šçŠ¶æ…‹: {is_stable_after}")
            print(f"    å¯¾è±¡ã‚¨ãƒƒã‚¸ï¼ˆ{edge_to_change}ï¼‰ã‚¹ã‚³ã‚¢: {target_edge_score_after:.4f}")
            print(f"    å¯¾è±¡ã‚¨ãƒƒã‚¸ãŒæ­£: {target_edge_positive_after}")

        # å ±é…¬è¨ˆç®—: stable_bonus + preference_match_bonus
        rel_after_bonus = None  # terminal_bonus_durationå¾Œã®é–¢ä¿‚æ€§ã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°

        # stable_bonusä»˜ä¸æ¡ä»¶: å¯¾è±¡ã‚¨ãƒƒã‚¸ãŒæ­£ AND å…¨ä½“ãŒå®‰å®š
        if is_stable_after and target_edge_positive_after:
            if self.debug:
                print(f"  ğŸ¯ å®‰å®šé”æˆ & å¯¾è±¡ã‚¨ãƒƒã‚¸æ­£ â†’ terminal_bonusãƒã‚§ãƒƒã‚¯é–‹å§‹")
                print(f"    è¿½åŠ ã§{self.terminal_bonus_duration}äººé–“ç™ºè©±åˆ†ã®å®‰å®šæ€§ã‚’ç¢ºèª")
        elif self.debug:
            if not is_stable_after:
                print(f"  âš ï¸  å…¨ä½“ãŒä¸å®‰å®š â†’ stable_bonusãªã—")
            elif not target_edge_positive_after:
                print(f"  âš ï¸  å¯¾è±¡ã‚¨ãƒƒã‚¸ï¼ˆ{edge_to_change}ï¼‰ãŒæ­£ã§ãªã„ï¼ˆ{target_edge_score_after:.4f}ï¼‰ â†’ stable_bonusãªã—")

        if is_stable_after and target_edge_positive_after:

            # terminal_bonus_durationäººé–“ç™ºè©±ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯1ãƒ©ã‚¦ãƒ³ãƒ‰ = 3äººé–“ç™ºè©±ãŒæœ€å°å˜ä½ï¼‰
            # æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºã¨æ­£è§£æˆ¦ç•¥ãƒ•ãƒ©ã‚°ã‚’å¼•ãç¶™ã
            self._bootstrap_humans(
                self.terminal_bonus_duration,
                emotional_needs=emotional_needs,
                is_correct_strategy_flags=is_correct_strategy_flags
            )

            # æœ€å¾Œã®é–¢ä¿‚æ€§ã‚’å†è©•ä¾¡
            participants_check = self._participants(self.logs)
            human_count_check = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')

            stability_maintained = True
            target_edge_positive_check = False
            if human_count_check >= self.start_relation_check_after_utterances:
                filtered_check = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
                rel_check, _ = self._relation_state(filtered_check, update_state=True)
                metrics_check, _ = self._metrics_state(rel_check, participants_check)

                # å¯¾è±¡ã‚¨ãƒƒã‚¸ã®ã‚¹ã‚³ã‚¢ã‚’ãƒã‚§ãƒƒã‚¯
                target_edge_score_check = get_edge_score(edge_to_change, rel_check)
                target_edge_positive_check = target_edge_score_check > 0

                if metrics_check.get("unstable_triads", 0) > 0:
                    # ä¸å®‰å®šã«æˆ»ã£ãŸ
                    stability_maintained = False
                    if self.debug:
                        print(f"    âŒ ä¸å®‰å®šã«æˆ»ã£ãŸ")
                elif not target_edge_positive_check:
                    # å¯¾è±¡ã‚¨ãƒƒã‚¸ãŒè² ã¾ãŸã¯0ã«ãªã£ãŸ
                    stability_maintained = False
                    if self.debug:
                        print(f"    âŒ å¯¾è±¡ã‚¨ãƒƒã‚¸ï¼ˆ{edge_to_change}ï¼‰ãŒè² ã¾ãŸã¯0ã«: {target_edge_score_check:.4f}")
                else:
                    if self.debug:
                        print(f"    âœ… å®‰å®šç¶­æŒ & å¯¾è±¡ã‚¨ãƒƒã‚¸æ­£ï¼ˆ{target_edge_score_check:.4f}ï¼‰")

            # terminal_bonus_durationäººé–“ç™ºè©±å¾Œã‚‚å®‰å®šãŒç¶šãã€å¯¾è±¡ã‚¨ãƒƒã‚¸ã‚‚æ­£ã®å ´åˆ
            if stability_maintained and target_edge_positive_check:
                if self.debug:
                    print(f"  ğŸ å®‰å®šãŒæŒç¶š & å¯¾è±¡ã‚¨ãƒƒã‚¸æ­£ â†’ stable_bonusä»˜ä¸: +{self.stable_bonus:.4f}")
                reward += self.stable_bonus
                reward_breakdown["stable_bonus"] = self.stable_bonus
                # terminal_bonus_durationå¾Œã®é–¢ä¿‚æ€§ã‚’ä¿å­˜ï¼ˆå¾Œã§infoã«è¿½åŠ ï¼‰
                rel_after_bonus = metrics_check
            elif self.debug:
                if not stability_maintained:
                    print(f"  âš ï¸  å®‰å®šãŒæŒç¶šã›ãš â†’ stable_bonusãªã—")
                elif not target_edge_positive_check:
                    print(f"  âš ï¸  å¯¾è±¡ã‚¨ãƒƒã‚¸ãŒæ­£ã§ãªã„ â†’ stable_bonusãªã—")

        # æ­£è§£æˆ¦ç•¥ã®å ´åˆã€preference_match_bonusã‚’ä»˜ä¸
        preferred_strategy = self._get_human_preferred_strategy(target_speaker)
        is_correct_strategy = (strategy == preferred_strategy)
        if is_correct_strategy:
            reward += self.preference_match_bonus
            reward_breakdown["preference_match_bonus"] = self.preference_match_bonus
            if self.debug:
                print(f"  âœ… æ­£è§£æˆ¦ç•¥ï¼ˆ{strategy}ï¼‰ â†’ preference_match_bonusä»˜ä¸: +{self.preference_match_bonus:.4f}")

        if self.debug:
            print(f"  ğŸ’° æœ€çµ‚å ±é…¬: {reward:.4f}")

        if intervened:
            self.steps_since_last_intervention = 0
        else:
            self.steps_since_last_intervention += 1

        # ã‚¹ãƒ†ãƒƒãƒ—ã‚«ã‚¦ãƒ³ã‚¿ã‚’æ›´æ–°
        self._episode_step += 1
        self._unstable_step += 1  # ä¸å®‰å®šãªã‚¿ãƒ¼ãƒ³ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        self.t += 1
        self.total_steps += 1

        # æœ€çµ‚çš„ãªé–¢ä¿‚æ€§ã¨observation
        final_participants = self._participants(self.logs)
        final_human_count = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')

        # çµ‚äº†æ¡ä»¶: ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒmax_stepsã«é”ã—ãŸã‹ç¢ºèª
        done = self.t >= self.max_steps

        if final_human_count >= self.start_relation_check_after_utterances:
            final_filtered = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
            final_rel, _ = self._relation_state(final_filtered, update_state=True)
        else:
            final_rel = {}

        final_metrics, _ = self._metrics_state(final_rel, final_participants)
        final_balanced = final_metrics.get("unstable_triads", 0) == 0

        next_observation = self._make_observation()
        self._last_observation = next_observation

        if self.debug:
            print(f"  ğŸ step()å®Œäº†")
            print(f"    æœ€çµ‚å ±é…¬: {reward:.4f}")
            print(f"    done: {done}")
            print(f"    ç·ãƒ­ã‚°æ•°: {len(self.logs)}")

        # infoè¾æ›¸
        info: Dict[str, Any] = {
            "plan": plan,
            "plan_error": plan_error,
            "intervened": intervened,
            "balanced": final_balanced,
            "robot_utterance": robot_entry["utterance"] if robot_entry else None,
            "replies": [entry for entry in self.logs[len(snapshot_logs):]],
            "human_utterance_before_relation": human_replies_before,  # ãƒ­ã‚°é †åºèª¿æ•´ç”¨
            "rel": final_metrics,
            "reward_breakdown": reward_breakdown,
            "personas": list(self.persona_pool),
            # ãƒ‡ãƒãƒƒã‚°ç”¨: ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆmetricsã‚’å«ã‚€ï¼‰
            "rel_before": rel_before_snapshot.get("metrics") if isinstance(rel_before_snapshot, dict) else {},
            "next_observation": next_observation,
            # æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºã¨æˆ¦ç•¥æƒ…å ±
            "emotional_needs": dict(self.persona_emotional_needs),
            "target_speaker": target_speaker,
            "chosen_strategy": strategy,
            "preferred_strategy": preferred_strategy,
            "preference_match": is_correct_strategy,
            # å¯¾è±¡ã‚¨ãƒƒã‚¸æƒ…å ±ï¼ˆstable_bonusåˆ¤å®šç”¨ï¼‰
            "edge_to_change": edge_to_change,
            "target_edge_score_after": target_edge_score_after,
            "target_edge_positive_after": target_edge_positive_after,
        }

        # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ã®é–¢ä¿‚æ€§ã‚’è¿½åŠ ï¼ˆãƒ­ã‚°ç”¨ï¼‰
        # rel_before_snapshotã®æ§‹é€ ã«å¯¾å¿œ
        if isinstance(rel_before_snapshot, dict):
            if "metrics" in rel_before_snapshot:
                rel_before_metrics = rel_before_snapshot["metrics"]
            else:
                rel_before_metrics = rel_before_snapshot
        else:
            rel_before_metrics = {}
        unstable_count_before = rel_before_metrics.get("unstable_triads", 0)
        info["status"] = {
            "is_stable": unstable_count_before == 0,
            "edges": rel_before_metrics.get("edges", {}),
        }

        if self.debug:
            print(f"[ConvoEnv.step] DEBUG - info['status']:")
            print(f"  is_stable: {unstable_count_before == 0}")
            print(f"  edges: {rel_before_metrics.get('edges', {})}")

        # ä»‹å…¥ã—ãŸå ´åˆã€evaluation_horizonå¾Œã®é–¢ä¿‚æ€§ã‚’è¿½åŠ 
        if intervened:
            info["rel_after_horizon"] = metrics_after
            info["stable_after_horizon"] = is_stable_after

            # terminal_bonus_durationå¾Œã®é–¢ä¿‚æ€§ã‚’è¿½åŠ ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
            if rel_after_bonus is not None:
                info["rel_after_bonus"] = rel_after_bonus

        # å ±é…¬ã®å†…è¨³ãŒç©ºã®å ´åˆã¯æ³¨è¨˜ã‚’è¿½åŠ ï¼ˆå®‰å®šã§å ±é…¬è¨ˆç®—ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸç­‰ã®ç†ç”±ï¼‰
        if not reward_breakdown:
            info.setdefault("reward_notes", "no_breakdown_or_stable_no_reward")

        # previousæ›´æ–°
        self.previous_intervened = intervened
        self.previous_rel_after_horizon = info.get("rel_after_horizon") if intervened else None
        self.previous_rel_after_bonus = info.get("rel_after_bonus") if intervened and info.get("rel_after_bonus") else None

        return next_observation, reward, done, info

    def _get_topic_suggestion(self) -> str:
        """LLMã§è©±é¡Œã‚’ç”Ÿæˆã—ã€çŸ­ã„ãƒˆãƒ”ãƒƒã‚¯æ–‡å­—åˆ—ã‚’è¿”ã™ã€‚"""
        import random
        cfg = get_config()
        topic_cfg = getattr(cfg, "topic_manager", None)
        if not topic_cfg or not getattr(topic_cfg, "enable", False):
            # ãƒˆãƒ”ãƒƒã‚¯æ©Ÿèƒ½ãŒç„¡åŠ¹ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒˆãƒ”ãƒƒã‚¯ã‚’è¿”ã™
            self.current_topic_trigger = None
            return "è‡ªç”±ãªè©±é¡Œ"

        system = getattr(topic_cfg, "generation_prompt", "")

        # persona_triggersã‹ã‚‰ trigger_examples ã‚’ç”Ÿæˆ
        # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã ã‘é¸æŠï¼ˆæ—¢ã«é¸æŠæ¸ˆã¿ã®åœ°é›·ã¯é™¤å¤–ï¼‰
        selected_trigger = None
        if self.persona_triggers and "{trigger_examples}" in system:
            # å…¨personaã®triggersã‚’å¹³å¦åŒ–ï¼ˆé‡è¤‡ã‚’é™¤ãï¼‰
            all_triggers = []
            for triggers in self.persona_triggers.values():
                all_triggers.extend(triggers)
            # é‡è¤‡ã‚’é™¤å»
            all_triggers = list(set(all_triggers))

            if all_triggers:
                # ã¾ã é¸æŠã—ã¦ã„ãªã„åœ°é›·ã‚’å–å¾—
                available_triggers = [t for t in all_triggers if t not in self.used_triggers]

                # å…¨ã¦ã®åœ°é›·ãŒé¸æŠæ¸ˆã¿ã®å ´åˆã¯ãƒªã‚»ãƒƒãƒˆ
                if not available_triggers:
                    self.used_triggers = []
                    available_triggers = all_triggers

                # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã ã‘é¸æŠ
                selected_trigger = random.choice(available_triggers)
                self.used_triggers.append(selected_trigger)
                trigger_examples = selected_trigger
                system = system.replace("{trigger_examples}", trigger_examples)

                if self.debug:
                    print(f"[topic] é¸æŠã•ã‚ŒãŸåœ°é›·: {selected_trigger}")
                    print(f"[topic] åœ°é›·ã‚’æŒã¤ãƒšãƒ«ã‚½ãƒŠ: {[p for p, ts in self.persona_triggers.items() if selected_trigger in ts]}")
            else:
                # triggersãŒç©ºã®å ´åˆã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å‰Šé™¤
                system = system.replace("{trigger_examples}", "æ§˜ã€…ãªãƒ†ãƒ¼ãƒ")
                if self.debug:
                    print(f"[topic] åœ°é›·ãƒªã‚¹ãƒˆãŒç©ºã§ã™")
        else:
            if self.debug:
                print(f"[topic] persona_triggers: {bool(self.persona_triggers)}, has placeholder: {'{trigger_examples}' in system}")

        # é¸æŠã•ã‚ŒãŸåœ°é›·ã‚’ä¿å­˜ï¼ˆäººé–“LLMã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
        self.current_topic_trigger = selected_trigger

        if self.debug:
            print(f"[topic] current_topic_trigger: {self.current_topic_trigger}")

        used_str = "\n".join(f"- {t}" for t in self.used_topics) if self.used_topics else "(ãªã—)"
        prompt = f"[æ—¢ã«ææ¡ˆã—ãŸè©±é¡Œ]\n{used_str}"

        llm_cfg = getattr(cfg, "llm", None)
        client, deployment = get_azure_chat_completion_client(llm_cfg, model_type="topic")
        max_attempts = getattr(cfg.llm, "max_attempts", 5) or 5
        base_backoff = getattr(cfg.llm, "base_backoff", 0.5) or 0.5
        
        if client and deployment:
            messages = [{"role":"system","content":system},
                        {"role":"user","content":prompt}]
            for attempt in range(1, max_attempts + 1):
                try:
                    # GPT-5ã®å ´åˆã¯reasoningãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    params = build_chat_completion_params(deployment, messages, cfg.llm, temperature=1.0)
                    res = client.chat.completions.create(**params)
                    if res and getattr(res, "choices", None):
                        choice = res.choices[0]
                        message = getattr(choice, "message", None)
                        if isinstance(message, dict):
                            txt = message.get("content", "")
                        else:
                            txt = getattr(message, "content", "")
                        txt = (txt or "").strip()
                        if txt:
                            return txt
                except Exception as exc:
                    if self.debug:
                        print(f"[topic] attempt {attempt} failed:", exc)
                    if attempt < max_attempts:
                        import time
                        time.sleep(base_backoff * (2 ** (attempt - 1)))
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return "æœ€è¿‘ã®å‡ºæ¥äº‹ã«ã¤ã„ã¦"

    def planning_context(self) -> Dict[str, Any]:
        # é–¢ä¿‚å®‰å®šåŒ–ã®ãŸã‚ã®ä»‹å…¥è¨ˆç”»ã‚’ç«‹æ¡ˆã™ã‚‹
        weights = self._edge_weights(self.logs)
        u_flip, stable_sign, distances = self._compute_u_flip(weights)
        target_edge = "AB"
        if distances:
            target_edge = max(distances.items(), key=lambda kv: kv[1])[0]
        return {
            "scores": weights,
            "u_flip": u_flip,
            "stable_sign": stable_sign,
            "distances": distances,
            "target_edge": target_edge,
            "evaluation_horizon": self.evaluation_horizon,
            "time_penalty": self.time_penalty,
            "intervention_cost": self.intervention_cost,
            "balanced": self._is_balanced(),
        }

    def _make_observation(self) -> str:
        context = self.planning_context()
        # intervention_max_historyå€‹ã®äººé–“ç™ºè©± + ãã®é–“ã®ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’å–å¾—ï¼ˆä»‹å…¥åˆ¤å®šç”¨ï¼‰
        filtered_logs = filter_logs_by_human_count(self.logs, self.intervention_max_history)
        history_lines = [f"[{item.get('speaker', '?')}] {item.get('utterance', '').strip()}" for item in filtered_logs]
        if not history_lines:
            history_lines = ["(å±¥æ­´ãªã—)"]

        scores = context.get("scores", {}) or {"AB": 0.0, "BC": 0.0, "CA": 0.0}
        
        # æ”¹å–„ã™ã¹ãã‚¨ãƒƒã‚¸ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã‚’ç‰¹å®šï¼ˆå…±é€šé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        # â€»é‡è¦: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã¯ã“ã“ã§1å›ã ã‘ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã€
        #   å¾Œç¶šã®_parse_planã§å†åˆ©ç”¨ã™ã‚‹ï¼ˆ2å›é¸æŠã™ã‚‹ã¨ä¸æ•´åˆãŒç”Ÿã˜ã‚‹ãŸã‚ï¼‰
        # relation_snapshot()ã‹ã‚‰å–å¾—ã—ãŸã‚¨ãƒƒã‚¸æƒ…å ±ã‚’ä½¿ç”¨
        rel = self.relation_snapshot()
        if isinstance(rel, dict):
            metrics = rel.get("metrics", rel)
            edges = metrics.get("edges", {})
            if edges:
                target_edge, target_speaker = select_target_edge_and_speaker(
                    edges, 
                    debug=False,  # observationç”Ÿæˆæ™‚ã¯ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ä¸è¦
                    debug_prefix=""
                )
                # é¸æŠã—ãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã‚’ä¿å­˜ï¼ˆ_parse_planã§å†åˆ©ç”¨ï¼‰
                self._current_target_edge = target_edge
                self._current_target_speaker = target_speaker
                
                # ã‚¨ãƒƒã‚¸ã®ã‚¹ã‚³ã‚¢ã‚’å–å¾—
                # edgesã®ã‚­ãƒ¼ã¯ã‚¿ãƒ—ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€ä¸¡æ–¹ã®å½¢å¼ã‚’è©¦ã™
                target_score = None
                for edge_key, score in edges.items():
                    if isinstance(edge_key, tuple):
                        edge_str = "".join(str(c) for c in edge_key)
                    else:
                        edge_str = str(edge_key).replace(",", "").replace(" ", "").upper()
                    if edge_str == target_edge or edge_str == target_edge[::-1]:
                        target_score = score
                        break
                
                if target_score is None:
                    target_score = 0.0
            else:
                target_edge = "AB"
                target_score = 0.0
                target_speaker = "A"
                self._current_target_edge = target_edge
                self._current_target_speaker = target_speaker
        else:
            target_edge = "AB"
            target_score = 0.0
            target_speaker = "A"
            self._current_target_edge = target_edge
            self._current_target_speaker = target_speaker

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–: å¯å¤‰è¦ç´ ï¼ˆä¼šè©±å±¥æ­´ã€é–¢ä¿‚ã‚¹ã‚³ã‚¢ã€æ”¹å–„å¯¾è±¡ï¼‰ã‚’è¿”ã™
        # å›ºå®šèª¬æ˜ï¼ˆã‚¿ã‚¹ã‚¯ã€åˆ¶ç´„ã€æˆ¦ç•¥ï¼‰ã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ç§»å‹•æ¸ˆã¿ï¼ˆbuild_robot_messageså‚ç…§ï¼‰
        prompt_lines = [
            "å±¥æ­´:",
            *history_lines,
            "",
            "ç¾åœ¨ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆ-1..1ï¼‰: " + ", ".join(f"w_{edge}={value:+.2f}" for edge, value in scores.items()),
            "",
            f"æ”¹å–„ã™ã¹ãã‚¨ãƒƒã‚¸: {target_edge} (ç¾åœ¨: {target_score:+.2f})",
            f"ç™ºè©±å¯¾è±¡ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰: {target_speaker}",
        ]
        return "\n".join(prompt_lines)

    def _parse_plan(self, action: str) -> Tuple[Optional[Dict[str, Any]], Optional[str], Optional[str]]:
        # å…ˆé ­ãƒ»æœ«å°¾ã®å¼•ç”¨ç¬¦ã‚„æ‹¬å¼§ã‚’å‰Šã‚‹
        if action is None:
            return None, "empty_action", None
        text = action.strip()
        if not text:
            return None, "empty_action", None

        # æ–°å½¢å¼: æ•°å­—1-4ã®ãƒ‘ãƒ¼ã‚¹
        strategy_num = None
        for char in text:
            if char in '1234':
                strategy_num = int(char)
                break
        
        # JSONãƒ‘ãƒ¼ã‚¹ï¼ˆæ—§å½¢å¼ã¨ã®å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
        json_parsed = False
        payload = None
        try:
            payload = json.loads(text)
            json_parsed = True
        except json.JSONDecodeError:
            pass

        plan: Dict[str, Any] = {}

        # æ–°å½¢å¼ï¼ˆæ•°å­—ï¼‰ã®å‡¦ç†
        if strategy_num is not None:
            strategy_map = {
                1: "validate",
                2: "bridge",
                3: "plan",
                4: "no_intervention"
            }
            
            strategy = strategy_map.get(strategy_num)
            if not strategy:
                return None, "invalid_strategy_number", text

            # edge_to_changeã¨target_speakerã¯_make_observationã§æ—¢ã«é¸æŠæ¸ˆã¿
            # â€»é‡è¦: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè©±è€…ã‚’ã“ã“ã§å†é¸æŠã™ã‚‹ã¨ã€LLMã«æç¤ºã—ãŸå€¤ã¨ç•°ãªã‚‹å€¤ã«ãªã‚‹
            #   å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€_make_observationã§é¸æŠã—ãŸå€¤ã‚’å†åˆ©ç”¨ã™ã‚‹
            edge_to_change = getattr(self, '_current_target_edge', None)
            target_speaker = getattr(self, '_current_target_speaker', None)

            if strategy == "no_intervention":
                plan["intervene_now"] = False
                # ä»‹å…¥ãªã—ã®å ´åˆã§ã‚‚edge_to_changeã¨target_speakerã‚’è¨˜éŒ²ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰
                plan["edge_to_change"] = edge_to_change
                plan["target_speaker"] = target_speaker
                return plan, None, None

            # ä»‹å…¥ã‚ã‚Šã®å ´åˆ
            plan["intervene_now"] = True
            plan["strategy"] = strategy
            plan["edge_to_change"] = edge_to_change
            plan["target_speaker"] = target_speaker

            return plan, None, None

        # æ—§å½¢å¼ï¼ˆJSONï¼‰ã®å‡¦ç†ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
        elif json_parsed and isinstance(payload, dict):
            intervene_now = _coerce_bool(payload.get("intervene_now"))
            if intervene_now is None:
                intervene_now = bool(payload.get("intervene_now"))
            plan["intervene_now"] = bool(intervene_now)

            edge_raw = str(payload.get("edge_to_change", "AB")).upper().strip()
            if edge_raw not in {"AB", "BC", "CA"}:
                edge_raw = "AB"
            plan["edge_to_change"] = edge_raw

            strategy_raw = str(payload.get("strategy", "plan")).strip()
            if strategy_raw not in _PLANNER_STRATEGIES:
                strategy_raw = "plan"
            plan["strategy"] = strategy_raw

            target_raw = str(payload.get("target_speaker", "A")).upper().strip()
            if target_raw not in {"A", "B", "C"}:
                target_raw = "A"
            plan["target_speaker"] = target_raw

            return plan, None, None
        
        else:
            return None, "not_json_or_number", text

    def _render_intervention(self, plan: Dict[str, Any], *, simulate: bool) -> Dict[str, Any]:
        # ä»‹å…¥ç™ºè©±ã‚’ç”Ÿæˆã™ã‚‹
        labels = self._human_labels()
        target_char = plan.get("target_speaker", "A")
        edge_to_change = plan.get("edge_to_change", "AB")
        partner_char = next((ch for ch in edge_to_change if ch != target_char), "B")

        try:
            target_idx = "ABC".index(target_char)
            target_name = labels[target_idx]
        except ValueError:
            target_name = target_char
        try:
            partner_idx = "ABC".index(partner_char)
            partner_name = labels[partner_idx]
        except ValueError:
            partner_name = partner_char

        strategy = plan.get("strategy")

        # no_interventionã®å ´åˆã¯ã€Œè¦‹å®ˆã‚Šã€ç™ºè©±
        if strategy == "no_intervention":
            import random
            utterances = [
                "ï¼ˆé™ã‹ã«èã„ã¦ã„ã¾ã™ï¼‰",
                "ï¼ˆã†ãªãšã„ã¦è¦‹å®ˆã£ã¦ã„ã¾ã™ï¼‰",
                "ï¼ˆè©±ã‚’èã„ã¦ã„ã¾ã™ï¼‰",
                "ï¼ˆé»™ã£ã¦è€³ã‚’å‚¾ã‘ã¦ã„ã¾ã™ï¼‰"
            ]
            utterance = random.choice(utterances)
            return {
                "speaker": "ãƒ­ãƒœãƒƒãƒˆ",
                "utterance": utterance
            }

        # robot_max_historyå€‹ã®äººé–“ç™ºè©± + ãã®é–“ã®ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’å–å¾—ï¼ˆãƒ­ãƒœãƒƒãƒˆç™ºè©±ç”Ÿæˆç”¨ï¼‰
        filtered_logs = filter_logs_by_human_count(self.logs, self.robot_max_history)
        history_lines = [
            f"[{entry.get('speaker', '?')}] {entry.get('utterance', '').strip()}" for entry in filtered_logs
        ]
        history_text = "\n".join(history_lines) if history_lines else "(å±¥æ­´ãªã—)"

        directive_map = {
            "plan": f"{target_name}ã•ã‚“ã«å¯¾ã—ã¦ã€{partner_name}ã•ã‚“ã¨ã®é–¢ä¿‚ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€Œã“ã‚Œã‹ã‚‰ã©ã†ã™ã‚‹ã‹ã€ã¨ã„ã†æœªæ¥å¿—å‘ã®è¦–ç‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªæ¬¡ã®ä¸€æ­©ã‚„å°ã•ãªè¡Œå‹•æ¡ˆã‚’ä¸€æ–‡ã§ç¤ºã—ã€å‰å‘ããªè¡Œå‹•ã‚’ä¿ƒã—ã¦ãã ã•ã„ã€‚",
            "validate": f"{target_name}ã•ã‚“ã®æ„Ÿæƒ…ã‚„æ„è¦‹ã‚’æ˜ç¢ºã«æ‰¿èªãƒ»å…±æ„Ÿã—ã€ãã®ä¾¡å€¤ã‚’èªã‚ã¦ãã ã•ã„ã€‚{partner_name}ã•ã‚“ã¨ã®é–¢ä¿‚æ”¹å–„ã«å‘ã‘ã¦ã€{target_name}ã•ã‚“ãŒç†è§£ã•ã‚Œã€å°Šé‡ã•ã‚Œã¦ã„ã‚‹ã¨æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ãªä¸€æ–‡ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚",
            "bridge": f"{target_name}ã•ã‚“ã¨{partner_name}ã•ã‚“ã®é–“ã«å…±é€šç‚¹ãƒ»å…±é€šã®ç›®æ¨™ãƒ»ç›¸äº’ä¾å­˜æ€§ã‚’è¦‹å‡ºã—ã€ä¸¡è€…ã‚’ã¤ãªãå½¹å‰²ã‚’æœãŸã™ä¸€æ–‡ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚å¯¾ç«‹ã‚„èª¤è§£ã‚’å’Œã‚‰ã’ã€å”åŠ›çš„ãªé–¢ä¿‚æ§‹ç¯‰ã‚’ä¿ƒé€²ã—ã¦ãã ã•ã„ã€‚",
        }
        directive = directive_map.get(strategy, directive_map["plan"])

        fallback_text = self._fallback_intervention_text(target_name, partner_name, strategy)
        if simulate:
            return {"speaker": "ãƒ­ãƒœãƒƒãƒˆ", "utterance": fallback_text}

        cfg = get_config()
        llm_cfg = getattr(cfg, "llm", None)
        client, deployment = get_azure_chat_completion_client(llm_cfg, model_type="robot")
        max_attempts = getattr(cfg.llm, "max_attempts", 5) or 5
        base_backoff = getattr(cfg.llm, "base_backoff", 0.5) or 0.5
        if client and deployment:
            user_payload = (
                f"ã‚ãªãŸã¯{target_name}ã•ã‚“ã¨{partner_name}ã•ã‚“ã®é–¢ä¿‚æ€§ã‚’è‰¯ãã™ã‚‹ãŸã‚ã«ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å‡ºåŠ›ã¯æ—¥æœ¬èªã§ä¸€æ–‡ã®ã¿ã€‚è©±è€…ãƒ©ãƒ™ãƒ«ã‚„æ‹¬å¼§ã¯ä½¿ã‚ãªã„ã€‚\n"
                "ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ãªãŒã‚‰ã€ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦ç™ºè©±ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                f"æŒ‡ç¤º: {directive}\n"
                f"ä¼šè©±å±¥æ­´:\n{history_text}\n\n"
                "å¿…é ˆæ¡ä»¶:\n"
                f"- {target_name} ã•ã‚“ã¨{partner_name} ã•ã‚“ã®åå‰ã‚’ä¸€åº¦ã ã‘å…¥ã‚Œã‚‹ã€‚\n"
                "- ç›´å‰ã®è©±é¡Œã‚’è‡ªç„¶ã«å¼•ãç¶™ãã€‚\n"
                "- ä¸€æ–‡ã®ã¿ (60å­—å‰å¾Œ)ã€‚\n"
            )
            messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯é–¢ä¿‚æ€§ã‚’è‰¯ãã™ã‚‹ãŸã‚ã®ãƒ­ãƒœãƒƒãƒˆã®ç™ºè¨€ç”Ÿæˆå™¨ã¨ã—ã¦ã€é©åˆ‡ãªç™ºè©±å†…å®¹ã‚’ä½œæˆã—ã¾ã™ã€‚å¸¸ã«æ—¥æœ¬èªã®ä¸€æ–‡ã ã‘ã‚’è¿”ã—ã¾ã™ã€‚"},
                {"role": "user", "content": user_payload},
            ]
            for attempt in range(1, max_attempts + 1):
                try:
                    # GPT-5ã®å ´åˆã¯reasoningãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    params = build_chat_completion_params(deployment, messages, cfg.llm)
                    res = client.chat.completions.create(**params)
                    if res and getattr(res, "choices", None):
                        choice = res.choices[0]
                        message = getattr(choice, "message", None)
                        if isinstance(message, dict):
                            txt = message.get("content", "")
                        else:
                            txt = getattr(message, "content", "")
                        txt = (txt or "").strip()
                        cleaned = _strip_quotes(txt or "")
                        if cleaned:
                            return {"speaker": "ãƒ­ãƒœãƒƒãƒˆ", "utterance": cleaned}
                except Exception as exc:
                    # Azure OpenAIã®content filterã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å³åº§ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if "content_filter" in str(exc) or "ResponsibleAIPolicyViolation" in str(exc):
                        if getattr(get_config().env, "debug", False):
                            print(f"[robot_utterance] Azure content filter triggered, using fallback immediately")
                        break  # ã™ãã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ç§»è¡Œ

                    if getattr(get_config().env, "debug", False):
                        print(f"[robot_utterance] attempt {attempt} failed:", exc)
                    if attempt < max_attempts:
                        time.sleep(base_backoff * (2 ** (attempt - 1)))
                    else:
                        if getattr(get_config().env, "debug", False):
                            print("[robot_utterance] all attempts failed, falling back to local heuristic")
        return {"speaker": "ãƒ­ãƒœãƒƒãƒˆ", "utterance": fallback_text}

    def _fallback_intervention_text(self, target_name: str, partner_name: str, strategy: str) -> str:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ä»‹å…¥ç™ºè©±ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        templates = {
            "plan": f"{target_name}ã•ã‚“ã€æ¬¡ã®ä¸€æ­©ã¨ã—ã¦ã€ã¾ãšå°ã•ãªã“ã¨ã‹ã‚‰å§‹ã‚ã¦ã¿ã¾ã›ã‚“ã‹ï¼Ÿ",
            "validate": f"{target_name}ã•ã‚“ã€ã‚ãªãŸã®æ„è¦‹ã¯ã¨ã¦ã‚‚å¤§åˆ‡ã§ã™ã€‚ã‚‚ã£ã¨èã‹ã›ã¦ãã ã•ã„ã€‚",
            "bridge": f"{target_name}ã•ã‚“ã€{partner_name}ã•ã‚“ã€ãŠäºŒäººã«ã¯å…±é€šã®ç›®æ¨™ãŒã‚ã‚‹ã¨æ€ã„ã¾ã™ã€‚",
        }
        return templates.get(strategy, templates["plan"])

    def _bootstrap_humans(
        self,
        target_turns: int,
        emotional_needs: Optional[Dict[str, str]] = None,
        is_correct_strategy_flags: Optional[Dict[str, bool]] = None
    ) -> None:
        # äººé–“å‚åŠ è€…ã®ç™ºè©±ã‚’è¿½åŠ ã—ã¦ä¼šè©±ã‚’é€²ã‚ã‚‹
        turns_added = 0
        safety_limit = max(1, self.max_steps * max(1, len(self.persona_pool)) * 3)
        while turns_added < target_turns and turns_added < safety_limit:
            # 1äººé–“ç™ºè©±ãšã¤ç”Ÿæˆ
            replies = human_reply(
                self.logs,
                self.persona_pool,
                topic=self.current_topic,
                topic_trigger=self.current_topic_trigger,
                num_speakers=1,
                speaker_aggressiveness=self.speaker_aggressiveness,
                emotional_needs=emotional_needs,
                is_correct_strategy_flags=is_correct_strategy_flags
            )
            if not replies:
                break
            self.logs.extend(replies)
            participants = self._participants(self.logs)
            if participants:
                # 3ç™ºè©±å¾Œã‹ã‚‰é–¢ä¿‚æ€§æ¨å®šã‚’æ›´æ–°
                human_utterance_count = sum(1 for log in self.logs if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if human_utterance_count >= self.start_relation_check_after_utterances:
                    # é–¢ä¿‚æ€§LLMã«ã¯ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’é™¤å¤–ã—ã¦æ¸¡ã™
                    filtered_logs = filter_logs_by_human_count(self.logs, self.max_history_relation, exclude_robot=True)
                    self.scorer.get_scores(filtered_logs, participants, return_trace=False, update_state=True)
            turns_added += 1

    async def _bootstrap_humans_async(
        self,
        logs: List[Dict[str, Any]],
        target_turns: int,
        scorer: RelationScorer,
    ) -> List[Dict[str, Any]]:
        """
        äººé–“å‚åŠ è€…ã®ç™ºè©±ã‚’éåŒæœŸã§è¿½åŠ ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰

        Args:
            logs: ä¼šè©±ãƒ­ã‚°ï¼ˆå¤‰æ›´ã•ã‚Œãªã„ã€ã‚³ãƒ”ãƒ¼ã—ã¦ä½¿ç”¨ï¼‰
            target_turns: ç”Ÿæˆã™ã‚‹äººé–“ç™ºè©±ã®å›æ•°
            scorer: é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ãƒ©ãƒ¼

        Returns:
            æ›´æ–°ã•ã‚ŒãŸä¼šè©±ãƒ­ã‚°
        """
        logs_copy = copy.deepcopy(logs)
        turns_added = 0
        safety_limit = max(1, self.max_steps * max(1, len(self.persona_pool)))

        while turns_added < target_turns and turns_added < safety_limit:
            # human_replyã¯åŒæœŸé–¢æ•°ãªã®ã§ã€asyncio.to_thread()ã§ãƒ©ãƒƒãƒ—
            # 1äººé–“ç™ºè©±ãšã¤ç”Ÿæˆ
            replies = await asyncio.to_thread(
                human_reply,
                logs_copy,
                self.persona_pool,
                topic=self.current_topic,
                topic_trigger=self.current_topic_trigger,
                num_speakers=1
            )
            if not replies:
                break
            logs_copy.extend(replies)
            participants = self._participants(logs_copy)
            if participants:
                human_utterance_count = sum(1 for log in logs_copy if log.get('speaker') != 'ãƒ­ãƒœãƒƒãƒˆ')
                if human_utterance_count >= self.start_relation_check_after_utterances:
                    filtered_logs = filter_logs_by_human_count(logs_copy, self.max_history_relation, exclude_robot=True)
                    # get_scoresã‚‚åŒæœŸé–¢æ•°ãªã®ã§ã€asyncio.to_thread()ã§ãƒ©ãƒƒãƒ—
                    await asyncio.to_thread(
                        scorer.get_scores,
                        filtered_logs,
                        participants,
                        return_trace=False,
                        update_state=True
                    )
            turns_added += len([r for r in replies if r.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ"])

        return logs_copy

    def _ensure_unstable_seed(self) -> None:
        # åˆæœŸçŠ¶æ…‹ãŒä¸å®‰å®šã«ãªã‚‹ã¾ã§äººé–“ç™ºè©±ã‚’è¿½åŠ ã™ã‚‹
        attempts = 0
        while self._is_balanced() and attempts < self.max_steps:
            self._bootstrap_humans(self.evaluation_horizon)
            attempts += 1

    def _participants(self, logs: List[Dict[str, Any]]) -> List[str]:
        # ç™ºè©±è€…ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ï¼ˆãƒ­ãƒœãƒƒãƒˆé™¤å¤–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
        names = {entry.get("speaker") for entry in logs if entry.get("speaker") and entry.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ"}
        return sorted(names)

    def _human_labels(self) -> List[str]:
        # äººé–“å‚åŠ è€…ã®ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹
        labels = [name for name in self.persona_pool if name]
        while len(labels) < 3:
            labels.append(chr(ord("A") + len(labels)))
        return labels[:3]

    def _edge_weights(self, logs: List[Dict[str, Any]]) -> Dict[str, float]:
        # ã‚¨ãƒƒã‚¸ã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹
        participants = self._participants(logs)
        scores = self.scorer.get_scores(logs, participants, return_trace=False, update_state=False)
        return self._edge_weights_from_scores(scores)

    def _edge_weights_from_scores(self, scores: Dict[Tuple[str, str], float]) -> Dict[str, float]:
        # ã‚¹ã‚³ã‚¢ã‹ã‚‰ã‚¨ãƒƒã‚¸ã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹
        labels = self._human_labels()
        key_map = {
            "AB": tuple(sorted((labels[0], labels[1]))),
            "BC": tuple(sorted((labels[1], labels[2]))),
            "CA": tuple(sorted((labels[2], labels[0]))),
        }
        return {edge: float(scores.get(pair, 0.0)) for edge, pair in key_map.items()}

    def _relation_state(self, logs: List[Dict[str, Any]], *, update_state: bool) -> Tuple[Dict[Tuple[str, str], float], List[str]]:
        # é–¢ä¿‚ã‚¹ã‚³ã‚¢ã®çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹
        participants = self._participants(logs)
        scores, trace = self.scorer.get_scores(logs, participants, return_trace=True, update_state=update_state)
        return scores, trace

    def _metrics_state(self, scores: Dict[Tuple[str, str], float], participants: List[str]) -> Tuple[Dict[str, Any], List[str]]:
        # é–¢ä¿‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹
        metrics, trace = analyze_relations_from_scores(scores, include_nodes=participants, verbose=True, return_trace=True)
        return metrics, trace

    def _compute_u_flip(self, weights: Dict[str, float]) -> Tuple[float, str, Dict[str, float]]:
        # ä¸å®‰å®šåº¦ u_flip ã¨æœ€é©å®‰å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—ã™ã‚‹
        best_total = math.inf
        best_sign = "+++"
        best_distances: Dict[str, float] = {edge: 0.0 for edge in weights}
        for sign, mapping in _STABLE_SIGN_PATTERNS.items():
            total = 0.0
            distances: Dict[str, float] = {}
            for edge, direction in mapping.items():
                weight = weights.get(edge, 0.0)
                distance = max(0.0, -direction * weight)
                distances[edge] = distance
                total += distance
            if total < best_total:
                best_total = total
                best_sign = sign
                best_distances = distances
        if not math.isfinite(best_total):
            best_total = 0.0
        return best_total, best_sign, best_distances

    def _get_human_preferred_strategy(self, target_speaker: str) -> str:
        """å¯¾è±¡è©±è€…ã®æ„Ÿæƒ…ãƒ‹ãƒ¼ã‚ºã‹ã‚‰å¥½ã¾ã‚Œã‚‹æˆ¦ç•¥ã‚’è¿”ã™"""
        need = self.persona_emotional_needs.get(target_speaker, "recognition")
        need_to_strategy = {
            "recognition": "validate",
            "mediation": "bridge",
            "solution": "plan",
            "independence": "no_intervention"
        }
        return need_to_strategy[need]

    def _is_balanced(self) -> bool:
        # ç¾åœ¨ã®ä¼šè©±ãƒ­ã‚°ã«åŸºã¥ãã€é–¢ä¿‚ãŒå®‰å®šçŠ¶æ…‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        snapshot = self.relation_snapshot()
        triangles = snapshot.get("triangles", {})
        if not triangles:
            return False
        return all(status == "S" for status in triangles.values())

    # ------------------------------------------------------------------
    # Validation
    # ------------------------------------------------------------------
    def _validate_plan(self, plan: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        # ä»‹å…¥ãƒ—ãƒ©ãƒ³ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼
        if not isinstance(plan, dict):
            return False, "plan_not_dict"
        if "intervene_now" not in plan:
            return False, "missing_intervene_now"

        intervene_now = bool(plan.get("intervene_now"))
        if intervene_now:
            edge = plan.get("edge_to_change")
            strategy = plan.get("strategy")
            target = plan.get("target_speaker")
            if edge not in _TARGET_EDGES:
                return False, "invalid_edge"
            if strategy not in _ALLOWED_STRATEGIES:
                return False, "invalid_strategy"
            if target not in _TARGET_SPEAKERS:
                return False, "invalid_target"
        return True, None

    # ------------------------------------------------------------------
    # Diagnostics
    # ------------------------------------------------------------------
    def relation_snapshot(self) -> Dict[str, Any]:
        # ç¾åœ¨ã®ä¼šè©±ãƒ­ã‚°ã«åŸºã¥ãã€é–¢ä¿‚ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        participants = self._participants(self.logs)
        scores = self.scorer.get_scores(self.logs, participants, return_trace=False, update_state=False)
        relations = analyze_relations_from_scores(scores, include_nodes=participants, verbose=self.debug)
        triangles = {}
        for tri in relations.get("triangles", []):
            nodes = tuple(sorted(tri.get("nodes", [])))
            if any(node == "ãƒ­ãƒœãƒƒãƒˆ" for node in nodes):
                continue
            struct = tri.get("struct")
            if struct in BALANCED:
                status = "S"
            elif struct in UNBALANCED:
                status = "U"
            else:
                status = "?"
            triangles[nodes] = status

        # æˆ»ã‚Šå€¤ã‚’æ§‹ç¯‰ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€metricsã®å†…å®¹ã‚‚ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«å«ã‚ã‚‹ï¼‰
        result = {
            "participants": [p for p in participants if p != "ãƒ­ãƒœãƒƒãƒˆ"],
            "triangles": triangles,
            "scores": scores,
            "metrics": relations,  # metricsã‚­ãƒ¼ã‚’è¿½åŠ ï¼ˆedgesãªã©ã‚’å«ã‚€ï¼‰
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€metricsã®ä¸»è¦ãªã‚­ãƒ¼ã‚’ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«ã‚‚è¿½åŠ 
            "unstable_triads": relations.get("unstable_triads", 0),
            "balanced_triads": relations.get("balanced_triads", 0),
            "edges": relations.get("edges", {}),
            "iso_nodes": relations.get("iso_nodes", 0),
        }
        return result
